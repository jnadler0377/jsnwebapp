from __future__ import annotations

# ---- Windows event loop fix for asyncio subprocess ----
import sys as _sys
import asyncio as _asyncio
if _sys.platform == "win32":
    try:
        _asyncio.set_event_loop_policy(_asyncio.WindowsProactorEventLoopPolicy())
    except Exception:
        pass

# ---------------- Stdlib ----------------
import logging
import asyncio
import csv as _csv
import datetime as _dt
import os
import sys
import tempfile
import uuid
import io, json
from pathlib import Path
from typing import List, Optional
from PyPDF2 import PdfReader, PdfWriter
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from tools.import_pasco_csv import main as import_pasco_csv_main
import requests  # for BatchData skip trace calls

# ---------------- FastAPI / Responses ----------------
from fastapi import (
    FastAPI,
    Request,
    Depends,
    UploadFile,
    File,
    Form,
    Query,
    HTTPException,
)
from fastapi.responses import HTMLResponse, RedirectResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates

# ---------------- DB / ORM ----------------
from sqlalchemy.orm import Session
from sqlalchemy import inspect, text, bindparam
from sqlalchemy.exc import OperationalError

# ---------------- App imports ----------------
from app.services.progress_bus import progress_bus
from app.settings import settings
from .database import Base, engine, SessionLocal
from .models import Case, Defendant, Docket, Note
from .utils import ensure_case_folder, compute_offer_70
from .schemas import OutstandingLien, OutstandingLiensUpdate
from dotenv import dotenv_values

# Resolve project root (adjust if your .env lives somewhere else)
BASE_DIR = Path(__file__).resolve().parent.parent  # e.g. C:\pascowebapp
ENV_PATH = BASE_DIR / ".env"

# Read ONLY from the .env file
env_values = dotenv_values(ENV_PATH)

BATCHDATA_API_KEY = env_values.get("BATCHDATA_API_KEY")

print("DEBUG: .env path =", ENV_PATH)
print("DEBUG: BATCHDATA_API_KEY from .env =", BATCHDATA_API_KEY)

# ======================================================================
# App bootstrap
# ======================================================================
app = FastAPI(title="JSN Holdings Foreclosure Manager")
logger = logging.getLogger("pascowebapp")
logger.setLevel(logging.INFO)

BASE_DIR = Path(__file__).resolve().parent.parent
STATIC_DIR = BASE_DIR / "app" / "static"
TEMPLATES_DIR = BASE_DIR / "app" / "templates"
UPLOAD_ROOT = BASE_DIR / "uploads"
UPLOAD_ROOT.mkdir(parents=True, exist_ok=True)

app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")
app.mount("/uploads", StaticFiles(directory=str(UPLOAD_ROOT)), name="uploads")

templates = Jinja2Templates(directory=str(TEMPLATES_DIR))

# ======================================================================
# Jinja filters / globals
# ======================================================================
def _currency(v):
    try:
        return "${:,.2f}".format(float(v))
    except Exception:
        return "$0.00"


def streetview_url(address: str) -> str:
    """
    Prefer Google Street View Static API if key present, else fall back
    to Static Map with a marker. Reads key from settings (env/.env).
    """
    if not address:
        return ""
    key = settings.GOOGLE_MAPS_API_KEY
    if key:
        base = "https://maps.googleapis.com/maps/api/streetview"
        return f"{base}?size=600x360&location={address}&key={key}"
    base = "https://maps.googleapis.com/maps/api/staticmap"
    return f"{base}?size=640x360&markers={address}"


def _parcel_to_property_card_param(parcel_id: str | None) -> Optional[str]:
    """
    Convert Pasco parcel formats to the property card 'parcel=' digits string.

    Example:
      Input:  '33-24-16-0260-00000-2540'
      Output: '1624330260000002540'
      (the first three 2-digit sets are mirrored: 33-24-16 -> 16 24 33)
    """
    if not parcel_id:
        return None

    s = parcel_id.strip().replace(" ", "")
    parts = s.split("-")

    # If it looks like the standard dash-delimited format with first three 2-digit parts
    if len(parts) >= 3 and all(len(p) == 2 for p in parts[:3]):
        reordered = parts[2] + parts[1] + parts[0] + "".join(parts[3:])
        digits = "".join(ch for ch in reordered if ch.isdigit())
        return digits or None

    # Fallback: digits only
    digits = "".join(ch for ch in s if ch.isdigit())
    return digits or None


def pasco_appraiser_url(parcel_id: str | None) -> Optional[str]:
    """Return the direct property card URL for a given parcel id."""
    param = _parcel_to_property_card_param(parcel_id)
    if not param:
        return None
    return f"https://search.pascopa.com/parcel.aspx?parcel={param}"


# ======================================================================
# BatchData Skip Trace config + helpers
# ======================================================================
BATCHDATA_API_KEY = env_values.get("BATCHDATA_API_KEY")
BATCHDATA_BASE_URL = "https://api.batchdata.com/api/v1"


def get_case_address_components(case) -> tuple[str, str, str, Optional[str]]:
    """
    Best-effort extraction of address components for BatchData skip trace.

    We try explicit fields first (if they exist on the model), otherwise
    we parse the combined address line into:
      street, city, state, postal_code
    """
    raw_addr = (getattr(case, "address_override", None) or getattr(case, "address", "") or "").strip()

    street = raw_addr
    city = ""
    state = "FL"
    postal_code: Optional[str] = None

    # If the ORM model has explicit fields, prefer them
    city_attr = getattr(case, "city", None)
    state_attr = getattr(case, "state", None)
    postal_attr = getattr(case, "postal_code", None) or getattr(case, "zip", None)

    if city_attr or state_attr or postal_attr:
        if city_attr:
            city = str(city_attr).strip()
        if state_attr:
            s = str(state_attr).strip()
            if s:
                state = s
        if postal_attr:
            postal_code = str(postal_attr).strip() or None
        if street:
            return street, city, state, postal_code

    # Fallback: parse from combined address string "123 Main St, City, ST 33556"
    if raw_addr and "," in raw_addr:
        parts = [p.strip() for p in raw_addr.split(",")]
        street = parts[0]
        if len(parts) >= 2:
            city = parts[1]
        if len(parts) >= 3:
            st_zip_parts = parts[2].split()
            if st_zip_parts:
                state = st_zip_parts[0]
            if len(st_zip_parts) > 1:
                postal_code = st_zip_parts[1]

    return street, city, state, postal_code


def batchdata_skip_trace(
    street: str,
    city: str,
    state: str,
    postal_code: Optional[str] = None,
) -> dict:
    """
    Call BatchData Property Skip Trace API and normalize into a structure
    the template can use, including detailed phone/email metadata.
    """
    import logging
    logger = logging.getLogger("batchdata")
    logger.setLevel(logging.INFO)

    if not BATCHDATA_API_KEY:
        raise HTTPException(status_code=500, detail="BatchData API key not configured")

    if not street or not city or not state:
        raise HTTPException(status_code=400, detail="Incomplete address for skip trace")

    url = f"{BATCHDATA_BASE_URL}/property/skip-trace"

    property_address: dict = {
        "street": street,
        "city": city,
        "state": state,
    }
    if postal_code:
        property_address["postalCode"] = postal_code

    payload = {
        "requests": [
            {
                "propertyAddress": property_address
            }
        ]
    }

    headers = {
        # BatchData docs expect Bearer here
        "Authorization": f"Bearer {BATCHDATA_API_KEY}",
        "Content-Type": "application/json",
    }

    # *** LOG OUTGOING REQUEST (with masked key) ***
    masked_headers = dict(headers)
    if "Authorization" in masked_headers:
        token = masked_headers["Authorization"]
        if len(token) > 20:
            masked_headers["Authorization"] = token[:20] + "...(masked)"

    logger.info("=== BatchData Skip Trace REQUEST ===")
    logger.info("URL: %s", url)
    logger.info("HEADERS: %s", masked_headers)
    logger.info("PAYLOAD: %s", json.dumps(payload))

    # Also print to console so you 100% see it, even if logging config is odd
    print("=== BatchData Skip Trace REQUEST ===")
    print("URL:", url)
    print("HEADERS:", masked_headers)
    print("PAYLOAD:", json.dumps(payload))

    try:
        resp = requests.post(url, json=payload, headers=headers, timeout=20)
    except requests.RequestException as exc:
        logger.error("Error calling BatchData API: %s", exc)
        print("BatchData ERROR:", exc)
        raise HTTPException(status_code=502, detail=f"Error calling BatchData API: {exc}") from exc

    # *** LOG RAW RESPONSE ***
    logger.info("=== BatchData Skip Trace RESPONSE ===")
    logger.info("STATUS: %s", resp.status_code)
    logger.info("TEXT: %s", resp.text[:2000])

    print("=== BatchData Skip Trace RESPONSE ===")
    print("STATUS:", resp.status_code)
    print("TEXT:", resp.text[:2000])

    # --- Handle error status codes cleanly ---
    if resp.status_code >= 400:
        try:
            err_json = resp.json()
        except Exception:
            err_json = resp.text

        if resp.status_code == 403:
            raise HTTPException(
                status_code=403,
                detail=(
                    "BatchData: this API key does not have permission for the "
                    "Property Skip Trace endpoint. Check your BatchData plan or API key settings."
                ),
            )

        raise HTTPException(
            status_code=resp.status_code,
            detail=f"BatchData error: {err_json}",
        )

    # --- Parse success response (same as before) ---
    try:
        data = resp.json()
    except Exception:
        raise HTTPException(
            status_code=502,
            detail=f"BatchData returned non-JSON response: {resp.text[:500]}",
        )

    out_results: list[dict] = []

    if isinstance(data, dict):
        res = data.get("results")
        if isinstance(res, dict):
            raw_results = [res]
        elif isinstance(res, list):
            raw_results = res
        else:
            resp_obj = data.get("response")
            if isinstance(resp_obj, dict) and isinstance(resp_obj.get("results"), list):
                raw_results = resp_obj["results"]
            else:
                raise HTTPException(
                    status_code=502,
                    detail=f"Unexpected BatchData response structure (dict, no usable results): {data}",
                )
    elif isinstance(data, list):
        raw_results = data
    else:
        raise HTTPException(
            status_code=502,
            detail=f"Unexpected BatchData response type: {type(data).__name__} -> {data!r}",
        )

    for r in raw_results:
        if not isinstance(r, dict):
            continue

        persons_raw = r.get("persons") or []
        if not isinstance(persons_raw, list):
            persons_raw = []

        simple_persons: list[dict] = []
        property_addr_result: dict = r.get("propertyAddress") or {}

        for p in persons_raw:
            if not isinstance(p, dict):
                continue

            if not property_addr_result:
                pa = p.get("propertyAddress")
                if not isinstance(pa, dict):
                    prop = p.get("property") or {}
                    if isinstance(prop, dict):
                        pa = prop.get("address")
                if isinstance(pa, dict):
                    property_addr_result = pa

            full_name = ""
            if isinstance(p.get("fullName"), str):
                full_name = p["fullName"]
            else:
                name_obj = p.get("name")
                if isinstance(name_obj, dict):
                    full_name = (
                        name_obj.get("full")
                        or " ".join(
                            x for x in [name_obj.get("first"), name_obj.get("last")] if x
                        )
                    )
                elif isinstance(name_obj, str):
                    full_name = name_obj

            emails: list[dict] = []
            emails_raw = p.get("emails") or []
            if isinstance(emails_raw, list):
                for e in emails_raw:
                    if isinstance(e, dict):
                        email = e.get("email")
                        tested = e.get("tested")
                        if email:
                            emails.append(
                                {
                                    "email": email,
                                    "tested": bool(tested) if isinstance(tested, bool) else None,
                                }
                            )
                    elif isinstance(e, str):
                        emails.append({"email": e, "tested": None})

            phones: list[dict] = []
            phones_raw = p.get("phoneNumbers") or []
            if isinstance(phones_raw, list):
                for ph in phones_raw:
                    if not isinstance(ph, dict):
                        continue
                    number = ph.get("number") or ph.get("phone")
                    if not number:
                        continue
                    phone_type = ph.get("type")
                    carrier = ph.get("carrier")
                    tested = ph.get("tested")
                    reachable = ph.get("reachable")
                    dnc = ph.get("dnc")
                    last_reported = ph.get("lastReportedDate")
                    score = ph.get("score")
                    phones.append(
                        {
                            "number": number,
                            "type": phone_type,
                            "carrier": carrier,
                            "tested": bool(tested) if isinstance(tested, bool) else None,
                            "reachable": bool(reachable) if isinstance(reachable, bool) else None,
                            "dnc": bool(dnc) if isinstance(dnc, bool) else None,
                            "last_reported": last_reported,
                            "score": score,
                        }
                    )

            simple_persons.append(
                {
                    "full_name": full_name,
                    "emails": emails,
                    "phones": phones,
                }
            )

        out_results.append(
            {
                "propertyAddress": property_addr_result or {},
                "persons": simple_persons,
            }
        )

    return {"results": out_results}



def save_skiptrace_row(case_id: int, skip_trace: dict) -> None:
    """
    Take our normalized skip_trace dict (from batchdata_skip_trace) and
    persist ALL phones/emails into case_skiptrace_phone / case_skiptrace_email,
    plus a summary row in case_skiptrace.
    """
    try:
        results = (skip_trace or {}).get("results") or []
        if not results:
            return

        res = results[0]
        persons = res.get("persons") or []
        if not persons:
            return

        p = persons[0]

        owner_name = p.get("full_name") or ""

        # Property address from the normalized result
        prop_addr = res.get("propertyAddress") or {}
        prop_street = prop_addr.get("street")
        prop_city = prop_addr.get("city")
        prop_state = prop_addr.get("state")
        prop_zip = prop_addr.get("zip") or prop_addr.get("postalCode")

        phones = p.get("phones") or []
        emails = p.get("emails") or []

        with engine.begin() as conn:
            # Upsert base summary row
            conn.exec_driver_sql(
                """
                INSERT INTO case_skiptrace (
                    case_id,
                    owner_name,
                    prop_street, prop_city, prop_state, prop_zip
                )
                VALUES (?, ?, ?, ?, ?, ?)
                ON CONFLICT(case_id) DO UPDATE SET
                    owner_name = excluded.owner_name,
                    prop_street = excluded.prop_street,
                    prop_city = excluded.prop_city,
                    prop_state = excluded.prop_state,
                    prop_zip = excluded.prop_zip
                """,
                (case_id, owner_name, prop_street, prop_city, prop_state, prop_zip),
            )

            # Clear old phones/emails for this case
            conn.exec_driver_sql(
                "DELETE FROM case_skiptrace_phone WHERE case_id = ?",
                (case_id,),
            )
            conn.exec_driver_sql(
                "DELETE FROM case_skiptrace_email WHERE case_id = ?",
                (case_id,),
            )

            # Insert ALL phones
            for ph in phones:
                if not isinstance(ph, dict):
                    continue
                number = ph.get("number")
                if not number:
                    continue
                phone_type = ph.get("type")
                carrier = ph.get("carrier")
                last_reported = ph.get("last_reported") or ph.get("lastReportedDate")
                score = ph.get("score")

                def as_int_bool(val):
                    if isinstance(val, bool):
                        return int(val)
                    return None

                tested = as_int_bool(ph.get("tested"))
                reachable = as_int_bool(ph.get("reachable"))
                dnc = as_int_bool(ph.get("dnc"))

                conn.exec_driver_sql(
                    """
                    INSERT INTO case_skiptrace_phone (
                        case_id, number, type, carrier,
                        last_reported, score, tested, reachable, dnc
                    )
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """,
                    (
                        case_id,
                        number,
                        phone_type,
                        carrier,
                        last_reported,
                        score,
                        tested,
                        reachable,
                        dnc,
                    ),
                )

            # Insert ALL emails
            for em in emails:
                if isinstance(em, dict):
                    email_addr = em.get("email")
                    tested_val = em.get("tested")
                    tested_int = int(tested_val) if isinstance(tested_val, bool) else None
                else:
                    email_addr = str(em)
                    tested_int = None

                if not email_addr:
                    continue

                conn.exec_driver_sql(
                    """
                    INSERT INTO case_skiptrace_email (
                        case_id, email, tested
                    )
                    VALUES (?, ?, ?)
                    """,
                    (case_id, email_addr, tested_int),
                )

    except Exception as exc:
        logger.warning("Failed to save skip trace rows for case %s: %s", case_id, exc)



def load_skiptrace_for_case(case_id: int) -> Optional[dict]:
    """
    Load normalized skip-trace data from case_skiptrace + phone/email tables
    and convert it back into the 'skip_trace' dict structure the template expects.
    """
    try:
        with engine.connect() as conn:
            base = conn.exec_driver_sql(
                """
                SELECT
                    owner_name,
                    prop_street, prop_city, prop_state, prop_zip
                FROM case_skiptrace
                WHERE case_id = ?
                """,
                (case_id,),
            ).fetchone()

            phones_rows = conn.exec_driver_sql(
                """
                SELECT
                    number, type, carrier, last_reported,
                    score, tested, reachable, dnc
                FROM case_skiptrace_phone
                WHERE case_id = ?
                ORDER BY
                    -- highest score first, then non-null last_reported
                    CASE WHEN score IS NULL THEN 1 ELSE 0 END,
                    score DESC
                """,
                (case_id,),
            ).fetchall()

            emails_rows = conn.exec_driver_sql(
                """
                SELECT
                    email, tested
                FROM case_skiptrace_email
                WHERE case_id = ?
                """,
                (case_id,),
            ).fetchall()
    except Exception as exc:
        logger.warning("Failed to load skip trace for case %s: %s", case_id, exc)
        return None

    if not base:
        return None

    (
        owner_name,
        prop_street, prop_city, prop_state, prop_zip,
    ) = base

    def as_bool(val):
        if val is None:
            return None
        return bool(val)

    phones = []
    for row in phones_rows:
        (
            number, ptype, carrier, last_reported,
            score, tested, reachable, dnc,
        ) = row
        phones.append(
            {
                "number": number,
                "type": ptype,
                "carrier": carrier,
                "last_reported": last_reported,
                "score": score,
                "tested": as_bool(tested),
                "reachable": as_bool(reachable),
                "dnc": as_bool(dnc),
            }
        )

    emails = []
    for row in emails_rows:
        email_addr, tested = row
        emails.append(
            {
                "email": email_addr,
                "tested": as_bool(tested),
            }
        )

    property_address = {
        "street": prop_street,
        "city": prop_city,
        "state": prop_state,
        "postalCode": prop_zip,
    }

    person = {
        "full_name": owner_name,
        "phones": phones,
        "emails": emails,
    }

    return {
        "results": [
            {
                "propertyAddress": property_address,
                "persons": [person],
            }
        ]
    }



templates.env.filters["currency"] = _currency
templates.env.globals["streetview_url"] = streetview_url
templates.env.globals["pasco_appraiser_url"] = pasco_appraiser_url

# ======================================================================
# DB session
# ======================================================================
def get_db():
    """
    Standard DB session dependency.
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


# ======================================================================
# Skip Trace JSON Cache Helpers (legacy, still safe to keep)
# ======================================================================
def get_cached_skip_trace(case_id: int) -> Optional[dict]:
    """
    Read cached skip-trace JSON from the cases table, if any.
    """
    try:
        with engine.connect() as conn:
            row = conn.execute(
                text("SELECT skip_trace_json FROM cases WHERE id = :id"),
                {"id": case_id},
            ).mappings().first()
        if row and row.get("skip_trace_json"):
            try:
                return json.loads(row["skip_trace_json"])
            except Exception as exc:
                logger.warning(
                    "Failed to parse skip_trace_json for case %s: %s", case_id, exc
                )
                return None
    except Exception as exc:
        logger.warning(
            "Failed to read skip_trace_json for case %s: %s", case_id, exc
        )
    return None


def set_cached_skip_trace(case_id: int, payload: dict) -> None:
    """
    Persist skip-trace JSON into the cases.skip_trace_json column.
    """
    try:
        with engine.begin() as conn:
            conn.exec_driver_sql(
                "UPDATE cases SET skip_trace_json = :payload WHERE id = :id",
                {"payload": json.dumps(payload), "id": case_id},
            )
    except Exception as exc:
        logger.warning(
            "Failed to write skip_trace_json for case %s: %s", case_id, exc
        )


Base.metadata.create_all(bind=engine)

# ======================================================================
# Startup: ensure late-added columns exist (sqlite ALTERs)
# ======================================================================
@app.on_event("startup")
def ensure_sqlite_columns():
    Base.metadata.create_all(bind=engine)
    try:
        inspector = inspect(engine)
        cols = {c["name"] for c in inspector.get_columns("cases")}
        with engine.begin() as conn:
            if "current_deed_path" not in cols:
                conn.exec_driver_sql(
                    "ALTER TABLE cases ADD COLUMN current_deed_path TEXT DEFAULT ''"
                )
            if "previous_deed_path" not in cols:
                conn.exec_driver_sql(
                    "ALTER TABLE cases ADD COLUMN previous_deed_path TEXT DEFAULT ''"
                )
            # Outstanding liens column (JSON stored as TEXT)
            if "outstanding_liens" not in cols:
                conn.exec_driver_sql(
                    "ALTER TABLE cases ADD COLUMN outstanding_liens TEXT DEFAULT '[]'"
                )
            # Skip trace JSON cache
            if "skip_trace_json" not in cols:
                conn.exec_driver_sql(
                    "ALTER TABLE cases ADD COLUMN skip_trace_json TEXT DEFAULT NULL"
                )
    except OperationalError:
        # first run or non-sqlite; ignore
        pass


# --------------------------------------------------------
#  SKIP TRACE NORMALIZED TABLE (CREATE ON STARTUP)
# --------------------------------------------------------
@app.on_event("startup")
# --------------------------------------------------------
#  SKIP TRACE NORMALIZED TABLES (CREATE ON STARTUP)
# --------------------------------------------------------
@app.on_event("startup")
def ensure_skiptrace_tables():
    """
    Ensure the skip-trace tables exist:

      - case_skiptrace         (1 row per case: owner + property address)
      - case_skiptrace_phone   (N rows per case: all phones)
      - case_skiptrace_email   (N rows per case: all emails)
    """
    try:
        with engine.begin() as conn:
            # Base summary table (leave existing extra columns alone if already created)
            conn.exec_driver_sql(
                """
                CREATE TABLE IF NOT EXISTS case_skiptrace (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    case_id INTEGER NOT NULL UNIQUE,
                    owner_name TEXT,
                    prop_street TEXT,
                    prop_city TEXT,
                    prop_state TEXT,
                    prop_zip TEXT,
                    FOREIGN KEY(case_id) REFERENCES cases(id)
                )
                """
            )

            # Phones: one row per phone record
            conn.exec_driver_sql(
                """
                CREATE TABLE IF NOT EXISTS case_skiptrace_phone (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    case_id INTEGER NOT NULL,
                    number TEXT,
                    type TEXT,
                    carrier TEXT,
                    last_reported TEXT,
                    score INTEGER,
                    tested INTEGER,
                    reachable INTEGER,
                    dnc INTEGER,
                    FOREIGN KEY(case_id) REFERENCES cases(id)
                )
                """
            )

            # Emails: one row per email record
            conn.exec_driver_sql(
                """
                CREATE TABLE IF NOT EXISTS case_skiptrace_email (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    case_id INTEGER NOT NULL,
                    email TEXT,
                    tested INTEGER,
                    FOREIGN KEY(case_id) REFERENCES cases(id)
                )
                """
            )
    except OperationalError:
        # sqlite / first run quirks; ignore
        pass
    except Exception as exc:
        logger.warning("Failed to ensure skip-trace tables: %s", exc)



# ======================================================================
# Helpers: shell runner + scraper glue
# ======================================================================
async def run_command_with_logs(cmd: list[str], job_id: str) -> int:
    """
    Async process runner that streams stdout->progress_bus line by line.
    """
    proc = await asyncio.create_subprocess_exec(
        *cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.STDOUT,
    )
    assert proc.stdout is not None
    async for raw in proc.stdout:
        await progress_bus.publish(job_id, raw.decode(errors="ignore").rstrip("\n"))
    rc = await proc.wait()
    await progress_bus.publish(job_id, f"[done] exit_code={rc}")
    return rc


def _find_scraper_script() -> Path:
    """
    Locate `pasco_foreclosure_scraper.py` in either:
    - <root>/Pasco Foreclosure Scrape
    - <root>/app/scrapers
    """
    candidates = [
        BASE_DIR / "Pasco Foreclosure Scrape" / "pasco_foreclosure_scraper.py",
        BASE_DIR / "app" / "scrapers" / "pasco_foreclosure_scraper.py",
    ]
    for p in candidates:
        if p.exists():
            return p
    raise HTTPException(
        status_code=500,
        detail=(
            "Scraper script not found. Place 'pasco_foreclosure_scraper.py' in "
            "'Pasco Foreclosure Scrape/' or 'app/scrapers/'."
        ),
    )


def _import_csv_into_db(db: Session, csv_path: str) -> tuple[int, int, int]:
    """
    Lightweight importer (upsert by case_number, ignore duplicates).
    Returns (added, updated, skipped).
    """
    import re
    logger = logging.getLogger(__name__)

    def norm_case(s):
        s = str(s or "").strip().replace("\\", "-").replace("/", "-")
        s = re.sub(r"\s+", "", s)
        return s

    def pick_col(headers, candidates):
        """
        Given a list of headers and candidate names, return the first
        header that matches (case-insensitive, trimmed).
        """
        norm_headers = [h.strip().lower() for h in headers]
        for cand in candidates:
            cand_norm = cand.strip().lower()
            if cand_norm in norm_headers:
                # return the original header name exactly as in the CSV
                return headers[norm_headers.index(cand_norm)]
        return None

    added, updated, skipped = 0, 0, 0

    with open(csv_path, newline="", encoding="utf-8-sig") as f:
        reader = _csv.DictReader(f)
        headers = reader.fieldnames or []
        logger.info("UpdateCases: CSV headers = %s", headers)

        # Try multiple possible names for important columns
        case_col   = pick_col(headers, ["Case #", "Case Number", "Case", "Case No.", "Case No"])
        filing_col = pick_col(headers, ["Filing Date", "Filing", "Filed"])
        style_col  = pick_col(headers, ["Case Name", "Style", "Case Style"])

        if not case_col:
            msg = f"Could not find case number column in CSV headers: {headers}"
            logger.error("UpdateCases: %s", msg)
            # fail cleanly so you see the error on the progress page
            raise HTTPException(status_code=400, detail=msg)

        for row in reader:
            cn_raw = row.get(case_col, "")
            cn = norm_case(cn_raw)
            if not cn:
                skipped += 1
                continue

            case = db.query(Case).filter(Case.case_number == cn).one_or_none()
            if not case:
                case = Case(case_number=cn)
                if filing_col:
                    case.filing_datetime = row.get(filing_col, "") or None
                if style_col:
                    case.style = row.get(style_col, "") or None
                db.add(case)
                db.flush()
                added += 1
            else:
                # only fill blanks to avoid overwriting your manual edits
                if not case.filing_datetime and filing_col:
                    case.filing_datetime = row.get(filing_col, "") or None
                if not case.style and style_col:
                    case.style = row.get(style_col, "") or None
                updated += 1

            # defendants: add only new names
            dnames = [
                row.get(k, "")
                for k in row.keys()
                if k and k.strip().lower().startswith("defendant")
            ]
            dnames = [d.strip() for d in dnames if d and d.strip()]

            existing = {d.name for d in (case.defendants or [])}
            for name in dnames:
                if name not in existing:
                    db.add(Defendant(case_id=case.id, name=name))

        db.commit()

    logger.info(
        "UpdateCases: Import complete. Added=%s Updated=%s Skipped=%s",
        added, updated, skipped,
    )
    return added, updated, skipped


# ======================================================================
# Routes: home, list, detail
# ======================================================================
@app.get("/", response_class=HTMLResponse)
def home():
    return RedirectResponse(url="/cases", status_code=303)


@app.get("/cases/new", response_class=HTMLResponse)
def new_case_form(request: Request):
    return templates.TemplateResponse("cases_new.html", {"request": request, "error": None})


@app.post("/cases/create")
def create_case(
    request: Request,
    case_number: str = Form(...),
    filing_date: Optional[str] = Form(None),   # "YYYY-MM-DD" or blank
    style: Optional[str] = Form(None),
    parcel_id: Optional[str] = Form(None),
    address_override: Optional[str] = Form(None),
    arv: Optional[str] = Form(None),
    rehab: Optional[str] = Form(None),
    closing_costs: Optional[str] = Form(None),
    defendants_csv: Optional[str] = Form(None),
    db: Session = Depends(get_db),
):
    # helpers
    def _num(x: Optional[str]) -> Optional[float]:
        if x is None:
            return None
        s = x.strip()
        if not s:
            return None
        try:
            return float(s.replace(",", ""))
        except ValueError:
            return None

    cn = (case_number or "").strip()
    if not cn:
        return templates.TemplateResponse("cases_new.html", {"request": request, "error": "Case # is required."})

    # Duplicate check
    exists = db.query(Case).filter(Case.case_number == cn).one_or_none()
    if exists:
        return templates.TemplateResponse("cases_new.html", {"request": request, "error": f"Case {cn} already exists (ID {exists.id})."})

    # Create case
    case = Case(case_number=cn)
    if filing_date:
        case.filing_datetime = filing_date.strip()
    if style:
        case.style = style.strip()
    if parcel_id:
        case.parcel_id = parcel_id.strip()
    if address_override:
        case.address_override = address_override.strip()

    # only set if provided
    v_arv = _num(arv)
    v_rehab = _num(rehab)
    v_cc = _num(closing_costs)
    if v_arv is not None:
        case.arv = v_arv
    if v_rehab is not None:
        case.rehab = v_rehab
    if v_cc is not None:
        case.closing_costs = v_cc

    db.add(case)
    db.flush()

    if defendants_csv:
        raw = defendants_csv.replace("\r", "\n")
        parts = [p.strip() for chunk in raw.split("\n") for p in chunk.split(",")]
        seen = set()
        for name in parts:
            if name and name not in seen:
                seen.add(name)
                db.add(Defendant(case_id=case.id, name=name))

    db.commit()
    return RedirectResponse(url=f"/cases/{case.id}", status_code=303)


@app.get("/cases/{case_id}", response_class=HTMLResponse)
def case_detail(request: Request, case_id: int, db: Session = Depends(get_db)):
    getter = getattr(db, "get", None)
    if callable(getter):
        case = db.get(Case, case_id)
    else:
        case = db.query(Case).get(case_id)  # type: ignore[call-arg]

    if not case:
        raise HTTPException(status_code=404, detail="Case not found")

    notes = (
        db.query(Note)
        .filter(Note.case_id == case_id)
        .order_by(Note.id.desc())
        .all()
    )
    try:
        setattr(case, "notes", notes)
    except Exception:
        pass

    # Load skip trace from normalized table (if present)
    skip_trace = load_skiptrace_for_case(case_id)
    skip_trace_error = None

    offer = compute_offer_70(case.arv or 0, case.rehab or 0, case.closing_costs or 0)

    return templates.TemplateResponse(
        "case_detail.html",
        {
            "request": request,
            "case": case,
            "offer_70": offer,
            "active_parcel_id": case.parcel_id,
            "notes": notes,
            "skip_trace": skip_trace,
            "skip_trace_error": skip_trace_error,
        },
    )


# NEW: Skip trace endpoint using BatchData
@app.post("/cases/{case_id}/skip-trace", response_class=HTMLResponse)
def skip_trace_case(request: Request, case_id: int, db: Session = Depends(get_db)):
    # Load case
    getter = getattr(db, "get", None)
    if callable(getter):
        case = db.get(Case, case_id)
    else:
        case = db.query(Case).get(case_id)  # type: ignore[call-arg]

    if not case:
        raise HTTPException(status_code=404, detail="Case not found")

    # Notes
    notes = (
        db.query(Note)
        .filter(Note.case_id == case_id)
        .order_by(Note.id.desc())
        .all()
    )

    skip_trace: Optional[dict] = None
    skip_trace_error: Optional[str] = None

    # 1) Try table-based cache first
    skip_trace = load_skiptrace_for_case(case_id)

    # 2) If no stored data, call BatchData and persist normalized row
    if skip_trace is None:
        street, city, state, postal_code = get_case_address_components(case)

        try:
            skip_trace = batchdata_skip_trace(street, city, state, postal_code)
            # Save normalized into case_skiptrace
            save_skiptrace_row(case.id, skip_trace)
            # (optional) also keep JSON cache if you still want it:
            # set_cached_skip_trace(case_id, skip_trace)
        except HTTPException as exc:
            detail = exc.detail
            skip_trace_error = detail if isinstance(detail, str) else str(detail)
        except Exception as exc:
            skip_trace_error = f"Unexpected error during skip trace: {exc}"

    offer = compute_offer_70(case.arv or 0, case.rehab or 0, case.closing_costs or 0)

    return templates.TemplateResponse(
        "case_detail.html",
        {
            "request": request,
            "case": case,
            "offer_70": offer,
            "active_parcel_id": case.parcel_id,
            "notes": notes,
            "skip_trace": skip_trace,
            "skip_trace_error": skip_trace_error,
        },
    )


# ======================================================================
# SSE progress endpoints + update job orchestration
# ======================================================================
@app.get("/update_progress/{job_id}", response_class=HTMLResponse)
async def update_progress_page(request: Request, job_id: str):
    html = f"""
<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Updating cases…</title>
  <style>
    body {{ font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; margin: 0; }}
    .wrap {{ max-width: 900px; margin: 24px auto; padding: 0 16px; }}
    .spinner {{
      position: fixed; inset: 0; display: flex; align-items: center; justify-content: center;
      background: rgba(0,0,0,0.5); color: #fff; z-index: 9999; font-size: 18px;
    }}
    .log {{
      background: #0b0b0b; color: #c9f4ff; padding: 16px; border-radius: 12px;
      font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace;
      white-space: pre-wrap; line-height: 1.35; max-height: 60vh; overflow: auto;
      box-shadow: 0 10px 30px rgba(0,0,0,0.2);
    }}
    .muted {{ color: #9aa7b1; font-size: 12px; margin-top: 8px; }}
    .hide {{ display:none; }}
    .pill {{ display:inline-block; padding:4px 10px; border-radius: 999px; background:#eef2ff; color:#3730a3; font-size:12px; }}
  </style>
</head>
<body>
  <div id="spinner" class="spinner">Updating cases… Please don’t navigate away.</div>
  <div class="wrap">
    <h1>Update in progress <span class="pill">live log</span></h1>
    <div id="log" class="log"></div>
    <div id="hint" class="muted">This log will auto-scroll. You’ll be redirected when finished.</div>
  </div>

<script>
  const logEl = document.getElementById('log');
  const spinner = document.getElementById('spinner');
  const es = new EventSource('/events/{job_id}');
  function appendLine(s) {{
    logEl.textContent += s + '\\n';
    logEl.scrollTop = logEl.scrollHeight;
  }}
  es.onmessage = (e) => {{
    const t = e.data || '';
    if (t.startsWith('[done]')) {{
      spinner.classList.add('hide');
      es.close();
      setTimeout(() => window.location.href = '/cases', 10000);
    }} else {{
      if (t.trim().length) {{
        appendLine(t);
        spinner.classList.add('hide');
      }}
    }}
  }};
  es.onerror = () => {{
    appendLine('[connection error] retrying…');
  }};
</script>
</body>
</html>
"""
    return HTMLResponse(content=html)


@app.get("/events/{job_id}")
async def events(job_id: str):
    async def event_generator():
        # initial hello to open the stream promptly
        yield ": connected\n\n"
        while True:
            try:
                async for line in progress_bus.stream(job_id):
                    yield f"data: {line}\n\n"
            except Exception:
                # brief heartbeat to keep connection alive
                yield ": heartbeat\n\n"
                await asyncio.sleep(5)
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"},
    )


@app.get("/import", response_class=HTMLResponse)
def update_case_list_page(request: Request):
    # Renders the form with the "Days to scrape" selector that posts to /update_cases
    return templates.TemplateResponse("import.html", {"request": request})


@app.post("/update_cases")
async def update_cases(
    request: Request,
    since_days: int = Form(7),
):
    """
    Starts an async job that:
      1) Runs the foreclosure scraper with --since-days
      2) Imports the resulting CSV with upsert-by-case_number (no dupes)
    Immediately redirects to a live log page.
    """
    job_id = uuid.uuid4().hex
    # prime the log so the progress page shows something immediately
    await progress_bus.publish(job_id, f"Queued job {job_id}…")
    asyncio.create_task(_update_cases_job(job_id, since_days))
    return RedirectResponse(url=f"/update_progress/{job_id}", status_code=303)


async def _update_cases_job(job_id: str, since_days: int):
    try:
        await progress_bus.publish(job_id, f"Starting update job {job_id} (since_days={since_days})")

        # 1) Run the scraper to produce CSV
        scraper_script = _find_scraper_script()
        tmpdir = tempfile.mkdtemp(prefix="pasco_update_")
        csv_out = os.path.join(tmpdir, "pasco_foreclosures.csv")

        cmd = [
            sys.executable,
            str(scraper_script),
            "--since-days", str(max(0, int(since_days))),
            "--out", csv_out,  # your integrated scraper should accept --out
        ]
        await progress_bus.publish(job_id, "Launching scraper: " + " ".join(cmd))
        rc = await run_command_with_logs(cmd, job_id)
        if rc != 0 or not os.path.exists(csv_out):
            await progress_bus.publish(job_id, "[error] Scraper failed or CSV not found.]")
            await progress_bus.publish(job_id, "[done] exit_code=1")
            return

        await progress_bus.publish(job_id, "Scraper finished. Importing CSV via tools/import_pasco_csv.py…")

        # 2) Import CSV using the same logic as the CLI tool
        def _run_import():
            import_pasco_csv_main(csv_out)

        loop = asyncio.get_running_loop()
        await loop.run_in_executor(None, _run_import)

        await progress_bus.publish(job_id, "Import complete via tools/import_pasco_csv.py")
        await progress_bus.publish(job_id, "[done] exit_code=0")

    except Exception as e:
        # Surface the exception in the log and signal completion
        await progress_bus.publish(job_id, f"[exception] {e}")
        await progress_bus.publish(job_id, "[done] exit_code=1")


# ======================================================================
# PDF Report for a Case (summary + attached documents)
# ======================================================================
@app.get("/cases/{case_id}/report")
def case_report(case_id: int, db: Session = Depends(get_db)):
    # Fetch case
    getter = getattr(db, "get", None)
    if callable(getter):
        case = db.get(Case, case_id)
    else:
        case = db.query(Case).get(case_id)  # type: ignore[call-arg]

    if not case:
        raise HTTPException(status_code=404, detail="Case not found")

    # Load any saved skip-trace for this case (normalized table)
    skip_trace = load_skiptrace_for_case(case_id)

    # -----------------------------
    # 1) Build summary/cover page
    # -----------------------------
    summary_buf = io.BytesIO()
    c = canvas.Canvas(summary_buf, pagesize=letter)
    width, height = letter

    y = height - 50

    def line(text: str, dy: int = 14, bold: bool = False):
        """
        Draw a single line of text with optional bold and vertical spacing.
        """
        nonlocal y
        if y < 60:  # basic page-break safety
            c.showPage()
            y_new = height - 50
        else:
            y_new = y
        if bold:
            c.setFont("Helvetica-Bold", 11)
        else:
            c.setFont("Helvetica", 10)
        c.drawString(50, y_new, text)
        y = y_new - dy

    def section_title(text: str):
        """
        Draw a clear section header.
        """
        nonlocal y
        if y < 70:
            c.showPage()
            y = height - 50
        c.setFont("Helvetica-Bold", 12)
        c.drawString(50, y, text)
        # underline-ish rule
        c.setLineWidth(0.4)
        c.line(50, y - 3, width - 50, y - 3)
        y -= 20

    def _fmt_money(raw) -> str:
        # Accept str, int, float, or None and return a currency-formatted string when possible
        if raw is None:
            return ""
        if isinstance(raw, (int, float)):
            try:
                return f"${float(raw):,.2f}"
            except Exception:
                return str(raw)
        raw_str = str(raw).strip()
        if not raw_str:
            return ""
        cleaned = raw_str.replace("$", "").replace(",", "")
        try:
            val = float(cleaned)
            return f"${val:,.2f}"
        except Exception:
            return raw_str

    def _fmt_phone(num) -> str:
        s = str(num or "").strip()
        digits = "".join(ch for ch in s if ch.isdigit())
        if len(digits) == 10:
            return f"({digits[0:3]}) {digits[3:6]}-{digits[6:10]}"
        return s

    def _yn_icon(val) -> str:
        if val is None:
            return ""
        return "✓" if bool(val) else "✗"

    # ----- Header -----
    c.setFont("Helvetica-Bold", 18)
    c.drawString(50, y, "JSN Holdings – Case Report")
    y -= 26

    c.setFont("Helvetica", 10)
    today_str = _dt.datetime.now().strftime("%m/%d/%Y")
    c.drawRightString(width - 50, y + 6, f"Generated: {today_str}")
    y -= 8

    # Case identifier
    section_title(f"Case {case.case_number or ''}")

    # ----- Property / Case Info -----
    addr = (getattr(case, "address_override", None) or getattr(case, "address", "") or "").strip()
    parcel = case.parcel_id or ""
    filing = case.filing_datetime or ""

    line(f"Address: {addr}")
    line(f"Parcel ID: {parcel} | Filing Date: {filing}")
    style = case.style or ""
    if style:
        line(f"Style / Case Name: {style}")

    # ----- Financials / Deal Summary -----
    section_title("Deal Summary")

    arv_val = getattr(case, "arv", "") or ""
    rehab_val = getattr(case, "rehab", "") or ""
    closing_val = getattr(case, "closing_costs", "") or ""

    line(f"ARV: {_fmt_money(arv_val)}")
    line(f"Rehab: {_fmt_money(rehab_val)}")
    line(f"Closing Costs: {_fmt_money(closing_val)}")

    # JSN deal calculator
    def _to_float(val) -> float:
        if isinstance(val, (int, float)):
            return float(val)
        s = str(val or "").replace("$", "").replace(",", "").strip()
        if not s:
            return 0.0
        try:
            return float(s)
        except Exception:
            return 0.0

    arv_num = _to_float(arv_val)
    rehab_num = _to_float(rehab_val)
    closing_num = _to_float(closing_val)

    try:
        from app.utils import compute_offer_70 as _compute_offer_70
    except Exception:
        def _compute_offer_70(arv, rehab, closing):
            return max(0.0, 0.7 * (arv or 0.0) - (rehab or 0.0) - (closing or 0.0))

    offer_70 = _compute_offer_70(arv_num, rehab_num, closing_num)
    offer_display = _fmt_money(offer_70)

    # Sum all liens for seller-in-hand calc
    total_liens_for_calc = 0.0
    liens_raw_for_calc = getattr(case, "outstanding_liens", "[]") or "[]"
    try:
        liens_for_calc = json.loads(liens_raw_for_calc)
    except Exception:
        liens_for_calc = []
    if isinstance(liens_for_calc, list):
        for l in liens_for_calc:
            if isinstance(l, dict):
                amt_raw2 = (l.get("amount") or "").strip()
            else:
                amt_raw2 = ""
            if not amt_raw2:
                continue
            cleaned2 = amt_raw2.replace("$", "").replace(",", "")
            try:
                total_liens_for_calc += float(cleaned2)
            except Exception:
                continue
    seller_cash = max(0.0, float(offer_70) - float(total_liens_for_calc))
    seller_display = _fmt_money(seller_cash)

    line(f"JSN Max Offer: {offer_display}", bold=True)
    line(f"Max Seller in Hand Cash (after liens): {seller_display}", bold=True)

    # ----- Outstanding Liens -----
    section_title("Outstanding Liens")

    liens_raw = getattr(case, "outstanding_liens", "[]") or "[]"
    try:
        liens = json.loads(liens_raw)
    except Exception:
        liens = []

    if isinstance(liens, list) and liens:
        for idx, l in enumerate(liens):
            if isinstance(l, dict):
                desc = (l.get("description") or "").strip()
                amt_raw = (l.get("amount") or "").strip()
            else:
                desc = str(l).strip()
                amt_raw = ""

            if not desc:
                desc = "Foreclosing Mortgage" if idx == 0 else "Lien"

            amt_str = _fmt_money(amt_raw) if amt_raw else ""
            if amt_str:
                line(f"• {desc} – {amt_str}")
            else:
                line(f"• {desc}")
    else:
        line("No recorded liens on file.")

    # ----- Defendants -----
    section_title("Defendants")

    defendants = getattr(case, "defendants", []) or []
    clean_defendants = []
    for d in defendants:
        name = (getattr(d, "name", "") or "").strip()
        if not name:
            continue
        lower = name.lower()
        if lower in {"nan", "none", "nil"}:
            continue
        clean_defendants.append(name)

    if clean_defendants:
        for name in clean_defendants:
            line(f"• {name}")
    else:
        line("No defendants recorded.")

    # ----- Skip Trace -----
    section_title("Skip Trace (Owner & Contact Details)")

    if skip_trace and isinstance(skip_trace, dict) and skip_trace.get("results"):
        res = skip_trace["results"][0]
        
        persons = res.get("persons") or []
        if persons:
            # Show primary owner first
            for idx, p in enumerate(persons):
                if idx == 0:
                    owner_label = "Primary Owner"
                else:
                    owner_label = f"Additional Contact {idx}"
                full_name = (p.get("full_name") or "").strip()
                if full_name:
                    line(f"{owner_label}: {full_name}", bold=True)
                phones = p.get("phones") or []
                emails = p.get("emails") or []

                if phones:
                    line("Phones:")
                    for ph in phones:
                        num = _fmt_phone(ph.get("number"))
                        pieces = [num]
                        if ph.get("type"):
                            pieces.append(f"({ph['type']})")
                        if ph.get("score") is not None:
                            pieces.append(f"Score: {ph['score']}")
                        if ph.get("last_reported"):
                            pieces.append(f"Last: {ph['last_reported']}")
                        tested_icon = _yn_icon(ph.get("tested"))
                        if tested_icon:
                            pieces.append(f"Tested: {tested_icon}")
                        reachable_icon = _yn_icon(ph.get("reachable"))
                        if reachable_icon:
                            pieces.append(f"Reachable: {reachable_icon}")
                        dnc_icon = _yn_icon(ph.get("dnc"))
                        if dnc_icon:
                            pieces.append(f"DNC: {dnc_icon}")

                        line("   - " + " | ".join(pieces))

                if emails:
                    line("Emails:")
                    for em in emails:
                        addr = em.get("email") if isinstance(em, dict) else str(em)
                        tested_icon = _yn_icon(em.get("tested") if isinstance(em, dict) else None)
                        parts = [addr]
                        if tested_icon:
                            parts.append(f"Tested: {tested_icon}")
                        line("   - " + " | ".join(parts))
        else:
            line("No contact persons returned from skip trace.")
    else:
        line("No skip trace data on file for this case.")

    # ----- Mortgage Info (snippet from uploaded mortgage PDF if present) -----
    

    # ----- Notes -----
    section_title("Notes")

    notes = getattr(case, "notes", None)
    if notes is None:
        notes = (
            db.query(Note)
            .filter(Note.case_id == case_id)
            .order_by(Note.id.desc())
            .all()
        )

    if notes:
        for n in notes:
            content = (getattr(n, "content", "") or "").strip()
            if not content:
                continue
            if len(content) > 200:
                content = content[:197] + "..."
            created = getattr(n, "created_at", "") or ""
            if created:
                line(f"• [{created}] {content}")
            else:
                line(f"• {content}")
    else:
        line("No notes recorded.")

    # ----- Attached Documents -----
    section_title("Attached Documents")

    attachments: list[tuple[str, str]] = []

    def add_doc(label: str, attr: str):
        rel = getattr(case, attr, None)
        if rel:
            attachments.append((label, rel))

    add_doc("Verified Complaint", "verified_complaint_path")
    add_doc("Value Calculation", "value_calc_path")
    add_doc("Mortgage", "mortgage_path")
    add_doc("Current Deed", "current_deed_path")
    add_doc("Previous Deed", "previous_deed_path")

    if attachments:
        for label, rel in attachments:
            line(f"• {label}: {rel}")
    else:
        line("No documents uploaded.")

    c.showPage()
    c.save()
    summary_buf.seek(0)

    # -----------------------------
    # 2) Merge summary + attachments
    # -----------------------------
    writer = PdfWriter()

    summary_reader = PdfReader(summary_buf)
    for page in summary_reader.pages:
        writer.add_page(page)

    for label, rel in attachments:
        abs_path = UPLOAD_ROOT / rel
        if abs_path.exists():
            try:
                reader = PdfReader(str(abs_path))
                for page in reader.pages:
                    writer.add_page(page)
            except Exception:
                continue

    out_buf = io.BytesIO()
    writer.write(out_buf)
    out_buf.seek(0)

    filename = f"case_{case.id}_report.pdf"
    return StreamingResponse(
        out_buf,
        media_type="application/pdf",
        headers={"Content-Disposition": f'attachment; filename=\"{filename}\"'},
    )



# ======================================================================
# Case editing / uploads / notes
# ======================================================================
@app.post("/cases/{case_id}/update")
def case_update(
    case_id: int,
    parcel_id: Optional[str] = Form(None),
    address_override: Optional[str] = Form(None),
    arv: Optional[str] = Form(None),
    rehab: Optional[str] = Form(None),
    closing_costs: Optional[str] = Form(None),
    db: Session = Depends(get_db),
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)

    if parcel_id is not None:
        case.parcel_id = (parcel_id or "").strip()
    if address_override is not None:
        case.address_override = (address_override or "").strip()

    def _num(x: Optional[str]) -> Optional[float]:
        if x is None:
            return None
        s = x.strip()
        if not s:
            return None
        try:
            return float(s.replace(",", ""))
        except ValueError:
            return None

    v_arv = _num(arv)
    v_rehab = _num(rehab)
    v_cc = _num(closing_costs)

    if v_arv is not None:
        case.arv = v_arv
    if v_rehab is not None:
        case.rehab = v_rehab
    if v_cc is not None:
        case.closing_costs = v_cc

    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)



@app.post("/cases/{case_id}/upload/verified")
async def upload_verified(
    case_id: int, verified_complaint: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Verified_Complaint.pdf"
    with open(dest, "wb") as f:
        f.write(await verified_complaint.read())
    case.verified_complaint_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/upload/value_calc")
async def upload_value_calc(
    case_id: int, value_calc: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Value_Calculation.pdf"
    with open(dest, "wb") as f:
        f.write(await value_calc.read())
    case.value_calc_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/upload/mortgage")
async def upload_mortgage(
    case_id: int, mortgage: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Mortgage.pdf"
    with open(dest, "wb") as f:
        f.write(await mortgage.read())
    case.mortgage_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/upload/current-deed")
async def upload_current_deed(
    case_id: int, current_deed: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Current_Deed.pdf"
    with open(dest, "wb") as f:
        f.write(await current_deed.read())
    case.current_deed_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/upload/previous-deed")
async def upload_previous_deed(
    case_id: int, previous_deed: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Previous_Deed.pdf"
    with open(dest, "wb") as f:
        f.write(await previous_deed.read())
    case.previous_deed_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/notes/add")
def add_note(case_id: int, content: str = Form(...), db: Session = Depends(get_db)):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        raise HTTPException(status_code=404, detail="Case not found")
    content = (content or "").strip()
    if not content:
        return RedirectResponse(url=f"/cases/{case_id}", status_code=303)
    ts = _dt.datetime.now().strftime("%Y-%m-%d %H:%M")
    note = Note(case_id=case_id, content=content, created_at=ts)
    db.add(note)
    db.commit()
    return RedirectResponse(url=f"/cases/{case_id}", status_code=303)


# ======================================================================
# NEW: Outstanding Liens API
# ======================================================================
@app.get("/cases/{case_id}/liens", response_model=list[OutstandingLien])
def get_outstanding_liens(case_id: int, db: Session = Depends(get_db)):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        raise HTTPException(status_code=404, detail="Case not found")
    return case.get_outstanding_liens()


@app.post("/cases/{case_id}/liens", response_model=list[OutstandingLien])
def save_outstanding_liens(case_id: int, payload: OutstandingLiensUpdate, db: Session = Depends(get_db)):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        raise HTTPException(status_code=404, detail="Case not found")
    case.set_outstanding_liens([l.dict() for l in payload.outstanding_liens])
    db.add(case)
    db.commit()
    db.refresh(case)
    return case.get_outstanding_liens()


# ======================================================================
# Simple health check
# ======================================================================
@app.get("/healthz")
def healthz():
    return {"status": "ok"}


# =====================
# START: Added in v1.05+ for Archive + Export + Search
# =====================
@app.on_event("startup")
def _ensure_archived_column():
    try:
        inspector = inspect(engine)
        cols = {c["name"] for c in inspector.get_columns("cases")}
        if "archived" not in cols:
            with engine.begin() as conn:
                conn.exec_driver_sql("ALTER TABLE cases ADD COLUMN archived INTEGER DEFAULT 0")
    except Exception as e:
        logger.warning("Could not ensure 'archived' column: %s", e)


@app.get("/cases", response_class=HTMLResponse)
def cases_list(
    request: Request,
    page: int = Query(1),
    show_archived: int = Query(0),
    case: str = Query("", alias="case"),
    db: Session = Depends(get_db),
):
    qry = db.query(Case)

    if not show_archived:
        qry = qry.filter(text("(archived IS NULL OR archived = 0)"))

    if case:
        qry = qry.filter(Case.case_number.contains(case))

    page_size = 10
    total = qry.count()
    pages = (total + page_size - 1) // page_size
    offset = (page - 1) * page_size
    cases = (
        qry.order_by(Case.filing_datetime.desc())
           .offset(offset)
           .limit(page_size)
           .all()
    )
    pagination = {"page": page, "pages": pages, "total": total}
    return templates.TemplateResponse(
        "cases_list.html",
        {
            "request": request,
            "cases": cases,
            "pagination": pagination,
            "show_archived": bool(show_archived),
            "search_query": case,
        },
    )


@app.post("/cases/archive")
def archive_cases(
    request: Request,
    ids: List[int] = Form(default=[]),
    show_archived: int = Form(0),
    db: Session = Depends(get_db),
):
    if ids:
        db.execute(
            text("UPDATE cases SET archived = 1 WHERE id IN :ids")
            .bindparams(bindparam("ids", expanding=True)),
            {"ids": ids},
        )
        db.commit()
    return RedirectResponse(url="/cases?show_archived=0&page=1", status_code=303)


@app.post("/cases/export")
def export_cases(
    request: Request,
    ids: List[int] = Form(default=[]),
    show_archived: int = Form(0),
    case: str = Form("", alias="case"),
    db: Session = Depends(get_db),
):
    qry = db.query(Case)

    if not show_archived:
        qry = qry.filter(text("(archived IS NULL OR archived = 0)"))

    if case:
        qry = qry.filter(Case.case_number.contains(case))
    if ids:
        qry = qry.filter(Case.id.in_(ids))

    header = [
        "id",
        "case_number",
        "filing_datetime",
        "style",
        "address",
        "arv",
        "closing_costs",
        "current_deed_path",
        "defendants",
        "mortgage_path",
        "notes_count",
        "outstanding_liens",
        "parcel_id",
        "previous_deed_path",
        "rehab",
        "value_calc_path",
        "verified_complaint_path",
    ]

    buf = io.StringIO()
    writer = _csv.writer(buf, lineterminator="\n")
    writer.writerow(header)

    rows = qry.order_by(Case.filing_datetime.desc()).all()
    for c in rows:
        try:
            defendants = [d.name for d in c.defendants] if getattr(c, "defendants", None) else []
        except Exception:
            defendants = []
        try:
            notes_count = len(c.notes) if getattr(c, "notes", None) else 0
        except Exception:
            notes_count = 0

        address = (getattr(c, "address_override", None) or getattr(c, "address", "") or "").strip()
        outstanding = getattr(c, "outstanding_liens", None) or "[]"

        writer.writerow([
            c.id,
            c.case_number or "",
            c.filing_datetime or "",
            c.style or "",
            address,
            getattr(c, "arv", "") or "",
            getattr(c, "closing_costs", "") or "",
            getattr(c, "current_deed_path", "") or "",
            json.dumps(defendants),
            getattr(c, "mortgage_path", "") or "",
            notes_count,
            outstanding,
            c.parcel_id or "",
            getattr(c, "previous_deed_path", "") or "",
            getattr(c, "rehab", "") or "",
            getattr(c, "value_calc_path", "") or "",
            getattr(c, "verified_complaint_path", "") or "",
        ])

    buf.seek(0)
    filename = f"cases_export_{_dt.datetime.now().strftime('%Y-%m-%d')}.csv"
    return StreamingResponse(
        iter([buf.getvalue()]),
        media_type="text/csv",
        headers={"Content-Disposition": f'attachment; filename=\"{filename}\"'},
    )


# =====================
# v1.07 Additions — Unarchive + AJAX endpoints
# =====================
@app.on_event("startup")
def _ensure_archived_column_v107():
    try:
        inspector = inspect(engine)
        cols = {c["name"] for c in inspector.get_columns("cases")}
        if "archived" not in cols:
            with engine.begin() as conn:
                conn.exec_driver_sql("ALTER TABLE cases ADD COLUMN archived INTEGER DEFAULT 0")
    except Exception as e:
        logger.warning("Could not ensure 'archived' column: %s", e)


@app.post("/cases/unarchive")
def unarchive_cases(
    request: Request,
    ids: List[int] = Form(default=[]),
    show_archived: int = Form(0),
    db: Session = Depends(get_db),
):
    if ids:
        db.execute(
            text("UPDATE cases SET archived = 0 WHERE id IN :ids")
            .bindparams(bindparam("ids", expanding=True)),
            {"ids": ids},
        )
        db.commit()
    return RedirectResponse(url=f"/cases?show_archived={show_archived}&page=1", status_code=303)


@app.post("/cases/archive_async")
def archive_cases_async(
    ids: List[int] = Form(default=[]),
    db: Session = Depends(get_db),
):
    if not ids:
        return {"ok": True, "updated": 0}
    db.execute(
        text("UPDATE cases SET archived = 1 WHERE id IN :ids")
        .bindparams(bindparam("ids", expanding=True)),
        {"ids": ids},
    )
    db.commit()
    return {"ok": True, "updated": len(ids)}


@app.post("/cases/unarchive_async")
def unarchive_cases_async(
    ids: List[int] = Form(default=[]),
    db: Session = Depends(get_db),
):
    if not ids:
        return {"ok": True, "updated": 0}
    db.execute(
        text("UPDATE cases SET archived = 0 WHERE id IN :ids")
        .bindparams(bindparam("ids", expanding=True)),
        {"ids": ids},
    )
    db.commit()
    return {"ok": True, "updated": len(ids)}


# =====================
# Manual Add Case (v1.08)
# =====================
# (placeholder for future additions)
