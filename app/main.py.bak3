from __future__ import annotations

# ---- Windows event loop fix for asyncio subprocess ----
import sys as _sys
import asyncio as _asyncio
if _sys.platform == "win32":
    try:
        _asyncio.set_event_loop_policy(_asyncio.WindowsProactorEventLoopPolicy())
    except Exception:
        pass

# ---------------- Stdlib ----------------
import logging
import asyncio
import csv as _csv
import datetime as _dt
import os
import sys
import tempfile
import uuid
import io, json
from pathlib import Path
from typing import List, Optional
from PyPDF2 import PdfReader, PdfWriter
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from tools.import_pasco_csv import main as import_pasco_csv_main
import requests  # for BatchData skip trace calls

# ---------------- FastAPI / Responses ----------------
from fastapi import (
    FastAPI,
    Request,
    Depends,
    UploadFile,
    File,
    Form,
    Query,
    HTTPException,
)
from fastapi.responses import HTMLResponse, RedirectResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates

# ---------------- DB / ORM ----------------
from sqlalchemy.orm import Session
from sqlalchemy import inspect, text, bindparam
from sqlalchemy.exc import OperationalError

# ---------------- App imports ----------------
from app.services.progress_bus import progress_bus
from app.settings import settings
from .database import Base, engine, SessionLocal
from .models import Case, Defendant, Docket, Note
from .utils import ensure_case_folder, compute_offer_70
from .schemas import OutstandingLien, OutstandingLiensUpdate
from dotenv import dotenv_values

# Resolve project root (adjust if your .env lives somewhere else)
BASE_DIR = Path(__file__).resolve().parent.parent  # e.g. C:\pascowebapp
ENV_PATH = BASE_DIR / ".env"

# Read ONLY from the .env file
env_values = dotenv_values(ENV_PATH)

BATCHDATA_API_KEY = env_values.get("BATCHDATA_API_KEY")

print("DEBUG: .env path =", ENV_PATH)
print("DEBUG: BATCHDATA_API_KEY from .env =", BATCHDATA_API_KEY)

# ======================================================================
# App bootstrap
# ======================================================================
app = FastAPI(title="JSN Holdings Foreclosure Manager")
logger = logging.getLogger("pascowebapp")
logger.setLevel(logging.INFO)

BASE_DIR = Path(__file__).resolve().parent.parent
STATIC_DIR = BASE_DIR / "app" / "static"
TEMPLATES_DIR = BASE_DIR / "app" / "templates"
UPLOAD_ROOT = BASE_DIR / "uploads"
UPLOAD_ROOT.mkdir(parents=True, exist_ok=True)

app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")
app.mount("/uploads", StaticFiles(directory=str(UPLOAD_ROOT)), name="uploads")

templates = Jinja2Templates(directory=str(TEMPLATES_DIR))

# ======================================================================
# Jinja filters / globals
# ======================================================================
def _currency(v):
    try:
        return "${:,.2f}".format(float(v))
    except Exception:
        return "$0.00"


def streetview_url(address: str) -> str:
    """
    Prefer Google Street View Static API if key present, else fall back
    to Static Map with a marker. Reads key from settings (env/.env).
    """
    if not address:
        return ""
    key = settings.GOOGLE_MAPS_API_KEY
    if key:
        base = "https://maps.googleapis.com/maps/api/streetview"
        return f"{base}?size=600x360&location={address}&key={key}"
    base = "https://maps.googleapis.com/maps/api/staticmap"
    return f"{base}?size=640x360&markers={address}"


def _parcel_to_property_card_param(parcel_id: str | None) -> Optional[str]:
    """
    Convert Pasco parcel formats to the property card 'parcel=' digits string.

    Example:
      Input:  '33-24-16-0260-00000-2540'
      Output: '1624330260000002540'
      (the first three 2-digit sets are mirrored: 33-24-16 -> 16 24 33)
    """
    if not parcel_id:
        return None

    s = parcel_id.strip().replace(" ", "")
    parts = s.split("-")

    # If it looks like the standard dash-delimited format with first three 2-digit parts
    if len(parts) >= 3 and all(len(p) == 2 for p in parts[:3]):
        reordered = parts[2] + parts[1] + parts[0] + "".join(parts[3:])
        digits = "".join(ch for ch in reordered if ch.isdigit())
        return digits or None

    # Fallback: digits only
    digits = "".join(ch for ch in s if ch.isdigit())
    return digits or None


def pasco_appraiser_url(parcel_id: str | None) -> Optional[str]:
    """Return the direct property card URL for a given parcel id."""
    param = _parcel_to_property_card_param(parcel_id)
    if not param:
        return None
    return f"https://search.pascopa.com/parcel.aspx?parcel={param}"


# ======================================================================
# BatchData Skip Trace config + helpers
# ======================================================================
BATCHDATA_API_KEY = env_values.get("BATCHDATA_API_KEY")
BATCHDATA_BASE_URL = "https://api.batchdata.com/api/v1"


def get_case_address_components(case) -> tuple[str, str, str, Optional[str]]:
    """
    Best-effort extraction of address components for BatchData skip trace.

    We try explicit fields first (if they exist on the model), otherwise
    we parse the combined address line into:
      street, city, state, postal_code
    """
    raw_addr = (getattr(case, "address_override", None) or getattr(case, "address", "") or "").strip()

    street = raw_addr
    city = ""
    state = "FL"
    postal_code: Optional[str] = None

    # If the ORM model has explicit fields, prefer them
    city_attr = getattr(case, "city", None)
    state_attr = getattr(case, "state", None)
    postal_attr = getattr(case, "postal_code", None) or getattr(case, "zip", None)

    if city_attr or state_attr or postal_attr:
        if city_attr:
            city = str(city_attr).strip()
        if state_attr:
            s = str(state_attr).strip()
            if s:
                state = s
        if postal_attr:
            postal_code = str(postal_attr).strip() or None
        if street:
            return street, city, state, postal_code

    # Fallback: parse from combined address string "123 Main St, City, ST 33556"
    if raw_addr and "," in raw_addr:
        parts = [p.strip() for p in raw_addr.split(",")]
        street = parts[0]
        if len(parts) >= 2:
            city = parts[1]
        if len(parts) >= 3:
            st_zip_parts = parts[2].split()
            if st_zip_parts:
                state = st_zip_parts[0]
            if len(st_zip_parts) > 1:
                postal_code = st_zip_parts[1]

    return street, city, state, postal_code


def batchdata_skip_trace(
    street: str,
    city: str,
    state: str,
    postal_code: Optional[str] = None,
) -> dict:
    """
    Call BatchData Property Skip Trace API and normalize into a structure
    the template can use, including detailed phone/email metadata.
    """
    if not BATCHDATA_API_KEY:
        raise HTTPException(status_code=500, detail="BatchData API key not configured")

    if not street or not city or not state:
        raise HTTPException(status_code=400, detail="Incomplete address for skip trace")

    url = f"{BATCHDATA_BASE_URL}/property/skip-trace"

    property_address: dict = {
        "street": street,
        "city": city,
        "state": state,
    }
    if postal_code:
        property_address["postalCode"] = postal_code

    payload = {
        "requests": [
            {
                "propertyAddress": property_address
            }
        ]
    }

    headers = {
        "Authorization": f"Bearer {BATCHDATA_API_KEY}",
        "Content-Type": "application/json",
    }

    # ==========================================================
    # FORCE RAW REQUEST LOGGING TO CONSOLE EVERY TIME
    # ==========================================================
    masked_headers = headers.copy()
    if "Authorization" in masked_headers:
        token = masked_headers["Authorization"]
        if len(token) > 20:
            masked_headers["Authorization"] = token[:20] + "...(masked)"

    print("\n\n=================== BATCHDATA REQUEST ===================")
    print("URL:", url)
    print("HEADERS:", masked_headers)
    print("PAYLOAD:", json.dumps(payload, indent=2))
    print("=========================================================\n")

    try:
        resp = requests.post(url, json=payload, headers=headers, timeout=20)
    except Exception as exc:
        print("\n\n=================== BATCHDATA ERROR =====================")
        print(exc)
        print("=========================================================\n")
        raise HTTPException(
            status_code=502,
            detail=f"Error calling BatchData API: {exc}"
        )

    print("\n\n================== BATCHDATA RESPONSE ====================")
    print("STATUS:", resp.status_code)
    print("TEXT:", resp.text[:5000])  # Print up to 5000 chars of response
    print("==========================================================\n")

    # --- Handle error status codes cleanly ---
    if resp.status_code >= 400:
        try:
            err_json = resp.json()
        except Exception:
            err_json = resp.text

        if resp.status_code == 403:
            raise HTTPException(
                status_code=403,
                detail=(
                    "BatchData: this API key does not have permission for the "
                    "Property Skip Trace endpoint. Check your BatchData plan or API key settings."
                ),
            )

        raise HTTPException(
            status_code=resp.status_code,
            detail=f"BatchData error: {err_json}",
        )

    # --- Parse success response ---
    try:
        data = resp.json()
    except Exception:
        raise HTTPException(
            status_code=502,
            detail=f"BatchData returned non-JSON response: {resp.text[:500]}",
        )

    out_results: list[dict] = []

    # data looks like:
    # { "status": {...}, "results": { "persons": [ ... ], "meta": {...} } }
    if isinstance(data, dict):
        res = data.get("results")
        if isinstance(res, dict):
            raw_results = [res]   # single logical result object that has "persons"
        elif isinstance(res, list):
            raw_results = res
        else:
            resp_obj = data.get("response")
            if isinstance(resp_obj, dict) and isinstance(resp_obj.get("results"), list):
                raw_results = resp_obj["results"]
            else:
                raise HTTPException(
                    status_code=502,
                    detail=f"Unexpected BatchData response structure (dict, no usable results): {data}",
                )
    elif isinstance(data, list):
        raw_results = data
    else:
        raise HTTPException(
            status_code=502,
            detail=f"Unexpected BatchData response type: {type(data).__name__} -> {data!r}",
        )

    for r in raw_results:
        if not isinstance(r, dict):
            continue

        persons_raw = r.get("persons") or []
        if not isinstance(persons_raw, list):
            persons_raw = []

        simple_persons: list[dict] = []
        property_addr_result: dict = r.get("propertyAddress") or {}

        for p in persons_raw:
            if not isinstance(p, dict):
                continue

            # Try to pull a property address from each person if we don't have it yet
            if not property_addr_result:
                pa = p.get("propertyAddress")
                if not isinstance(pa, dict):
                    prop = p.get("property") or {}
                    if isinstance(prop, dict):
                        pa = prop.get("address")
                if isinstance(pa, dict):
                    property_addr_result = pa

            # --- Name ---
            full_name = ""
            if isinstance(p.get("fullName"), str):
                full_name = p["fullName"]
            else:
                name_obj = p.get("name")
                if isinstance(name_obj, dict):
                    full_name = (
                        name_obj.get("full")
                        or " ".join(
                            x for x in [name_obj.get("first"), name_obj.get("last")] if x
                        )
                    )
                elif isinstance(name_obj, str):
                    full_name = name_obj

            # --- Emails (keep email + tested) ---
            emails: list[dict] = []
            emails_raw = p.get("emails") or []
            if isinstance(emails_raw, list):
                for e in emails_raw:
                    if isinstance(e, dict):
                        email = e.get("email")
                        tested = e.get("tested")
                        if email:
                            emails.append(
                                {
                                    "email": email,
                                    "tested": bool(tested) if isinstance(tested, bool) else None,
                                }
                            )
                    elif isinstance(e, str):
                        emails.append({"email": e, "tested": None})

            # --- Phones (keep full metadata) ---
            phones: list[dict] = []
            phones_raw = p.get("phoneNumbers") or []
            if isinstance(phones_raw, list):
                for ph in phones_raw:
                    if not isinstance(ph, dict):
                        continue
                    number = ph.get("number") or ph.get("phone")
                    if not number:
                        continue
                    phone_type = ph.get("type")
                    carrier = ph.get("carrier")
                    tested = ph.get("tested")
                    reachable = ph.get("reachable")
                    dnc = ph.get("dnc")
                    last_reported = ph.get("lastReportedDate")
                    score = ph.get("score")
                    phones.append(
                        {
                            "number": number,
                            "type": phone_type,
                            "carrier": carrier,
                            "tested": bool(tested) if isinstance(tested, bool) else None,
                            "reachable": bool(reachable) if isinstance(reachable, bool) else None,
                            "dnc": bool(dnc) if isinstance(dnc, bool) else None,
                            "last_reported": last_reported,
                            "score": score,
                        }
                    )

            simple_persons.append(
                {
                    "full_name": full_name,
                    "emails": emails,
                    "phones": phones,
                }
            )

        out_results.append(
            {
                "propertyAddress": property_addr_result or {},
                "persons": simple_persons,
            }
        )

    return {"results": out_results}

def batchdata_property_lookup_all_attributes(
    street: str,
    city: str,
    state: str,
    postal_code: Optional[str] = None,
) -> dict:
    """
    Call BatchData Property Lookup (all-attributes) endpoint and
    return the raw JSON payload.
    """
    if not BATCHDATA_API_KEY:
        raise HTTPException(status_code=500, detail="BatchData API key not configured")

    if not street or not city or not state:
        raise HTTPException(status_code=400, detail="Incomplete address for property lookup")

    url = f"{BATCHDATA_BASE_URL}/property/lookup/all-attributes"

    property_address: dict = {
        "street": street,
        "city": city,
        "state": state,
    }
    if postal_code:
        property_address["postalCode"] = postal_code

    payload = {
        "requests": [
            {
                "address": property_address
            }
        ]
    }

    headers = {
        "Authorization": f"Bearer {BATCHDATA_API_KEY}",
        "Content-Type": "application/json",
    }

    # Optional: basic logging so you can see the call
    masked_headers = headers.copy()
    if "Authorization" in masked_headers:
        token = masked_headers["Authorization"]
        if len(token) > 20:
            masked_headers["Authorization"] = token[:20] + "...(masked)"

    print("\n\n=================== BATCHDATA PROPERTY LOOKUP ===================")
    print("URL:", url)
    print("HEADERS:", masked_headers)
    print("PAYLOAD:", json.dumps(payload, indent=2))
    print("===============================================================\n")

    try:
        resp = requests.post(url, json=payload, headers=headers, timeout=20)
    except Exception as exc:
        print("BatchData property lookup ERROR:", exc)
        raise HTTPException(
            status_code=502,
            detail=f"Error calling BatchData Property Lookup API: {exc}",
        )

    print("\n\n================== BATCHDATA PROPERTY RESPONSE ==================")
    print("STATUS:", resp.status_code)
    print("TEXT:", resp.text[:5000])
    print("===============================================================\n")

    if resp.status_code >= 400:
        try:
            err_json = resp.json()
        except Exception:
            err_json = resp.text
        raise HTTPException(
            status_code=resp.status_code,
            detail=f"BatchData property lookup error: {err_json}",
        )

    try:
        return resp.json()
    except Exception:
        raise HTTPException(
            status_code=502,
            detail=f"BatchData returned non-JSON response: {resp.text[:500]}",
        )

def save_property_for_case(case_id: int, payload: dict) -> None:
    """
    Upsert a single row in case_property for this case_id.
    Maps the first property in payload['results']['properties'] into columns.
    """
    def b2i(val):
        if isinstance(val, bool):
            return 1 if val else 0
        return None

    results = (payload or {}).get("results") or {}
    props = results.get("properties") or []
    if not props:
        logger.warning("save_property_for_case: no 'properties' in payload for case %s", case_id)
        return

    prop = props[0]  # use first result
    address = prop.get("address") or {}
    demo = prop.get("demographics") or {}
    fc = prop.get("foreclosure") or {}
    deed_history = prop.get("deedHistory") or []

    ts = _dt.datetime.utcnow().isoformat()

    vals = {
        "case_id": case_id,
        "batch_property_id": prop.get("_id"),

        # Address
        "address_validity":    address.get("addressValidity"),
        "address_house_number": address.get("houseNumber"),
        "address_street":      address.get("street"),
        "address_city":        address.get("city"),
        "address_county":      address.get("county"),
        "address_state":       address.get("state"),
        "address_zip":         address.get("zip"),
        "address_zip_plus4":   address.get("zipPlus4"),
        "address_latitude":    address.get("latitude"),
        "address_longitude":   address.get("longitude"),
        "address_county_fips": address.get("countyFipsCode"),
        "address_hash":        address.get("hash"),

        # Demographics
        "demo_age":                   demo.get("age"),
        "demo_household_size":        demo.get("householdSize"),
        "demo_income":                demo.get("income"),
        "demo_net_worth":            demo.get("netWorth"),
        "demo_discretionary_income":  demo.get("discretionaryIncome"),
        "demo_homeowner_renter_code": demo.get("homeownerRenterCode"),
        "demo_homeowner_renter":      demo.get("homeownerRenter"),
        "demo_gender_code":           demo.get("genderCode"),
        "demo_gender":                demo.get("gender"),
        "demo_child_count":           demo.get("childCount"),
        "demo_has_children":          b2i(demo.get("hasChildren")),
        "demo_marital_status_code":   demo.get("maritalStatusCode"),
        "demo_marital_status":        demo.get("maritalStatus"),
        "demo_single_parent":         b2i(demo.get("singleParent")),
        "demo_religious":             b2i(demo.get("religious")),
        "demo_religious_affil_code":  demo.get("religiousAffiliationCode"),
        "demo_religious_affil":       demo.get("religiousAffiliation"),
        "demo_education_code":        demo.get("individualEducationCode"),
        "demo_education":             demo.get("individualEducation"),
        "demo_occupation":            demo.get("individualOccupation"),
        "demo_occupation_code":       demo.get("individualOccupationCode"),

        # Foreclosure
        "fc_status_code":       fc.get("statusCode"),
        "fc_status":            fc.get("status"),
        "fc_recording_date":    fc.get("recordingDate"),
        "fc_filing_date":       fc.get("filingDate"),
        "fc_case_number":       fc.get("caseNumber"),
        "fc_auction_date":      fc.get("auctionDate"),
        "fc_auction_time":      fc.get("auctionTime"),
        "fc_auction_location":  fc.get("auctionLocation"),
        "fc_auction_city":      fc.get("auctionCity"),
        "fc_auction_min_bid":   fc.get("auctionMinimumBidAmount"),
        "fc_document_number":   fc.get("documentNumber"),
        "fc_book_number":       fc.get("bookNumber"),
        "fc_page_number":       fc.get("pageNumber"),
        "fc_document_type_code": fc.get("documentTypeCode"),
        "fc_document_type":     fc.get("documentType"),

        # JSON blobs
        "deed_history_json": json.dumps(deed_history) if deed_history else None,
        "raw_json":          json.dumps(payload),

        "created_at": ts,
        "updated_at": ts,
    }

    try:
        with engine.begin() as conn:
            conn.exec_driver_sql(
                """
                INSERT INTO case_property (
                    case_id,
                    batch_property_id,
                    address_validity,
                    address_house_number,
                    address_street,
                    address_city,
                    address_county,
                    address_state,
                    address_zip,
                    address_zip_plus4,
                    address_latitude,
                    address_longitude,
                    address_county_fips,
                    address_hash,
                    demo_age,
                    demo_household_size,
                    demo_income,
                    demo_net_worth,
                    demo_discretionary_income,
                    demo_homeowner_renter_code,
                    demo_homeowner_renter,
                    demo_gender_code,
                    demo_gender,
                    demo_child_count,
                    demo_has_children,
                    demo_marital_status_code,
                    demo_marital_status,
                    demo_single_parent,
                    demo_religious,
                    demo_religious_affil_code,
                    demo_religious_affil,
                    demo_education_code,
                    demo_education,
                    demo_occupation,
                    demo_occupation_code,
                    fc_status_code,
                    fc_status,
                    fc_recording_date,
                    fc_filing_date,
                    fc_case_number,
                    fc_auction_date,
                    fc_auction_time,
                    fc_auction_location,
                    fc_auction_city,
                    fc_auction_min_bid,
                    fc_document_number,
                    fc_book_number,
                    fc_page_number,
                    fc_document_type_code,
                    fc_document_type,
                    deed_history_json,
                    raw_json,
                    created_at,
                    updated_at
                )
                VALUES (
                    :case_id,
                    :batch_property_id,
                    :address_validity,
                    :address_house_number,
                    :address_street,
                    :address_city,
                    :address_county,
                    :address_state,
                    :address_zip,
                    :address_zip_plus4,
                    :address_latitude,
                    :address_longitude,
                    :address_county_fips,
                    :address_hash,
                    :demo_age,
                    :demo_household_size,
                    :demo_income,
                    :demo_net_worth,
                    :demo_discretionary_income,
                    :demo_homeowner_renter_code,
                    :demo_homeowner_renter,
                    :demo_gender_code,
                    :demo_gender,
                    :demo_child_count,
                    :demo_has_children,
                    :demo_marital_status_code,
                    :demo_marital_status,
                    :demo_single_parent,
                    :demo_religious,
                    :demo_religious_affil_code,
                    :demo_religious_affil,
                    :demo_education_code,
                    :demo_education,
                    :demo_occupation,
                    :demo_occupation_code,
                    :fc_status_code,
                    :fc_status,
                    :fc_recording_date,
                    :fc_filing_date,
                    :fc_case_number,
                    :fc_auction_date,
                    :fc_auction_time,
                    :fc_auction_location,
                    :fc_auction_city,
                    :fc_auction_min_bid,
                    :fc_document_number,
                    :fc_book_number,
                    :fc_page_number,
                    :fc_document_type_code,
                    :fc_document_type,
                    :deed_history_json,
                    :raw_json,
                    :created_at,
                    :updated_at
                )
                ON CONFLICT(case_id) DO UPDATE SET
                    batch_property_id          = excluded.batch_property_id,
                    address_validity           = excluded.address_validity,
                    address_house_number       = excluded.address_house_number,
                    address_street             = excluded.address_street,
                    address_city               = excluded.address_city,
                    address_county             = excluded.address_county,
                    address_state              = excluded.address_state,
                    address_zip                = excluded.address_zip,
                    address_zip_plus4          = excluded.address_zip_plus4,
                    address_latitude           = excluded.address_latitude,
                    address_longitude          = excluded.address_longitude,
                    address_county_fips        = excluded.address_county_fips,
                    address_hash               = excluded.address_hash,
                    demo_age                   = excluded.demo_age,
                    demo_household_size        = excluded.demo_household_size,
                    demo_income                = excluded.demo_income,
                    demo_net_worth             = excluded.demo_net_worth,
                    demo_discretionary_income  = excluded.demo_discretionary_income,
                    demo_homeowner_renter_code = excluded.demo_homeowner_renter_code,
                    demo_homeowner_renter      = excluded.demo_homeowner_renter,
                    demo_gender_code           = excluded.demo_gender_code,
                    demo_gender                = excluded.demo_gender,
                    demo_child_count           = excluded.demo_child_count,
                    demo_has_children          = excluded.demo_has_children,
                    demo_marital_status_code   = excluded.demo_marital_status_code,
                    demo_marital_status        = excluded.demo_marital_status,
                    demo_single_parent         = excluded.demo_single_parent,
                    demo_religious             = excluded.demo_religious,
                    demo_religious_affil_code  = excluded.demo_religious_affil_code,
                    demo_religious_affil       = excluded.demo_religious_affil,
                    demo_education_code        = excluded.demo_education_code,
                    demo_education             = excluded.demo_education,
                    demo_occupation            = excluded.demo_occupation,
                    demo_occupation_code       = excluded.demo_occupation_code,
                    fc_status_code             = excluded.fc_status_code,
                    fc_status                  = excluded.fc_status,
                    fc_recording_date          = excluded.fc_recording_date,
                    fc_filing_date             = excluded.fc_filing_date,
                    fc_case_number             = excluded.fc_case_number,
                    fc_auction_date            = excluded.fc_auction_date,
                    fc_auction_time            = excluded.fc_auction_time,
                    fc_auction_location        = excluded.fc_auction_location,
                    fc_auction_city            = excluded.fc_auction_city,
                    fc_auction_min_bid         = excluded.fc_auction_min_bid,
                    fc_document_number         = excluded.fc_document_number,
                    fc_book_number             = excluded.fc_book_number,
                    fc_page_number             = excluded.fc_page_number,
                    fc_document_type_code      = excluded.fc_document_type_code,
                    fc_document_type           = excluded.fc_document_type,
                    deed_history_json          = excluded.deed_history_json,
                    raw_json                   = excluded.raw_json,
                    updated_at                 = excluded.updated_at
                """,
                vals,
            )
    except Exception as exc:
        logger.warning("Failed to save property lookup for case %s: %s", case_id, exc)

def save_skiptrace_row(case_id: int, skip_trace: dict) -> None:
    """
    Take our normalized skip_trace dict (from batchdata_skip_trace) and
    persist ALL phones/emails into case_skiptrace_phone / case_skiptrace_email,
    plus a summary row in case_skiptrace.
    """
    try:
        results = (skip_trace or {}).get("results") or []
        if not results:
            return

        res = results[0]
        persons = res.get("persons") or []
        if not persons:
            return

        p = persons[0]

        owner_name = p.get("full_name") or ""

        # Property address from the normalized result
        prop_addr = res.get("propertyAddress") or {}
        prop_street = prop_addr.get("street")
        prop_city = prop_addr.get("city")
        prop_state = prop_addr.get("state")
        prop_zip = prop_addr.get("zip") or prop_addr.get("postalCode")

        phones = p.get("phones") or []
        emails = p.get("emails") or []

        with engine.begin() as conn:
            # Upsert base summary row
            conn.exec_driver_sql(
                """
                INSERT INTO case_skiptrace (
                    case_id,
                    owner_name,
                    prop_street, prop_city, prop_state, prop_zip
                )
                VALUES (?, ?, ?, ?, ?, ?)
                ON CONFLICT(case_id) DO UPDATE SET
                    owner_name = excluded.owner_name,
                    prop_street = excluded.prop_street,
                    prop_city = excluded.prop_city,
                    prop_state = excluded.prop_state,
                    prop_zip = excluded.prop_zip
                """,
                (case_id, owner_name, prop_street, prop_city, prop_state, prop_zip),
            )

            # Clear old phones/emails for this case
            conn.exec_driver_sql(
                "DELETE FROM case_skiptrace_phone WHERE case_id = ?",
                (case_id,),
            )
            conn.exec_driver_sql(
                "DELETE FROM case_skiptrace_email WHERE case_id = ?",
                (case_id,),
            )

            # Insert ALL phones
            for ph in phones:
                if not isinstance(ph, dict):
                    continue
                number = ph.get("number")
                if not number:
                    continue
                phone_type = ph.get("type")
                carrier = ph.get("carrier")
                last_reported = ph.get("last_reported") or ph.get("lastReportedDate")
                score = ph.get("score")

                def as_int_bool(val):
                    if isinstance(val, bool):
                        return int(val)
                    return None

                tested = as_int_bool(ph.get("tested"))
                reachable = as_int_bool(ph.get("reachable"))
                dnc = as_int_bool(ph.get("dnc"))

                conn.exec_driver_sql(
                    """
                    INSERT INTO case_skiptrace_phone (
                        case_id, number, type, carrier,
                        last_reported, score, tested, reachable, dnc
                    )
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """,
                    (
                        case_id,
                        number,
                        phone_type,
                        carrier,
                        last_reported,
                        score,
                        tested,
                        reachable,
                        dnc,
                    ),
                )

            # Insert ALL emails
            for em in emails:
                if isinstance(em, dict):
                    email_addr = em.get("email")
                    tested_val = em.get("tested")
                    tested_int = int(tested_val) if isinstance(tested_val, bool) else None
                else:
                    email_addr = str(em)
                    tested_int = None

                if not email_addr:
                    continue

                conn.exec_driver_sql(
                    """
                    INSERT INTO case_skiptrace_email (
                        case_id, email, tested
                    )
                    VALUES (?, ?, ?)
                    """,
                    (case_id, email_addr, tested_int),
                )

    except Exception as exc:
        logger.warning("Failed to save skip trace rows for case %s: %s", case_id, exc)

def save_property_for_case(case_id: int, payload: dict) -> None:
    """
    Upsert raw BatchData property lookup JSON into case_property table.
    """
    ts = _dt.datetime.utcnow().isoformat()
    try:
        with engine.begin() as conn:
            conn.exec_driver_sql(
                """
                INSERT INTO case_property (case_id, raw_json, created_at, updated_at)
                VALUES (?, ?, ?, ?)
                ON CONFLICT(case_id) DO UPDATE SET
                    raw_json = excluded.raw_json,
                    updated_at = excluded.updated_at
                """,
                (case_id, json.dumps(payload), ts, ts),
            )
    except Exception as exc:
        logger.warning("Failed to save property lookup for case %s: %s", case_id, exc)


def load_property_for_case(case_id: int) -> Optional[dict]:
    """
    Load raw property lookup JSON for a case, if it exists.
    """
    try:
        with engine.connect() as conn:
            row = conn.exec_driver_sql(
                "SELECT raw_json FROM case_property WHERE case_id = ?",
                (case_id,),
            ).fetchone()
        if row and row[0]:
            try:
                return json.loads(row[0])
            except Exception:
                return None
    except Exception as exc:
        logger.warning("Failed to load property lookup for case %s: %s", case_id, exc)
    return None


def load_skiptrace_for_case(case_id: int) -> Optional[dict]:
    """
    Load normalized skip-trace data from case_skiptrace + phone/email tables
    and convert it back into the 'skip_trace' dict structure the template expects.
    """
    try:
        with engine.connect() as conn:
            base = conn.exec_driver_sql(
                """
                SELECT
                    owner_name,
                    prop_street, prop_city, prop_state, prop_zip
                FROM case_skiptrace
                WHERE case_id = ?
                """,
                (case_id,),
            ).fetchone()

            phones_rows = conn.exec_driver_sql(
                """
                SELECT
                    number, type, carrier, last_reported,
                    score, tested, reachable, dnc
                FROM case_skiptrace_phone
                WHERE case_id = ?
                ORDER BY
                    -- highest score first, then non-null last_reported
                    CASE WHEN score IS NULL THEN 1 ELSE 0 END,
                    score DESC
                """,
                (case_id,),
            ).fetchall()

            emails_rows = conn.exec_driver_sql(
                """
                SELECT
                    email, tested
                FROM case_skiptrace_email
                WHERE case_id = ?
                """,
                (case_id,),
            ).fetchall()
    except Exception as exc:
        logger.warning("Failed to load skip trace for case %s: %s", case_id, exc)
        return None

    if not base:
        return None

    (
        owner_name,
        prop_street, prop_city, prop_state, prop_zip,
    ) = base

    def as_bool(val):
        if val is None:
            return None
        return bool(val)

    phones = []
    for row in phones_rows:
        (
            number, ptype, carrier, last_reported,
            score, tested, reachable, dnc,
        ) = row
        phones.append(
            {
                "number": number,
                "type": ptype,
                "carrier": carrier,
                "last_reported": last_reported,
                "score": score,
                "tested": as_bool(tested),
                "reachable": as_bool(reachable),
                "dnc": as_bool(dnc),
            }
        )

    emails = []
    for row in emails_rows:
        email_addr, tested = row
        emails.append(
            {
                "email": email_addr,
                "tested": as_bool(tested),
            }
        )

    property_address = {
        "street": prop_street,
        "city": prop_city,
        "state": prop_state,
        "postalCode": prop_zip,
    }

    person = {
        "full_name": owner_name,
        "phones": phones,
        "emails": emails,
    }

    return {
        "results": [
            {
                "propertyAddress": property_address,
                "persons": [person],
            }
        ]
    }



templates.env.filters["currency"] = _currency
templates.env.globals["streetview_url"] = streetview_url
templates.env.globals["pasco_appraiser_url"] = pasco_appraiser_url

# ======================================================================
# DB session
# ======================================================================
def get_db():
    """
    Standard DB session dependency.
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


# ======================================================================
# Skip Trace JSON Cache Helpers (legacy, still safe to keep)
# ======================================================================
def get_cached_skip_trace(case_id: int) -> Optional[dict]:
    """
    Read cached skip-trace JSON from the cases table, if any.
    """
    try:
        with engine.connect() as conn:
            row = conn.execute(
                text("SELECT skip_trace_json FROM cases WHERE id = :id"),
                {"id": case_id},
            ).mappings().first()
        if row and row.get("skip_trace_json"):
            try:
                return json.loads(row["skip_trace_json"])
            except Exception as exc:
                logger.warning(
                    "Failed to parse skip_trace_json for case %s: %s", case_id, exc
                )
                return None
    except Exception as exc:
        logger.warning(
            "Failed to read skip_trace_json for case %s: %s", case_id, exc
        )
    return None


def set_cached_skip_trace(case_id: int, payload: dict) -> None:
    """
    Persist skip-trace JSON into the cases.skip_trace_json column.
    """
    try:
        with engine.begin() as conn:
            conn.exec_driver_sql(
                "UPDATE cases SET skip_trace_json = :payload WHERE id = :id",
                {"payload": json.dumps(payload), "id": case_id},
            )
    except Exception as exc:
        logger.warning(
            "Failed to write skip_trace_json for case %s: %s", case_id, exc
        )


Base.metadata.create_all(bind=engine)

# ======================================================================
# Startup: ensure late-added columns exist (sqlite ALTERs)
# ======================================================================
@app.on_event("startup")
def ensure_sqlite_columns():
    Base.metadata.create_all(bind=engine)
    try:
        inspector = inspect(engine)
        cols = {c["name"] for c in inspector.get_columns("cases")}
        with engine.begin() as conn:
            if "current_deed_path" not in cols:
                conn.exec_driver_sql(
                    "ALTER TABLE cases ADD COLUMN current_deed_path TEXT DEFAULT ''"
                )
            if "previous_deed_path" not in cols:
                conn.exec_driver_sql(
                    "ALTER TABLE cases ADD COLUMN previous_deed_path TEXT DEFAULT ''"
                )
            # Outstanding liens column (JSON stored as TEXT)
            if "outstanding_liens" not in cols:
                conn.exec_driver_sql(
                    "ALTER TABLE cases ADD COLUMN outstanding_liens TEXT DEFAULT '[]'"
                )
            # Skip trace JSON cache
            if "skip_trace_json" not in cols:
                conn.exec_driver_sql(
                    "ALTER TABLE cases ADD COLUMN skip_trace_json TEXT DEFAULT NULL"
                )
    except OperationalError:
        # first run or non-sqlite; ignore
        pass


# --------------------------------------------------------
#  SKIP TRACE NORMALIZED TABLE (CREATE ON STARTUP)
# --------------------------------------------------------
@app.on_event("startup")
# --------------------------------------------------------
#  SKIP TRACE NORMALIZED TABLES (CREATE ON STARTUP)
# --------------------------------------------------------
@app.on_event("startup")
def ensure_skiptrace_tables():
    """
    Ensure the skip-trace tables exist:

      - case_skiptrace         (1 row per case: owner + property address)
      - case_skiptrace_phone   (N rows per case: all phones)
      - case_skiptrace_email   (N rows per case: all emails)
    """
    try:
        with engine.begin() as conn:
            # Base summary table (leave existing extra columns alone if already created)
            conn.exec_driver_sql(
                """
                CREATE TABLE IF NOT EXISTS case_skiptrace (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    case_id INTEGER NOT NULL UNIQUE,
                    owner_name TEXT,
                    prop_street TEXT,
                    prop_city TEXT,
                    prop_state TEXT,
                    prop_zip TEXT,
                    FOREIGN KEY(case_id) REFERENCES cases(id)
                )
                """
            )

            # Phones: one row per phone record
            conn.exec_driver_sql(
                """
                CREATE TABLE IF NOT EXISTS case_skiptrace_phone (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    case_id INTEGER NOT NULL,
                    number TEXT,
                    type TEXT,
                    carrier TEXT,
                    last_reported TEXT,
                    score INTEGER,
                    tested INTEGER,
                    reachable INTEGER,
                    dnc INTEGER,
                    FOREIGN KEY(case_id) REFERENCES cases(id)
                )
                """
            )

            # Emails: one row per email record
            conn.exec_driver_sql(
                """
                CREATE TABLE IF NOT EXISTS case_skiptrace_email (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    case_id INTEGER NOT NULL,
                    email TEXT,
                    tested INTEGER,
                    FOREIGN KEY(case_id) REFERENCES cases(id)
                )
                """
            )
    except OperationalError:
        # sqlite / first run quirks; ignore
        pass
    except Exception as exc:
        logger.warning("Failed to ensure skip-trace tables: %s", exc)
# --------------------------------------------------------
#  PROPERTY LOOKUP TABLE (CREATE ON STARTUP)
# --------------------------------------------------------
@app.on_event("startup")
# --------------------------------------------------------
#  PROPERTY DETAIL TABLE (CREATE ON STARTUP)
# --------------------------------------------------------
@app.on_event("startup")
def ensure_property_table():
    """
    Detailed property data from BatchData 'property/lookup/all-attributes'.
    One row per case_id.
    """
    try:
        with engine.begin() as conn:
            conn.exec_driver_sql(
                """
                CREATE TABLE IF NOT EXISTS case_property (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    case_id INTEGER NOT NULL UNIQUE,

                    -- BatchData property id
                    batch_property_id TEXT,

                    -- Address block
                    address_validity        TEXT,
                    address_house_number    TEXT,
                    address_street          TEXT,
                    address_city            TEXT,
                    address_county          TEXT,
                    address_state           TEXT,
                    address_zip             TEXT,
                    address_zip_plus4       TEXT,
                    address_latitude        REAL,
                    address_longitude       REAL,
                    address_county_fips     TEXT,
                    address_hash            TEXT,

                    -- Demographics block
                    demo_age                     INTEGER,
                    demo_household_size          INTEGER,
                    demo_income                  INTEGER,
                    demo_net_worth               INTEGER,
                    demo_discretionary_income    INTEGER,
                    demo_homeowner_renter_code   TEXT,
                    demo_homeowner_renter        TEXT,
                    demo_gender_code             TEXT,
                    demo_gender                  TEXT,
                    demo_child_count             INTEGER,
                    demo_has_children            INTEGER,
                    demo_marital_status_code     TEXT,
                    demo_marital_status          TEXT,
                    demo_single_parent           INTEGER,
                    demo_religious               INTEGER,
                    demo_religious_affil_code    TEXT,
                    demo_religious_affil         TEXT,
                    demo_education_code          TEXT,
                    demo_education               TEXT,
                    demo_occupation              TEXT,
                    demo_occupation_code         TEXT,

                    -- Foreclosure block
                    fc_status_code          TEXT,
                    fc_status               TEXT,
                    fc_recording_date       TEXT,
                    fc_filing_date          TEXT,
                    fc_case_number          TEXT,
                    fc_auction_date         TEXT,
                    fc_auction_time         TEXT,
                    fc_auction_location     TEXT,
                    fc_auction_city         TEXT,
                    fc_auction_min_bid      REAL,
                    fc_document_number      TEXT,
                    fc_book_number          TEXT,
                    fc_page_number          TEXT,
                    fc_document_type_code   TEXT,
                    fc_document_type        TEXT,

                    -- Full deed history + full payload backup
                    deed_history_json   TEXT,
                    raw_json            TEXT,

                    created_at          TEXT,
                    updated_at          TEXT,

                    FOREIGN KEY(case_id) REFERENCES cases(id)
                )
                """
            )
    except Exception as exc:
        logger.warning("Failed to ensure case_property table: %s", exc)





# ======================================================================
# Helpers: shell runner + scraper glue
# ======================================================================
async def run_command_with_logs(cmd: list[str], job_id: str) -> int:
    """
    Async process runner that streams stdout->progress_bus line by line.
    """
    proc = await asyncio.create_subprocess_exec(
        *cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.STDOUT,
    )
    assert proc.stdout is not None
    async for raw in proc.stdout:
        await progress_bus.publish(job_id, raw.decode(errors="ignore").rstrip("\n"))
    rc = await proc.wait()
    await progress_bus.publish(job_id, f"[done] exit_code={rc}")
    return rc


def _find_scraper_script() -> Path:
    """
    Locate `pasco_foreclosure_scraper.py` in either:
    - <root>/Pasco Foreclosure Scrape
    - <root>/app/scrapers
    """
    candidates = [
        BASE_DIR / "Pasco Foreclosure Scrape" / "pasco_foreclosure_scraper.py",
        BASE_DIR / "app" / "scrapers" / "pasco_foreclosure_scraper.py",
    ]
    for p in candidates:
        if p.exists():
            return p
    raise HTTPException(
        status_code=500,
        detail=(
            "Scraper script not found. Place 'pasco_foreclosure_scraper.py' in "
            "'Pasco Foreclosure Scrape/' or 'app/scrapers/'."
        ),
    )


def _import_csv_into_db(db: Session, csv_path: str) -> tuple[int, int, int]:
    """
    Lightweight importer (upsert by case_number, ignore duplicates).
    Returns (added, updated, skipped).
    """
    import re
    logger = logging.getLogger(__name__)

    def norm_case(s):
        s = str(s or "").strip().replace("\\", "-").replace("/", "-")
        s = re.sub(r"\s+", "", s)
        return s

    def pick_col(headers, candidates):
        """
        Given a list of headers and candidate names, return the first
        header that matches (case-insensitive, trimmed).
        """
        norm_headers = [h.strip().lower() for h in headers]
        for cand in candidates:
            cand_norm = cand.strip().lower()
            if cand_norm in norm_headers:
                # return the original header name exactly as in the CSV
                return headers[norm_headers.index(cand_norm)]
        return None

    added, updated, skipped = 0, 0, 0

    with open(csv_path, newline="", encoding="utf-8-sig") as f:
        reader = _csv.DictReader(f)
        headers = reader.fieldnames or []
        logger.info("UpdateCases: CSV headers = %s", headers)

        # Try multiple possible names for important columns
        case_col   = pick_col(headers, ["Case #", "Case Number", "Case", "Case No.", "Case No"])
        filing_col = pick_col(headers, ["Filing Date", "Filing", "Filed"])
        style_col  = pick_col(headers, ["Case Name", "Style", "Case Style"])

        if not case_col:
            msg = f"Could not find case number column in CSV headers: {headers}"
            logger.error("UpdateCases: %s", msg)
            # fail cleanly so you see the error on the progress page
            raise HTTPException(status_code=400, detail=msg)

        for row in reader:
            cn_raw = row.get(case_col, "")
            cn = norm_case(cn_raw)
            if not cn:
                skipped += 1
                continue

            case = db.query(Case).filter(Case.case_number == cn).one_or_none()
            if not case:
                case = Case(case_number=cn)
                if filing_col:
                    case.filing_datetime = row.get(filing_col, "") or None
                if style_col:
                    case.style = row.get(style_col, "") or None
                db.add(case)
                db.flush()
                added += 1
            else:
                # only fill blanks to avoid overwriting your manual edits
                if not case.filing_datetime and filing_col:
                    case.filing_datetime = row.get(filing_col, "") or None
                if not case.style and style_col:
                    case.style = row.get(style_col, "") or None
                updated += 1

            # defendants: add only new names
            dnames = [
                row.get(k, "")
                for k in row.keys()
                if k and k.strip().lower().startswith("defendant")
            ]
            dnames = [d.strip() for d in dnames if d and d.strip()]

            existing = {d.name for d in (case.defendants or [])}
            for name in dnames:
                if name not in existing:
                    db.add(Defendant(case_id=case.id, name=name))

        db.commit()

    logger.info(
        "UpdateCases: Import complete. Added=%s Updated=%s Skipped=%s",
        added, updated, skipped,
    )
    return added, updated, skipped


# ======================================================================
# Routes: home, list, detail
# ======================================================================
@app.get("/", response_class=HTMLResponse)
def home():
    return RedirectResponse(url="/cases", status_code=303)


@app.get("/cases/new", response_class=HTMLResponse)
def new_case_form(request: Request):
    return templates.TemplateResponse("cases_new.html", {"request": request, "error": None})


@app.post("/cases/create")
def create_case(
    request: Request,
    case_number: str = Form(...),
    filing_date: Optional[str] = Form(None),   # "YYYY-MM-DD" or blank
    style: Optional[str] = Form(None),
    parcel_id: Optional[str] = Form(None),
    address_override: Optional[str] = Form(None),
    arv: Optional[str] = Form(None),
    rehab: Optional[str] = Form(None),
    closing_costs: Optional[str] = Form(None),
    defendants_csv: Optional[str] = Form(None),
    db: Session = Depends(get_db),
):
    # helpers
    def _num(x: Optional[str]) -> Optional[float]:
        if x is None:
            return None
        s = x.strip()
        if not s:
            return None
        try:
            return float(s.replace(",", ""))
        except ValueError:
            return None

    cn = (case_number or "").strip()
    if not cn:
        return templates.TemplateResponse("cases_new.html", {"request": request, "error": "Case # is required."})

    # Duplicate check
    exists = db.query(Case).filter(Case.case_number == cn).one_or_none()
    if exists:
        return templates.TemplateResponse("cases_new.html", {"request": request, "error": f"Case {cn} already exists (ID {exists.id})."})

    # Create case
    case = Case(case_number=cn)
    if filing_date:
        case.filing_datetime = filing_date.strip()
    if style:
        case.style = style.strip()
    if parcel_id:
        case.parcel_id = parcel_id.strip()
    if address_override:
        case.address_override = address_override.strip()

    # only set if provided
    v_arv = _num(arv)
    v_rehab = _num(rehab)
    v_cc = _num(closing_costs)
    if v_arv is not None:
        case.arv = v_arv
    if v_rehab is not None:
        case.rehab = v_rehab
    if v_cc is not None:
        case.closing_costs = v_cc

    db.add(case)
    db.flush()

    if defendants_csv:
        raw = defendants_csv.replace("\r", "\n")
        parts = [p.strip() for chunk in raw.split("\n") for p in chunk.split(",")]
        seen = set()
        for name in parts:
            if name and name not in seen:
                seen.add(name)
                db.add(Defendant(case_id=case.id, name=name))

    db.commit()
    return RedirectResponse(url=f"/cases/{case.id}", status_code=303)


@app.get("/cases/{case_id}", response_class=HTMLResponse)
def case_detail(request: Request, case_id: int, db: Session = Depends(get_db)):
    getter = getattr(db, "get", None)
    if callable(getter):
        case = db.get(Case, case_id)
    else:
        case = db.query(Case).get(case_id)  # type: ignore[call-arg]

    if not case:
        raise HTTPException(status_code=404, detail="Case not found")

    notes = (
        db.query(Note)
        .filter(Note.case_id == case_id)
        .order_by(Note.id.desc())
        .all()
    )
    try:
        setattr(case, "notes", notes)
    except Exception:
        pass

    # Skip trace from normalized table (if present)
    skip_trace = load_skiptrace_for_case(case_id)
    skip_trace_error = None

    # Property lookup (if present)
    property_data = load_property_for_case(case_id)
    property_error = None

    offer = compute_offer_70(case.arv or 0, case.rehab or 0, case.closing_costs or 0)

    return templates.TemplateResponse(
        "case_detail.html",
        {
            "request": request,
            "case": case,
            "offer_70": offer,
            "active_parcel_id": case.parcel_id,
            "notes": notes,
            "skip_trace": skip_trace,
            "skip_trace_error": skip_trace_error,
            "property_data": property_data,
            "property_error": property_error,
        },
    )



# NEW: Skip trace endpoint using BatchData
@app.post("/cases/{case_id}/skip-trace", response_class=HTMLResponse)
def skip_trace_case(request: Request, case_id: int, db: Session = Depends(get_db)):
    # Load case
    getter = getattr(db, "get", None)
    if callable(getter):
        case = db.get(Case, case_id)
    else:
        case = db.query(Case).get(case_id)  # type: ignore[call-arg]

    if not case:
        raise HTTPException(status_code=404, detail="Case not found")

    # Notes
    notes = (
        db.query(Note)
        .filter(Note.case_id == case_id)
        .order_by(Note.id.desc())
        .all()
    )

    skip_trace: Optional[dict] = None
    skip_trace_error: Optional[str] = None

    # 1) Try table-based cache first
    skip_trace = load_skiptrace_for_case(case_id)

    # 2) If no stored data, call BatchData and persist normalized row
    if skip_trace is None:
        street, city, state, postal_code = get_case_address_components(case)

        try:
            skip_trace = batchdata_skip_trace(street, city, state, postal_code)
            # Save normalized into case_skiptrace
            save_skiptrace_row(case.id, skip_trace)
            # (optional) also keep JSON cache if you still want it:
            # set_cached_skip_trace(case_id, skip_trace)
        except HTTPException as exc:
            detail = exc.detail
            skip_trace_error = detail if isinstance(detail, str) else str(detail)
        except Exception as exc:
            skip_trace_error = f"Unexpected error during skip trace: {exc}"

    offer = compute_offer_70(case.arv or 0, case.rehab or 0, case.closing_costs or 0)

    return templates.TemplateResponse(
        "case_detail.html",
        {
            "request": request,
            "case": case,
            "offer_70": offer,
            "active_parcel_id": case.parcel_id,
            "notes": notes,
            "skip_trace": skip_trace,
            "skip_trace_error": skip_trace_error,
            "property_data": load_property_for_case(case_id),
            "property_error": None,
        },
    )

@app.post("/cases/{case_id}/property-lookup", response_class=HTMLResponse)
def property_lookup_case(request: Request, case_id: int, db: Session = Depends(get_db)):
    # Load case
    getter = getattr(db, "get", None)
    if callable(getter):
        case = db.get(Case, case_id)
    else:
        case = db.query(Case).get(case_id)  # type: ignore[call-arg]

    if not case:
        raise HTTPException(status_code=404, detail="Case not found")

    # Notes
    notes = (
        db.query(Note)
        .filter(Note.case_id == case_id)
        .order_by(Note.id.desc())
        .all()
    )
    try:
        setattr(case, "notes", notes)
    except Exception:
        pass

    # Existing skip trace (unchanged)
    skip_trace = load_skiptrace_for_case(case_id)
    skip_trace_error: Optional[str] = None

    # Property lookup
    property_data: Optional[dict] = None
    property_error: Optional[str] = None

    try:
        street, city, state, postal_code = get_case_address_components(case)
        property_data = batchdata_property_lookup_all_attributes(
            street, city, state, postal_code
        )
        save_property_for_case(case.id, property_data)
    except HTTPException as exc:
        detail = exc.detail
        property_error = detail if isinstance(detail, str) else str(detail)
        # fall back to any previously saved data
        property_data = load_property_for_case(case_id)
    except Exception as exc:
        property_error = f"Unexpected error during property lookup: {exc}"
        property_data = load_property_for_case(case_id)

    offer = compute_offer_70(case.arv or 0, case.rehab or 0, case.closing_costs or 0)

    return templates.TemplateResponse(
        "case_detail.html",
        {
            "request": request,
            "case": case,
            "offer_70": offer,
            "active_parcel_id": case.parcel_id,
            "notes": notes,
            "skip_trace": skip_trace,
            "skip_trace_error": skip_trace_error,
            "property_data": property_data,
            "property_error": property_error,
        },
    )


# ======================================================================
# SSE progress endpoints + update job orchestration
# ======================================================================
@app.get("/update_progress/{job_id}", response_class=HTMLResponse)
async def update_progress_page(request: Request, job_id: str):
    html = f"""
<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Updating cases</title>
  <style>
    body {{ font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; margin: 0; }}
    .wrap {{ max-width: 900px; margin: 24px auto; padding: 0 16px; }}
    .spinner {{
      position: fixed; inset: 0; display: flex; align-items: center; justify-content: center;
      background: rgba(0,0,0,0.5); color: #fff; z-index: 9999; font-size: 18px;
    }}
    .log {{
      background: #0b0b0b; color: #c9f4ff; padding: 16px; border-radius: 12px;
      font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace;
      white-space: pre-wrap; line-height: 1.35; max-height: 60vh; overflow: auto;
      box-shadow: 0 10px 30px rgba(0,0,0,0.2);
    }}
    .muted {{ color: #9aa7b1; font-size: 12px; margin-top: 8px; }}
    .hide {{ display:none; }}
    .pill {{ display:inline-block; padding:4px 10px; border-radius: 999px; background:#eef2ff; color:#3730a3; font-size:12px; }}
  </style>
</head>
<body>
  <div id="spinner" class="spinner">Updating cases Please dont navigate away.</div>
  <div class="wrap">
    <h1>Update in progress <span class="pill">live log</span></h1>
    <div id="log" class="log"></div>
    <div id="hint" class="muted">This log will auto-scroll. Youll be redirected when finished.</div>
  </div>

<script>
  const logEl = document.getElementById('log');
  const spinner = document.getElementById('spinner');
  const es = new EventSource('/events/{job_id}');
  function appendLine(s) {{
    logEl.textContent += s + '\\n';
    logEl.scrollTop = logEl.scrollHeight;
  }}
  es.onmessage = (e) => {{
    const t = e.data || '';
    if (t.startsWith('[done]')) {{
      spinner.classList.add('hide');
      es.close();
      setTimeout(() => window.location.href = '/cases', 10000);
    }} else {{
      if (t.trim().length) {{
        appendLine(t);
        spinner.classList.add('hide');
      }}
    }}
  }};
  es.onerror = () => {{
    appendLine('[connection error] retrying');
  }};
</script>
</body>
</html>
"""
    return HTMLResponse(content=html)


@app.get("/events/{job_id}")
async def events(job_id: str):
    async def event_generator():
        # initial hello to open the stream promptly
        yield ": connected\n\n"
        while True:
            try:
                async for line in progress_bus.stream(job_id):
                    yield f"data: {line}\n\n"
            except Exception:
                # brief heartbeat to keep connection alive
                yield ": heartbeat\n\n"
                await asyncio.sleep(5)
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"},
    )


@app.get("/import", response_class=HTMLResponse)
def update_case_list_page(request: Request):
    # Renders the form with the "Days to scrape" selector that posts to /update_cases
    return templates.TemplateResponse("import.html", {"request": request})


@app.post("/update_cases")
async def update_cases(
    request: Request,
    since_days: int = Form(7),
):
    """
    Starts an async job that:
      1) Runs the foreclosure scraper with --since-days
      2) Imports the resulting CSV with upsert-by-case_number (no dupes)
    Immediately redirects to a live log page.
    """
    job_id = uuid.uuid4().hex
    # prime the log so the progress page shows something immediately
    await progress_bus.publish(job_id, f"Queued job {job_id}")
    asyncio.create_task(_update_cases_job(job_id, since_days))
    return RedirectResponse(url=f"/update_progress/{job_id}", status_code=303)


async def _update_cases_job(job_id: str, since_days: int):
    try:
        await progress_bus.publish(job_id, f"Starting update job {job_id} (since_days={since_days})")

        # 1) Run the scraper to produce CSV
        scraper_script = _find_scraper_script()
        tmpdir = tempfile.mkdtemp(prefix="pasco_update_")
        csv_out = os.path.join(tmpdir, "pasco_foreclosures.csv")

        cmd = [
            sys.executable,
            str(scraper_script),
            "--since-days", str(max(0, int(since_days))),
            "--out", csv_out,  # your integrated scraper should accept --out
        ]
        await progress_bus.publish(job_id, "Launching scraper: " + " ".join(cmd))
        rc = await run_command_with_logs(cmd, job_id)
        if rc != 0 or not os.path.exists(csv_out):
            await progress_bus.publish(job_id, "[error] Scraper failed or CSV not found.]")
            await progress_bus.publish(job_id, "[done] exit_code=1")
            return

        await progress_bus.publish(job_id, "Scraper finished. Importing CSV via tools/import_pasco_csv.py")

        # 2) Import CSV using the same logic as the CLI tool
        def _run_import():
            import_pasco_csv_main(csv_out)

        loop = asyncio.get_running_loop()
        await loop.run_in_executor(None, _run_import)

        await progress_bus.publish(job_id, "Import complete via tools/import_pasco_csv.py")
        await progress_bus.publish(job_id, "[done] exit_code=0")

    except Exception as e:
        # Surface the exception in the log and signal completion
        await progress_bus.publish(job_id, f"[exception] {e}")
        await progress_bus.publish(job_id, "[done] exit_code=1")


# ======================================================================
# PDF Report for a Case (summary + attached documents)
# ======================================================================

@app.get("/cases/{case_id}/report")
def case_report(case_id: int, db: Session = Depends(get_db)):
    """
    Generate a professional, investorready PDF case report that mirrors
    the key information on case_detail.html, including:
       Case + property snapshot
       JSN deal calculator summary
       Outstanding liens
       Skip trace summary
       Notes
    """
    # ---- Fetch core case ----
    getter = getattr(db, "get", None)
    if callable(getter):
        case = db.get(Case, case_id)
    else:
        case = db.query(Case).get(case_id)  # type: ignore[call-arg]

    if not case:
        raise HTTPException(status_code=404, detail="Case not found")

    # ---- Helper: safe currency formatting ----
    def fmt_money(raw) -> str:
        if raw is None:
            return ""
        if isinstance(raw, (int, float)):
            try:
                return f"${float(raw):,.2f}"
            except Exception:
                return str(raw)
        s = str(raw).strip()
        if not s:
            return ""
        cleaned = s.replace("$", "").replace(",", "")
        try:
            v = float(cleaned)
            return f"${v:,.2f}"
        except Exception:
            return s

    # ---- Helper: normalize property snapshot from BatchData lookup ----
    def get_property_snapshot(case_id: int) -> dict:
        snap: dict = {}
        prop_raw = load_property_for_case(case_id)
        if not isinstance(prop_raw, dict):
            return {}

        # Expected structure: { "status": {...}, "results": { "properties": [ {...} ], ... } }
        props_block = None
        results = prop_raw.get("results")
        if isinstance(results, dict):
            props_block = results.get("properties")
        elif isinstance(results, list):
            props_block = results
        if not isinstance(props_block, list) or not props_block:
            return {}

        p0 = props_block[0] or {}

        valuation = p0.get("valuation", {}) or {}
        tax = p0.get("tax", {}) or {}
        open_lien = p0.get("openLien", {}) or {}
        owner = p0.get("owner", {}) or {}
        quick = p0.get("quickLists", {}) or {}
        general = p0.get("general", {}) or {}
        lot = p0.get("lot", {}) or {}

        snap["estimated_value"] = valuation.get("estimatedValue")
        snap["value_range_min"] = valuation.get("priceRangeMin")
        snap["value_range_max"] = valuation.get("priceRangeMax")
        snap["confidence_score"] = valuation.get("confidenceScore")

        snap["tax_amount"] = tax.get("taxAmount")
        snap["tax_year"] = tax.get("taxYear")
        snap["tax_rate_area"] = tax.get("taxRateCodeArea")

        snap["open_lien_balance"] = open_lien.get("totalOpenLienBalance")
        snap["open_lien_count"] = open_lien.get("totalOpenLienCount")
        snap["loan_types"] = ", ".join(open_lien.get("allLoanTypes") or [])

        snap["owner_name"] = owner.get("fullName")
        snap["owner_occupied_flag"] = quick.get("ownerOccupied")
        snap["absentee_owner_flag"] = quick.get("absenteeOwner")
        snap["high_equity_flag"] = quick.get("highEquity")
        snap["free_and_clear_flag"] = quick.get("freeAndClear")
        snap["preforeclosure_flag"] = quick.get("preforeclosure")
        snap["tax_default_flag"] = quick.get("taxDefault")
        snap["vacant_flag"] = quick.get("vacant")

        # A few extra context bits that are nice on a report
        snap["property_type"] = general.get("propertyTypeDetail") or general.get("propertyTypeCategory")
        snap["zoning"] = lot.get("zoningCode")
        snap["lot_size_acres"] = lot.get("lotSizeAcres")

        # Build a compact list of "tags" for quickLists that are true
        quick_tags = []
        for key, label in [
            ("highEquity_flag", "High Equity"),
            ("free_and_clear_flag", "Free & Clear"),
            ("owner_occupied_flag", "OwnerOccupied"),
            ("absentee_owner_flag", "Absentee Owner"),
            ("preforeclosure_flag", "Preforeclosure"),
            ("tax_default_flag", "Tax Default"),
            ("vacant_flag", "Vacant"),
        ]:
            if snap.get(key):
                quick_tags.append(label)
        snap["quick_tags"] = quick_tags

        return snap

    property_snapshot = get_property_snapshot(case.id)

    # ---- Compute ARV / Rehab / Closing / JSN numbers in same way as UI ----
    arv_fallback = property_snapshot.get("estimated_value") or 0
    try:
        case_arv = float(case.arv) if case.arv not in (None, "") else None
    except Exception:
        case_arv = None
    arv = case_arv if case_arv is not None else float(arv_fallback or 0)

    try:
        rehab = float(case.rehab) if case.rehab not in (None, "") else 0.0
    except Exception:
        rehab = 0.0

    # Closing costs: userentered if present, otherwise 4.5% of ARV
    try:
        user_closing = float(case.closing_costs) if case.closing_costs not in (None, "") else None
    except Exception:
        user_closing = None
    if user_closing is not None:
        closing_costs = user_closing
    else:
        closing_costs = round(arv * 0.045, 2) if arv else 0.0

    # JSN Max Offer: 70% of (ARV  Rehab  Closing)
    try:
        jsn_max_offer = max(0.0, 0.70 * (float(arv) - float(rehab) - float(closing_costs)))
    except Exception:
        jsn_max_offer = 0.0

    # Outstanding liens parsed from JSON
    liens_raw = getattr(case, "outstanding_liens", "[]") or "[]"
    try:
        liens_list = json.loads(liens_raw)
    except Exception:
        liens_list = []
    if not isinstance(liens_list, list):
        liens_list = []

    total_liens = 0.0
    cleaned_liens = []
    for l in liens_list:
        if not isinstance(l, dict):
            continue
        holder = (l.get("holder") or "").strip()
        amt_raw = (l.get("amount") or "").strip()
        if not amt_raw:
            amt_val = 0.0
        else:
            cleaned = amt_raw.replace("$", "").replace(",", "")
            try:
                amt_val = float(cleaned)
            except Exception:
                amt_val = 0.0
        total_liens += amt_val
        cleaned_liens.append(
            {
                "holder": holder or "Unknown",
                "amount": amt_val,
            }
        )

    max_seller_cash = max(0.0, jsn_max_offer - total_liens)

    # ---- Skip trace summary (top phones/emails) ----
    skip_data = load_skiptrace_for_case(case.id)
    skip_owner = None
    phone_rows: list[dict] = []
    email_rows: list[dict] = []

    if isinstance(skip_data, dict):
        # Expected structure from loader:
        # { "results": [ { "propertyAddress": {...}, "persons": [ { full_name, phones, emails, ... } ] } ] }
        results = skip_data.get("results")
        if isinstance(results, list) and results:
            first = results[0] or {}
            persons = first.get("persons") or []
            if isinstance(persons, list) and persons:
                person0 = persons[0] or {}
                skip_owner = person0.get("full_name") or person0.get("name")
                for p in (person0.get("phones") or []):
                    if not isinstance(p, dict):
                        continue
                    phone_rows.append(p)
                for e in (person0.get("emails") or []):
                    if not isinstance(e, dict):
                        continue
                    email_rows.append(e)

    # ---- Defendants & notes ----
    defendants = getattr(case, "defendants", []) or []
    clean_defendants: list[str] = []
    for d in defendants:
        name = (getattr(d, "name", "") or "").strip()
        if not name:
            continue
        lower = name.lower()
        if lower in {"nan", "none", "nil"}:
            continue
        clean_defendants.append(name)

    notes = getattr(case, "notes", None)
    if notes is None:
        notes = db.query(Note).filter(Note.case_id == case_id).order_by(Note.id.desc()).all()

    # ---- Start PDF ----
    buf = io.BytesIO()
    c = canvas.Canvas(buf, pagesize=letter)
    width, height = letter

    margin = 50
    y = height - margin

    def draw_title(text: str):
        nonlocal y
        c.setFont("Helvetica-Bold", 16)
        c.drawString(margin, y, text)
        y -= 24

    def draw_subtitle(text: str):
        nonlocal y
        c.setFont("Helvetica", 11)
        c.drawString(margin, y, text)
        y -= 16

    def draw_section(title: str):
        nonlocal y
        y -= 8
        c.setFont("Helvetica-Bold", 12)
        c.drawString(margin, y, title)
        y -= 12
        c.setLineWidth(0.5)
        c.line(margin, y, width - margin, y)
        y -= 10
        c.setFont("Helvetica", 10)

    def draw_label_value(label: str, value: str):
        nonlocal y
        if y < 80:
            c.showPage()
            y = height - margin
            c.setFont("Helvetica", 10)
        c.setFont("Helvetica-Bold", 9)
        c.drawString(margin, y, f"{label}:")
        c.setFont("Helvetica", 10)
        c.drawString(margin + 90, y, value)
        y -= 14

    # ---- Header ----
    addr = (getattr(case, "address_override", None) or getattr(case, "address", "") or "").strip()
    title_line = addr or f"Case #{case.case_number or case.id}"
    draw_title("JSN Holdings  Case Report")
    if title_line:
        draw_subtitle(title_line)
    draw_subtitle(f"Case ID: {case.id}   Case Number: {case.case_number or ''}")

    # ---- Property snapshot (BatchData AVM / tax / liens / flags) ----
    draw_section("Property Snapshot")

    owner_name = property_snapshot.get("owner_name") or skip_owner or (clean_defendants[0] if clean_defendants else "")
    if owner_name:
        draw_label_value("Owner", owner_name)

    if property_snapshot.get("estimated_value") is not None:
        draw_label_value("Estimated Value (AVM)", fmt_money(property_snapshot.get("estimated_value")))
    if property_snapshot.get("tax_amount") is not None:
        tax_label = f"{fmt_money(property_snapshot.get('tax_amount'))} (Year {property_snapshot.get('tax_year') or ''})"
        draw_label_value("Annual Taxes", tax_label)
    if property_snapshot.get("open_lien_balance") is not None:
        draw_label_value("Open Lien Balance", fmt_money(property_snapshot.get("open_lien_balance")))
    if property_snapshot.get("loan_types"):
        draw_label_value("Loan Types", property_snapshot.get("loan_types"))

    lot_acres = property_snapshot.get("lot_size_acres")
    if lot_acres:
        draw_label_value("Lot Size (acres)", f"{lot_acres:.3f}")
    if property_snapshot.get("property_type"):
        draw_label_value("Property Type", property_snapshot.get("property_type"))

    quick_tags = property_snapshot.get("quick_tags") or []
    if quick_tags:
        draw_label_value("Quick Flags", ", ".join(quick_tags))

    # ---- Case details ----
    draw_section("Case Details")
    filing_str = ""
    if getattr(case, "filing_datetime", None):
        try:
            filing_str = case.filing_datetime.strftime("%Y-%m-%d")
        except Exception:
            filing_str = str(case.filing_datetime)
    draw_label_value("Filing Date", filing_str or "")
    draw_label_value("Style / Caption", (case.style or "")[:120])
    draw_label_value("Parcel ID", case.parcel_id or "")
    draw_label_value("Address", addr)

    if clean_defendants:
        draw_label_value("Defendants", "; ".join(clean_defendants))

    # ---- JSN Deal Calculator Summary ----
    draw_section("JSN Deal Calculator")
    draw_label_value("After Repair Value (ARV)", fmt_money(arv))
    draw_label_value("Estimated Rehab", fmt_money(rehab))
    draw_label_value("Closing Costs", fmt_money(closing_costs))
    draw_label_value("JSN Max Offer", fmt_money(jsn_max_offer))
    if cleaned_liens:
        draw_label_value("Total Recorded Liens", fmt_money(total_liens))
        draw_label_value("Max Seller InHand Cash", fmt_money(max_seller_cash))

    # ---- Outstanding Liens detail ----
    if cleaned_liens:
        draw_section("Outstanding Liens")
        for l in cleaned_liens:
            line_txt = f"{l['holder']}: {fmt_money(l['amount'])}"
            if y < 80:
                c.showPage()
                y = height - margin
                c.setFont("Helvetica", 10)
            c.drawString(margin + 10, y, " " + line_txt)
            y -= 14

    # ---- Skip Trace Summary ----
    if phone_rows or email_rows:
        draw_section("Skip Trace Summary")
        if phone_rows:
            c.setFont("Helvetica-Bold", 10)
            if y < 80:
                c.showPage()
                y = height - margin
            c.drawString(margin, y, "Phones:")
            y -= 14
            c.setFont("Helvetica", 9)
            for p in phone_rows[:4]:
                num = p.get("number") or ""
                ptype = p.get("type") or ""
                score = p.get("score")
                tested = p.get("tested")
                reachable = p.get("reachable")
                dnc = p.get("dnc")
                bits = [num]
                if ptype:
                    bits.append(f"({ptype})")
                if score is not None:
                    bits.append(f"score {score}")
                flags = []
                if tested:
                    flags.append("tested")
                if reachable:
                    flags.append("reachable")
                if dnc:
                    flags.append("DNC")
                if flags:
                    bits.append("[" + ", ".join(flags) + "]")
                line_txt = " ".join(str(b) for b in bits if b)
                if y < 80:
                    c.showPage()
                    y = height - margin
                    c.setFont("Helvetica", 9)
                c.drawString(margin + 10, y, " " + line_txt)
                y -= 12

        if email_rows:
            if y < 80:
                c.showPage()
                y = height - margin
            c.setFont("Helvetica-Bold", 10)
            c.drawString(margin, y, "Emails:")
            y -= 14
            c.setFont("Helvetica", 9)
            for e in email_rows[:4]:
                addr_e = e.get("email") or ""
                tested = e.get("tested")
                flags = []
                if tested:
                    flags.append("tested")
                line_txt = addr_e
                if flags:
                    line_txt += " [" + ", ".join(flags) + "]"
                if y < 80:
                    c.showPage()
                    y = height - margin
                    c.setFont("Helvetica", 9)
                c.drawString(margin + 10, y, " " + line_txt)
                y -= 12

    # ---- Notes ----
    draw_section("Notes")
    if notes:
        for n in notes:
            content = (getattr(n, "content", "") or "").strip()
            if not content:
                continue
            if len(content) > 220:
                content = content[:217] + "..."
            if y < 80:
                c.showPage()
                y = height - margin
                c.setFont("Helvetica", 10)
            c.drawString(margin + 10, y, " " + content)
            y -= 12
    else:
        draw_label_value("Notes", "None recorded")

    c.showPage()
    c.save()
    buf.seek(0)

    filename = f"case_{case.id}_report.pdf"
    return StreamingResponse(
        buf,
        media_type="application/pdf",
        headers={"Content-Disposition": f'attachment; filename=\"{filename}\"'},
    )

@app.post("/cases/{case_id}/update")
def case_update(
    case_id: int,
    parcel_id: Optional[str] = Form(None),
    address_override: Optional[str] = Form(None),
    arv: Optional[str] = Form(None),
    rehab: Optional[str] = Form(None),
    closing_costs: Optional[str] = Form(None),
    db: Session = Depends(get_db),
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)

    if parcel_id is not None:
        case.parcel_id = (parcel_id or "").strip()
    if address_override is not None:
        case.address_override = (address_override or "").strip()

    def _num(x: Optional[str]) -> Optional[float]:
        if x is None:
            return None
        s = x.strip()
        if not s:
            return None
        try:
            return float(s.replace(",", ""))
        except ValueError:
            return None

    v_arv = _num(arv)
    v_rehab = _num(rehab)
    v_cc = _num(closing_costs)

    if v_arv is not None:
        case.arv = v_arv
    if v_rehab is not None:
        case.rehab = v_rehab
    if v_cc is not None:
        case.closing_costs = v_cc

    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)



@app.post("/cases/{case_id}/upload/verified")
async def upload_verified(
    case_id: int, verified_complaint: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Verified_Complaint.pdf"
    with open(dest, "wb") as f:
        f.write(await verified_complaint.read())
    case.verified_complaint_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/upload/value_calc")
async def upload_value_calc(
    case_id: int, value_calc: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Value_Calculation.pdf"
    with open(dest, "wb") as f:
        f.write(await value_calc.read())
    case.value_calc_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/upload/mortgage")
async def upload_mortgage(
    case_id: int, mortgage: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Mortgage.pdf"
    with open(dest, "wb") as f:
        f.write(await mortgage.read())
    case.mortgage_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/upload/current-deed")
async def upload_current_deed(
    case_id: int, current_deed: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Current_Deed.pdf"
    with open(dest, "wb") as f:
        f.write(await current_deed.read())
    case.current_deed_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/upload/previous-deed")
async def upload_previous_deed(
    case_id: int, previous_deed: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Previous_Deed.pdf"
    with open(dest, "wb") as f:
        f.write(await previous_deed.read())
    case.previous_deed_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/notes/add")
def add_note(case_id: int, content: str = Form(...), db: Session = Depends(get_db)):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        raise HTTPException(status_code=404, detail="Case not found")
    content = (content or "").strip()
    if not content:
        return RedirectResponse(url=f"/cases/{case_id}", status_code=303)
    ts = _dt.datetime.now().strftime("%Y-%m-%d %H:%M")
    note = Note(case_id=case_id, content=content, created_at=ts)
    db.add(note)
    db.commit()
    return RedirectResponse(url=f"/cases/{case_id}", status_code=303)


# ======================================================================
# NEW: Outstanding Liens API
# ======================================================================
@app.get("/cases/{case_id}/liens", response_model=list[OutstandingLien])
def get_outstanding_liens(case_id: int, db: Session = Depends(get_db)):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        raise HTTPException(status_code=404, detail="Case not found")
    return case.get_outstanding_liens()


@app.post("/cases/{case_id}/liens", response_model=list[OutstandingLien])
def save_outstanding_liens(case_id: int, payload: OutstandingLiensUpdate, db: Session = Depends(get_db)):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        raise HTTPException(status_code=404, detail="Case not found")
    case.set_outstanding_liens([l.dict() for l in payload.outstanding_liens])
    db.add(case)
    db.commit()
    db.refresh(case)
    return case.get_outstanding_liens()


# ======================================================================
# Simple health check
# ======================================================================
@app.get("/healthz")
def healthz():
    return {"status": "ok"}


# =====================
# START: Added in v1.05+ for Archive + Export + Search
# =====================
@app.on_event("startup")
def _ensure_archived_column():
    try:
        inspector = inspect(engine)
        cols = {c["name"] for c in inspector.get_columns("cases")}
        if "archived" not in cols:
            with engine.begin() as conn:
                conn.exec_driver_sql("ALTER TABLE cases ADD COLUMN archived INTEGER DEFAULT 0")
    except Exception as e:
        logger.warning("Could not ensure 'archived' column: %s", e)


@app.get("/cases", response_class=HTMLResponse)
def cases_list(
    request: Request,
    page: int = Query(1),
    show_archived: int = Query(0),
    case: str = Query("", alias="case"),
    db: Session = Depends(get_db),
):
    qry = db.query(Case)

    if not show_archived:
        qry = qry.filter(text("(archived IS NULL OR archived = 0)"))

    if case:
        qry = qry.filter(Case.case_number.contains(case))

    page_size = 10
    total = qry.count()
    pages = (total + page_size - 1) // page_size
    offset = (page - 1) * page_size
    cases = (
        qry.order_by(Case.filing_datetime.desc())
           .offset(offset)
           .limit(page_size)
           .all()
    )
    pagination = {"page": page, "pages": pages, "total": total}
    return templates.TemplateResponse(
        "cases_list.html",
        {
            "request": request,
            "cases": cases,
            "pagination": pagination,
            "show_archived": bool(show_archived),
            "search_query": case,
        },
    )


@app.post("/cases/archive")
def archive_cases(
    request: Request,
    ids: List[int] = Form(default=[]),
    show_archived: int = Form(0),
    db: Session = Depends(get_db),
):
    if ids:
        db.execute(
            text("UPDATE cases SET archived = 1 WHERE id IN :ids")
            .bindparams(bindparam("ids", expanding=True)),
            {"ids": ids},
        )
        db.commit()
    return RedirectResponse(url="/cases?show_archived=0&page=1", status_code=303)


@app.post("/cases/export")
def export_cases(
    request: Request,
    ids: List[int] = Form(default=[]),
    show_archived: int = Form(0),
    case: str = Form("", alias="case"),
    db: Session = Depends(get_db),
):
    qry = db.query(Case)

    if not show_archived:
        qry = qry.filter(text("(archived IS NULL OR archived = 0)"))

    if case:
        qry = qry.filter(Case.case_number.contains(case))
    if ids:
        qry = qry.filter(Case.id.in_(ids))

    header = [
        "id",
        "case_number",
        "filing_datetime",
        "style",
        "address",
        "arv",
        "closing_costs",
        "current_deed_path",
        "defendants",
        "mortgage_path",
        "notes_count",
        "outstanding_liens",
        "parcel_id",
        "previous_deed_path",
        "rehab",
        "value_calc_path",
        "verified_complaint_path",
    ]

    buf = io.StringIO()
    writer = _csv.writer(buf, lineterminator="\n")
    writer.writerow(header)

    rows = qry.order_by(Case.filing_datetime.desc()).all()
    for c in rows:
        try:
            defendants = [d.name for d in c.defendants] if getattr(c, "defendants", None) else []
        except Exception:
            defendants = []
        try:
            notes_count = len(c.notes) if getattr(c, "notes", None) else 0
        except Exception:
            notes_count = 0

        address = (getattr(c, "address_override", None) or getattr(c, "address", "") or "").strip()
        outstanding = getattr(c, "outstanding_liens", None) or "[]"

        writer.writerow([
            c.id,
            c.case_number or "",
            c.filing_datetime or "",
            c.style or "",
            address,
            getattr(c, "arv", "") or "",
            getattr(c, "closing_costs", "") or "",
            getattr(c, "current_deed_path", "") or "",
            json.dumps(defendants),
            getattr(c, "mortgage_path", "") or "",
            notes_count,
            outstanding,
            c.parcel_id or "",
            getattr(c, "previous_deed_path", "") or "",
            getattr(c, "rehab", "") or "",
            getattr(c, "value_calc_path", "") or "",
            getattr(c, "verified_complaint_path", "") or "",
        ])

    buf.seek(0)
    filename = f"cases_export_{_dt.datetime.now().strftime('%Y-%m-%d')}.csv"
    return StreamingResponse(
        iter([buf.getvalue()]),
        media_type="text/csv",
        headers={"Content-Disposition": f'attachment; filename=\"{filename}\"'},
    )


# =====================
# v1.07 Additions  Unarchive + AJAX endpoints
# =====================
@app.on_event("startup")
def _ensure_archived_column_v107():
    try:
        inspector = inspect(engine)
        cols = {c["name"] for c in inspector.get_columns("cases")}
        if "archived" not in cols:
            with engine.begin() as conn:
                conn.exec_driver_sql("ALTER TABLE cases ADD COLUMN archived INTEGER DEFAULT 0")
    except Exception as e:
        logger.warning("Could not ensure 'archived' column: %s", e)


@app.post("/cases/unarchive")
def unarchive_cases(
    request: Request,
    ids: List[int] = Form(default=[]),
    show_archived: int = Form(0),
    db: Session = Depends(get_db),
):
    if ids:
        db.execute(
            text("UPDATE cases SET archived = 0 WHERE id IN :ids")
            .bindparams(bindparam("ids", expanding=True)),
            {"ids": ids},
        )
        db.commit()
    return RedirectResponse(url=f"/cases?show_archived={show_archived}&page=1", status_code=303)


@app.post("/cases/archive_async")
def archive_cases_async(
    ids: List[int] = Form(default=[]),
    db: Session = Depends(get_db),
):
    if not ids:
        return {"ok": True, "updated": 0}
    db.execute(
        text("UPDATE cases SET archived = 1 WHERE id IN :ids")
        .bindparams(bindparam("ids", expanding=True)),
        {"ids": ids},
    )
    db.commit()
    return {"ok": True, "updated": len(ids)}


@app.post("/cases/unarchive_async")
def unarchive_cases_async(
    ids: List[int] = Form(default=[]),
    db: Session = Depends(get_db),
):
    if not ids:
        return {"ok": True, "updated": 0}
    db.execute(
        text("UPDATE cases SET archived = 0 WHERE id IN :ids")
        .bindparams(bindparam("ids", expanding=True)),
        {"ids": ids},
    )
    db.commit()
    return {"ok": True, "updated": len(ids)}


# =====================
# Manual Add Case (v1.08)
# =====================
# (placeholder for future additions)
