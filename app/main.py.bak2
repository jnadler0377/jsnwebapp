from __future__ import annotations

# ---- Windows event loop fix for asyncio subprocess ----
import sys as _sys
import asyncio as _asyncio
if _sys.platform == "win32":
    try:
        _asyncio.set_event_loop_policy(_asyncio.WindowsProactorEventLoopPolicy())
    except Exception:
        pass

# ---------------- Stdlib ----------------
import logging
import asyncio
import csv as _csv
import datetime as _dt
import os
import sys
import tempfile
import uuid
import io, json
from pathlib import Path
from typing import List, Optional
from PyPDF2 import PdfReader, PdfWriter
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from tools.import_pasco_csv import main as import_pasco_csv_main
import requests  # for BatchData skip trace calls

# ---------------- FastAPI / Responses ----------------
from fastapi import (
    FastAPI,
    Request,
    Depends,
    UploadFile,
    File,
    Form,
    Query,
    HTTPException,
)
from fastapi.responses import HTMLResponse, RedirectResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates

# ---------------- DB / ORM ----------------
from sqlalchemy.orm import Session
from sqlalchemy import inspect, text, bindparam
from sqlalchemy.exc import OperationalError

# ---------------- App imports ----------------
from app.services.progress_bus import progress_bus
from app.settings import settings
from .database import Base, engine, SessionLocal
from .models import Case, Defendant, Docket, Note
from .utils import ensure_case_folder, compute_offer_70
from .schemas import OutstandingLien, OutstandingLiensUpdate
from dotenv import dotenv_values

# Resolve project root (adjust if your .env lives somewhere else)
BASE_DIR = Path(__file__).resolve().parent.parent  # e.g. C:\pascowebapp
ENV_PATH = BASE_DIR / ".env"

# Read ONLY from the .env file
env_values = dotenv_values(ENV_PATH)

BATCHDATA_API_KEY = env_values.get("BATCHDATA_API_KEY")

print("DEBUG: .env path =", ENV_PATH)
print("DEBUG: BATCHDATA_API_KEY from .env =", BATCHDATA_API_KEY)

# ======================================================================
# App bootstrap
# ======================================================================
app = FastAPI(title="JSN Holdings Foreclosure Manager")
logger = logging.getLogger("pascowebapp")
logger.setLevel(logging.INFO)

BASE_DIR = Path(__file__).resolve().parent.parent
STATIC_DIR = BASE_DIR / "app" / "static"
TEMPLATES_DIR = BASE_DIR / "app" / "templates"
UPLOAD_ROOT = BASE_DIR / "uploads"
UPLOAD_ROOT.mkdir(parents=True, exist_ok=True)

app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")
app.mount("/uploads", StaticFiles(directory=str(UPLOAD_ROOT)), name="uploads")

templates = Jinja2Templates(directory=str(TEMPLATES_DIR))

# ======================================================================
# Jinja filters / globals
# ======================================================================
def _currency(v):
    try:
        return "${:,.2f}".format(float(v))
    except Exception:
        return "$0.00"


def streetview_url(address: str) -> str:
    """
    Prefer Google Street View Static API if key present, else fall back
    to Static Map with a marker. Reads key from settings (env/.env).
    """
    if not address:
        return ""
    key = settings.GOOGLE_MAPS_API_KEY
    if key:
        base = "https://maps.googleapis.com/maps/api/streetview"
        return f"{base}?size=600x360&location={address}&key={key}"
    base = "https://maps.googleapis.com/maps/api/staticmap"
    return f"{base}?size=640x360&markers={address}"


def _parcel_to_property_card_param(parcel_id: str | None) -> Optional[str]:
    """
    Convert Pasco parcel formats to the property card 'parcel=' digits string.

    Example:
      Input:  '33-24-16-0260-00000-2540'
      Output: '1624330260000002540'
      (the first three 2-digit sets are mirrored: 33-24-16 -> 16 24 33)
    """
    if not parcel_id:
        return None

    s = parcel_id.strip().replace(" ", "")
    parts = s.split("-")

    # If it looks like the standard dash-delimited format with first three 2-digit parts
    if len(parts) >= 3 and all(len(p) == 2 for p in parts[:3]):
        reordered = parts[2] + parts[1] + parts[0] + "".join(parts[3:])
        digits = "".join(ch for ch in reordered if ch.isdigit())
        return digits or None

    # Fallback: digits only
    digits = "".join(ch for ch in s if ch.isdigit())
    return digits or None


def pasco_appraiser_url(parcel_id: str | None) -> Optional[str]:
    """Return the direct property card URL for a given parcel id."""
    param = _parcel_to_property_card_param(parcel_id)
    if not param:
        return None
    return f"https://search.pascopa.com/parcel.aspx?parcel={param}"


# ======================================================================
# BatchData Skip Trace config + helpers
# ======================================================================
BATCHDATA_API_KEY = env_values.get("BATCHDATA_API_KEY")
BATCHDATA_BASE_URL = "https://api.batchdata.com/api/v1"


def get_case_address_components(case) -> tuple[str, str, str, Optional[str]]:
    """
    Best-effort extraction of address components for BatchData skip trace.

    We try explicit fields first (if they exist on the model), otherwise
    we parse the combined address line into:
      street, city, state, postal_code
    """
    raw_addr = (getattr(case, "address_override", None) or getattr(case, "address", "") or "").strip()

    street = raw_addr
    city = ""
    state = "FL"
    postal_code: Optional[str] = None

    # If the ORM model has explicit fields, prefer them
    city_attr = getattr(case, "city", None)
    state_attr = getattr(case, "state", None)
    postal_attr = getattr(case, "postal_code", None) or getattr(case, "zip", None)

    if city_attr or state_attr or postal_attr:
        if city_attr:
            city = str(city_attr).strip()
        if state_attr:
            s = str(state_attr).strip()
            if s:
                state = s
        if postal_attr:
            postal_code = str(postal_attr).strip() or None
        if street:
            return street, city, state, postal_code

    # Fallback: parse from combined address string "123 Main St, City, ST 33556"
    if raw_addr and "," in raw_addr:
        parts = [p.strip() for p in raw_addr.split(",")]
        street = parts[0]
        if len(parts) >= 2:
            city = parts[1]
        if len(parts) >= 3:
            st_zip_parts = parts[2].split()
            if st_zip_parts:
                state = st_zip_parts[0]
            if len(st_zip_parts) > 1:
                postal_code = st_zip_parts[1]

    return street, city, state, postal_code


def batchdata_skip_trace(
    street: str,
    city: str,
    state: str,
    postal_code: Optional[str] = None,
) -> dict:
    """
    Call BatchData Property Skip Trace API and normalize into a structure
    the template can use, including detailed phone/email metadata.
    """
    if not BATCHDATA_API_KEY:
        raise HTTPException(status_code=500, detail="BatchData API key not configured")

    if not street or not city or not state:
        raise HTTPException(status_code=400, detail="Incomplete address for skip trace")

    url = f"{BATCHDATA_BASE_URL}/property/skip-trace"

    property_address: dict = {
        "street": street,
        "city": city,
        "state": state,
    }
    if postal_code:
        property_address["postalCode"] = postal_code

    payload = {
        "requests": [
            {
                "propertyAddress": property_address
            }
        ]
    }

    headers = {
        "Authorization": f"Bearer {BATCHDATA_API_KEY}",
        "Content-Type": "application/json",
    }

    # ==========================================================
    # FORCE RAW REQUEST LOGGING TO CONSOLE EVERY TIME
    # ==========================================================
    masked_headers = headers.copy()
    if "Authorization" in masked_headers:
        token = masked_headers["Authorization"]
        if len(token) > 20:
            masked_headers["Authorization"] = token[:20] + "...(masked)"

    print("\n\n=================== BATCHDATA REQUEST ===================")
    print("URL:", url)
    print("HEADERS:", masked_headers)
    print("PAYLOAD:", json.dumps(payload, indent=2))
    print("=========================================================\n")

    try:
        resp = requests.post(url, json=payload, headers=headers, timeout=20)
    except Exception as exc:
        print("\n\n=================== BATCHDATA ERROR =====================")
        print(exc)
        print("=========================================================\n")
        raise HTTPException(
            status_code=502,
            detail=f"Error calling BatchData API: {exc}"
        )

    print("\n\n================== BATCHDATA RESPONSE ====================")
    print("STATUS:", resp.status_code)
    print("TEXT:", resp.text[:5000])  # Print up to 5000 chars of response
    print("==========================================================\n")

    # --- Handle error status codes cleanly ---
    if resp.status_code >= 400:
        try:
            err_json = resp.json()
        except Exception:
            err_json = resp.text

        if resp.status_code == 403:
            raise HTTPException(
                status_code=403,
                detail=(
                    "BatchData: this API key does not have permission for the "
                    "Property Skip Trace endpoint. Check your BatchData plan or API key settings."
                ),
            )

        raise HTTPException(
            status_code=resp.status_code,
            detail=f"BatchData error: {err_json}",
        )

    # --- Parse success response ---
    try:
        data = resp.json()
    except Exception:
        raise HTTPException(
            status_code=502,
            detail=f"BatchData returned non-JSON response: {resp.text[:500]}",
        )

    out_results: list[dict] = []

    # data looks like:
    # { "status": {...}, "results": { "persons": [ ... ], "meta": {...} } }
    if isinstance(data, dict):
        res = data.get("results")
        if isinstance(res, dict):
            raw_results = [res]   # single logical result object that has "persons"
        elif isinstance(res, list):
            raw_results = res
        else:
            resp_obj = data.get("response")
            if isinstance(resp_obj, dict) and isinstance(resp_obj.get("results"), list):
                raw_results = resp_obj["results"]
            else:
                raise HTTPException(
                    status_code=502,
                    detail=f"Unexpected BatchData response structure (dict, no usable results): {data}",
                )
    elif isinstance(data, list):
        raw_results = data
    else:
        raise HTTPException(
            status_code=502,
            detail=f"Unexpected BatchData response type: {type(data).__name__} -> {data!r}",
        )

    for r in raw_results:
        if not isinstance(r, dict):
            continue

        persons_raw = r.get("persons") or []
        if not isinstance(persons_raw, list):
            persons_raw = []

        simple_persons: list[dict] = []
        property_addr_result: dict = r.get("propertyAddress") or {}

        for p in persons_raw:
            if not isinstance(p, dict):
                continue

            # Try to pull a property address from each person if we don't have it yet
            if not property_addr_result:
                pa = p.get("propertyAddress")
                if not isinstance(pa, dict):
                    prop = p.get("property") or {}
                    if isinstance(prop, dict):
                        pa = prop.get("address")
                if isinstance(pa, dict):
                    property_addr_result = pa

            # --- Name ---
            full_name = ""
            if isinstance(p.get("fullName"), str):
                full_name = p["fullName"]
            else:
                name_obj = p.get("name")
                if isinstance(name_obj, dict):
                    full_name = (
                        name_obj.get("full")
                        or " ".join(
                            x for x in [name_obj.get("first"), name_obj.get("last")] if x
                        )
                    )
                elif isinstance(name_obj, str):
                    full_name = name_obj

            # --- Emails (keep email + tested) ---
            emails: list[dict] = []
            emails_raw = p.get("emails") or []
            if isinstance(emails_raw, list):
                for e in emails_raw:
                    if isinstance(e, dict):
                        email = e.get("email")
                        tested = e.get("tested")
                        if email:
                            emails.append(
                                {
                                    "email": email,
                                    "tested": bool(tested) if isinstance(tested, bool) else None,
                                }
                            )
                    elif isinstance(e, str):
                        emails.append({"email": e, "tested": None})

            # --- Phones (keep full metadata) ---
            phones: list[dict] = []
            phones_raw = p.get("phoneNumbers") or []
            if isinstance(phones_raw, list):
                for ph in phones_raw:
                    if not isinstance(ph, dict):
                        continue
                    number = ph.get("number") or ph.get("phone")
                    if not number:
                        continue
                    phone_type = ph.get("type")
                    carrier = ph.get("carrier")
                    tested = ph.get("tested")
                    reachable = ph.get("reachable")
                    dnc = ph.get("dnc")
                    last_reported = ph.get("lastReportedDate")
                    score = ph.get("score")
                    phones.append(
                        {
                            "number": number,
                            "type": phone_type,
                            "carrier": carrier,
                            "tested": bool(tested) if isinstance(tested, bool) else None,
                            "reachable": bool(reachable) if isinstance(reachable, bool) else None,
                            "dnc": bool(dnc) if isinstance(dnc, bool) else None,
                            "last_reported": last_reported,
                            "score": score,
                        }
                    )

            simple_persons.append(
                {
                    "full_name": full_name,
                    "emails": emails,
                    "phones": phones,
                }
            )

        out_results.append(
            {
                "propertyAddress": property_addr_result or {},
                "persons": simple_persons,
            }
        )

    return {"results": out_results}

def batchdata_property_lookup_all_attributes(
    street: str,
    city: str,
    state: str,
    postal_code: Optional[str] = None,
) -> dict:
    """
    Call BatchData Property Lookup (all-attributes) endpoint and
    return the raw JSON payload.
    """
    if not BATCHDATA_API_KEY:
        raise HTTPException(status_code=500, detail="BatchData API key not configured")

    if not street or not city or not state:
        raise HTTPException(status_code=400, detail="Incomplete address for property lookup")

    url = f"{BATCHDATA_BASE_URL}/property/lookup/all-attributes"

    property_address: dict = {
        "street": street,
        "city": city,
        "state": state,
    }
    if postal_code:
        property_address["postalCode"] = postal_code

    payload = {
        "requests": [
            {
                "address": property_address
            }
        ]
    }

    headers = {
        "Authorization": f"Bearer {BATCHDATA_API_KEY}",
        "Content-Type": "application/json",
    }

    # Optional: basic logging so you can see the call
    masked_headers = headers.copy()
    if "Authorization" in masked_headers:
        token = masked_headers["Authorization"]
        if len(token) > 20:
            masked_headers["Authorization"] = token[:20] + "...(masked)"

    print("\n\n=================== BATCHDATA PROPERTY LOOKUP ===================")
    print("URL:", url)
    print("HEADERS:", masked_headers)
    print("PAYLOAD:", json.dumps(payload, indent=2))
    print("===============================================================\n")

    try:
        resp = requests.post(url, json=payload, headers=headers, timeout=20)
    except Exception as exc:
        print("BatchData property lookup ERROR:", exc)
        raise HTTPException(
            status_code=502,
            detail=f"Error calling BatchData Property Lookup API: {exc}",
        )

    print("\n\n================== BATCHDATA PROPERTY RESPONSE ==================")
    print("STATUS:", resp.status_code)
    print("TEXT:", resp.text[:5000])
    print("===============================================================\n")

    if resp.status_code >= 400:
        try:
            err_json = resp.json()
        except Exception:
            err_json = resp.text
        raise HTTPException(
            status_code=resp.status_code,
            detail=f"BatchData property lookup error: {err_json}",
        )

    try:
        return resp.json()
    except Exception:
        raise HTTPException(
            status_code=502,
            detail=f"BatchData returned non-JSON response: {resp.text[:500]}",
        )

def save_property_for_case(case_id: int, payload: dict) -> None:
    """
    Upsert a single row in case_property for this case_id.
    Maps the first property in payload['results']['properties'] into columns
    and normalizes deedHistory, mortgageHistory, involuntaryLien.liens,
    and openLien.mortgages into detail tables.
    """
    def b2i(val):
        if isinstance(val, bool):
            return 1 if val else 0
        return None

    results = (payload or {}).get("results") or {}
    props = results.get("properties") or []
    if not props:
        logger.warning("save_property_for_case: no 'properties' in payload for case %s", case_id)
        return

    prop = props[0]  # first result only

    address          = prop.get("address") or {}
    demo             = prop.get("demographics") or {}
    fc               = prop.get("foreclosure") or {}
    assessment       = prop.get("assessment") or {}
    building         = prop.get("building") or {}
    ids_block        = prop.get("ids") or {}
    legal            = prop.get("legal") or {}
    lot              = prop.get("lot") or {}
    mort_hist        = prop.get("mortgageHistory") or []
    open_lien        = prop.get("openLien") or {}
    owner            = prop.get("owner") or {}
    owner_mail       = (owner.get("mailingAddress") or {}) if owner else {}
    pop_profile      = prop.get("propertyOwnerProfile") or {}
    quick            = prop.get("quickLists") or {}
    sale_data        = prop.get("sale") or {}
    sale_last_tx     = sale_data.get("lastTransfer") or {}
    sale_prior_tx    = sale_data.get("priorTransfer") or {}
    tax_data         = prop.get("tax") or {}
    valuation        = prop.get("valuation") or {}
    meta             = prop.get("meta") or {}
    intel_block      = prop.get("intel") or {}
    invol_lien_block = prop.get("involuntaryLien") or {}
    invol_liens      = invol_lien_block.get("liens") or []

    deed_history     = prop.get("deedHistory") or []

    # Open lien summary + mortgages list
    open_mortgages   = open_lien.get("mortgages") or []
    all_loan_types   = open_lien.get("allLoanTypes")

    ts = _dt.datetime.utcnow().isoformat()

    # JSON helpers
    import json as _json
    deed_history_json      = _json.dumps(deed_history) if deed_history else None
    mort_hist_json         = _json.dumps(mort_hist) if mort_hist else None
    invol_lien_json        = _json.dumps(invol_liens) if invol_liens else None
    open_lien_mort_json    = _json.dumps(open_mortgages) if open_mortgages else None
    open_lien_types_json   = _json.dumps(all_loan_types) if all_loan_types else None
    owner_names_json       = _json.dumps(owner.get("names") or []) if owner else None

    vals = {
        "case_id": case_id,
        "batch_property_id": prop.get("_id"),

        # ---------------- Address ----------------
        "address_validity":    address.get("addressValidity"),
        "address_house_number": address.get("houseNumber"),
        "address_street":      address.get("street"),
        "address_city":        address.get("city"),
        "address_county":      address.get("county"),
        "address_state":       address.get("state"),
        "address_zip":         address.get("zip"),
        "address_zip_plus4":   address.get("zipPlus4"),
        "address_latitude":    address.get("latitude"),
        "address_longitude":   address.get("longitude"),
        "address_county_fips": address.get("countyFipsCode"),
        "address_hash":        address.get("hash"),

        # ---------------- Demographics ----------------
        "demo_age":                   demo.get("age"),
        "demo_household_size":        demo.get("householdSize"),
        "demo_income":                demo.get("income"),
        "demo_net_worth":            demo.get("netWorth"),
        "demo_discretionary_income":  demo.get("discretionaryIncome"),
        "demo_homeowner_renter_code": demo.get("homeownerRenterCode"),
        "demo_homeowner_renter":      demo.get("homeownerRenter"),
        "demo_gender_code":           demo.get("genderCode"),
        "demo_gender":                demo.get("gender"),
        "demo_child_count":           demo.get("childCount"),
        "demo_has_children":          b2i(demo.get("hasChildren")),
        "demo_marital_status_code":   demo.get("maritalStatusCode"),
        "demo_marital_status":        demo.get("maritalStatus"),
        "demo_single_parent":         b2i(demo.get("singleParent")),
        "demo_religious":             b2i(demo.get("religious")),
        "demo_religious_affil_code":  demo.get("religiousAffiliationCode"),
        "demo_religious_affil":       demo.get("religiousAffiliation"),
        "demo_education_code":        demo.get("individualEducationCode"),
        "demo_education":             demo.get("individualEducation"),
        "demo_occupation":            demo.get("individualOccupation"),
        "demo_occupation_code":       demo.get("individualOccupationCode"),

        # ---------------- Foreclosure ----------------
        "fc_status_code":       fc.get("statusCode"),
        "fc_status":            fc.get("status"),
        "fc_recording_date":    fc.get("recordingDate"),
        "fc_filing_date":       fc.get("filingDate"),
        "fc_case_number":       fc.get("caseNumber"),
        "fc_auction_date":      fc.get("auctionDate"),
        "fc_auction_time":      fc.get("auctionTime"),
        "fc_auction_location":  fc.get("auctionLocation"),
        "fc_auction_city":      fc.get("auctionCity"),
        "fc_auction_min_bid":   fc.get("auctionMinimumBidAmount"),
        "fc_document_number":   fc.get("documentNumber"),
        "fc_book_number":       fc.get("bookNumber"),
        "fc_page_number":       fc.get("pageNumber"),
        "fc_document_type_code": fc.get("documentTypeCode"),
        "fc_document_type":     fc.get("documentType"),

        # ---------------- Assessment ----------------
        "assessed_improvement_value":  assessment.get("assessedImprovementValue"),
        "assessed_land_value":         assessment.get("assessedLandValue"),
        "assessed_total_value":        assessment.get("totalAssessedValue"),
        "assessed_year":               assessment.get("assessmentYear"),
        "market_improvement_value":    assessment.get("improvementMarketValue"),
        "market_land_value":           assessment.get("landMarketValue"),
        "market_total_value":          assessment.get("totalMarketValue"),
        "market_value_year":           assessment.get("marketValueYear"),

        # ---------------- Building ----------------
        "bldg_total_area_sqft":        building.get("totalBuildingAreaSquareFeet"),
        "bldg_living_area_sqft":       building.get("livingAreaSquareFeet"),
        "bldg_year_built":             building.get("yearBuilt"),
        "bldg_effective_year_built":   building.get("effectiveYearBuilt"),
        "bldg_count":                  building.get("buildingCount"),
        "bldg_room_count":             building.get("roomCount"),
        "bldg_unit_count":             building.get("unitCount"),
        "bldg_res_unit_count":         building.get("residentialUnitCount"),
        "bldg_calc_bath_count":        building.get("calculatedBathroomCount"),
        "bldg_full_bath_count":        building.get("fullBathroomCount"),
        "bldg_bath_count":             building.get("bathroomCount"),
        "bldg_bath_fixture_count":     building.get("bathFixtureCount"),
        "bldg_story_count":            building.get("storyCount"),
        "bldg_garage_spaces":          building.get("garageParkingSpaceCount"),
        "bldg_fireplace_count":        building.get("fireplaceCount"),
        "bldg_features_json":          _json.dumps(building.get("features") or []) if building.get("features") else None,
        "bldg_pool_code":              building.get("poolCode"),
        "bldg_pool":                   building.get("pool"),
        "bldg_roof_cover_code":        building.get("roofCoverCode"),
        "bldg_roof_cover":             building.get("roofCover"),

        # ---------------- IDs / Legal / Lot ----------------
        "ids_apn":                     ids_block.get("apn"),
        "legal_description":           legal.get("legalDescription"),
        "legal_subdivision_name":      legal.get("subdivisionName") or legal.get("tractNumber"),
        "lot_size_acres":              lot.get("lotSizeAcres"),

        # ---------------- Open lien summary ----------------
        "open_lien_total_count":                open_lien.get("totalOpenLienCount"),
        "open_lien_total_balance":              open_lien.get("totalOpenLienBalance"),
        "open_lien_first_loan_recording_date":  open_lien.get("firstLoanRecordingDate"),
        "open_lien_last_loan_recording_date":   open_lien.get("lastLoanRecordingDate"),
        "open_lien_all_loan_types_json":        open_lien_types_json,

        # JSON blobs for detail blocks
        "deed_history_json":           deed_history_json,
        "mortgage_history_json":       mort_hist_json,
        "involuntary_lien_json":       invol_lien_json,
        "open_lien_mortgages_json":    open_lien_mort_json,
        "raw_json":                    _json.dumps(payload),

        # ---------------- Owner + mailing ----------------
        "owner_full_name":             owner.get("fullName") if owner else None,
        "owner_occupied":              b2i(owner.get("ownerOccupied")) if owner else None,
        "owner_status_type_code":      owner.get("ownerStatusTypeCode") if owner else None,
        "owner_status_type":           owner.get("ownerStatusType") if owner else None,
        "owner_ownership_rights_code": owner.get("ownershipRightsCode") if owner else None,
        "owner_ownership_rights":      owner.get("ownershipRights") if owner else None,

        "owner_mail_housenumber":      owner_mail.get("houseNumber"),
        "owner_mail_street":           owner_mail.get("street"),
        "owner_mail_city":             owner_mail.get("city"),
        "owner_mail_county":           owner_mail.get("county"),
        "owner_mail_state":            owner_mail.get("state"),
        "owner_mail_zip":              owner_mail.get("zip"),
        "owner_mail_zip_plus4":        owner_mail.get("zipPlus4"),
        "owner_mail_dpv_match_code":   owner_mail.get("dpvMatchCode"),

        "owner_names_json":            owner_names_json,

        # ---------------- PropertyOwnerProfile subset ----------------
        "pop_avg_assessed_value":      pop_profile.get("averageAssessedValue"),
        "pop_avg_purchase_price":      pop_profile.get("averagePurchasePrice"),
        "pop_mortgages_total_balance": pop_profile.get("mortgagesTotalBalance"),
        "pop_mortgages_count":         pop_profile.get("mortgagesCount"),
        "pop_mortgages_avg_balance":   pop_profile.get("mortgagesAverageBalance"),
        "pop_total_purchase_price":    pop_profile.get("totalPurchasePrice"),

        # ---------------- Intel ----------------
        "intel_sale_propensity":           intel_block.get("salePropensity"),
        "intel_sale_propensity_status":    intel_block.get("salePropensityStatus"),
        "intel_sale_propensity_category":  intel_block.get("salePropensityCategory"),

        # ---------------- QuickLists ----------------
        "ql_absentee_owner":                      b2i(quick.get("absenteeOwner")),
        "ql_absentee_owner_in_state":             b2i(quick.get("absenteeOwnerInState")),
        "ql_absentee_owner_out_of_state":         b2i(quick.get("absenteeOwnerOutOfState")),
        "ql_active_listing":                      b2i(quick.get("activeListing")),
        "ql_active_auction":                      b2i(quick.get("activeAuction")),
        "ql_cash_buyer":                          b2i(quick.get("cashBuyer")),
        "ql_corporate_owned":                     b2i(quick.get("corporateOwned")),
        "ql_expired_listing":                     b2i(quick.get("expiredListing")),
        "ql_free_and_clear":                      b2i(quick.get("freeAndClear")),
        "ql_high_equity":                         b2i(quick.get("highEquity")),
        "ql_inherited":                           b2i(quick.get("inherited")),
        "ql_listed_below_market_price":           b2i(quick.get("listedBelowMarketPrice")),
        "ql_low_equity":                          b2i(quick.get("lowEquity")),
        "ql_mailing_address_vacant":              b2i(quick.get("mailingAddressVacant")),
        "ql_on_market":                           b2i(quick.get("onMarket")),
        "ql_out_of_state_owner":                  b2i(quick.get("outOfStateOwner")),
        "ql_owner_occupied":                      b2i(quick.get("ownerOccupied")),
        "ql_pending_listing":                     b2i(quick.get("pendingListing")),
        "ql_preforeclosure":                      b2i(quick.get("preforeclosure")),
        "ql_recently_sold":                       b2i(quick.get("recentlySold")),
        "ql_same_property_and_mailing_address":   b2i(quick.get("samePropertyAndMailingAddress")),
        "ql_tax_default":                         b2i(quick.get("taxDefault")),
        "ql_tired_landlord":                      b2i(quick.get("tiredLandlord")),
        "ql_unknown_equity":                      b2i(quick.get("unknownEquity")),
        "ql_vacant":                              b2i(quick.get("vacant")),
        "ql_has_hoa":                             b2i(quick.get("hasHoa")),
        "ql_has_hoa_fees":                        b2i(quick.get("hasHoaFees")),
        "ql_canceled_listing":                    b2i(quick.get("canceledListing")),
        "ql_notice_of_sale":                      b2i(quick.get("noticeOfSale")),
        "ql_notice_of_default":                   b2i(quick.get("noticeOfDefault")),
        "ql_notice_of_lis_pendens":               b2i(quick.get("noticeOfLisPendens")),

        # ---------------- Sale / Tax / Valuation / Meta ----------------
        "sale_last_transfer_doc_number":          sale_last_tx.get("documentNumber"),
        "sale_last_transfer_doc_type":            sale_last_tx.get("documentType"),
        "sale_last_transfer_recording_date":      sale_last_tx.get("recordingDate"),
        "sale_last_transfer_sale_date":           sale_last_tx.get("saleDate"),
        "sale_prior_transfer_doc_number":         sale_prior_tx.get("documentNumber"),
        "sale_prior_transfer_doc_type":           sale_prior_tx.get("documentType"),
        "sale_prior_transfer_price_code_desc":    sale_prior_tx.get("priceCodeDescription"),
        "sale_prior_transfer_price_code":         sale_prior_tx.get("priceCode"),

        "tax_amount":                             tax_data.get("taxAmount"),
        "tax_year":                               tax_data.get("taxYear"),
        "tax_delinquent_year":                    tax_data.get("taxDelinquentYear"),
        "tax_rate_code_area":                     tax_data.get("taxRateCodeArea"),

        "val_estimated_value":                    valuation.get("estimatedValue"),
        "val_price_range_min":                    valuation.get("priceRangeMin"),
        "val_price_range_max":                    valuation.get("priceRangeMax"),
        "val_confidence_score":                   valuation.get("confidenceScore"),
        "val_as_of_date":                         valuation.get("asOfDate"),
        "val_equity_current_estimated_balance":   valuation.get("equityCurrentEstimatedBalance"),
        "val_ltv":                                valuation.get("ltv"),
        "val_equity_percent":                     valuation.get("equityPercent"),

        "meta_property_date_modified":            meta.get("propertyDateModified"),
        "meta_api_version":                       results.get("meta", {}).get("apiVersion") if isinstance(results, dict) else None,
        "meta_request_id":                        results.get("meta", {}).get("requestId") if isinstance(results, dict) else None,

        "created_at": ts,
        "updated_at": ts,
    }

    try:
        with engine.begin() as conn:
            # -------- Upsert into case_property --------
            conn.exec_driver_sql(
                """
                INSERT INTO case_property (
                    case_id,
                    batch_property_id,
                    address_validity,
                    address_house_number,
                    address_street,
                    address_city,
                    address_county,
                    address_state,
                    address_zip,
                    address_zip_plus4,
                    address_latitude,
                    address_longitude,
                    address_county_fips,
                    address_hash,
                    demo_age,
                    demo_household_size,
                    demo_income,
                    demo_net_worth,
                    demo_discretionary_income,
                    demo_homeowner_renter_code,
                    demo_homeowner_renter,
                    demo_gender_code,
                    demo_gender,
                    demo_child_count,
                    demo_has_children,
                    demo_marital_status_code,
                    demo_marital_status,
                    demo_single_parent,
                    demo_religious,
                    demo_religious_affil_code,
                    demo_religious_affil,
                    demo_education_code,
                    demo_education,
                    demo_occupation,
                    demo_occupation_code,
                    fc_status_code,
                    fc_status,
                    fc_recording_date,
                    fc_filing_date,
                    fc_case_number,
                    fc_auction_date,
                    fc_auction_time,
                    fc_auction_location,
                    fc_auction_city,
                    fc_auction_min_bid,
                    fc_document_number,
                    fc_book_number,
                    fc_page_number,
                    fc_document_type_code,
                    fc_document_type,

                    assessed_improvement_value,
                    assessed_land_value,
                    assessed_total_value,
                    assessed_year,
                    market_improvement_value,
                    market_land_value,
                    market_total_value,
                    market_value_year,

                    bldg_total_area_sqft,
                    bldg_living_area_sqft,
                    bldg_year_built,
                    bldg_effective_year_built,
                    bldg_count,
                    bldg_room_count,
                    bldg_unit_count,
                    bldg_res_unit_count,
                    bldg_calc_bath_count,
                    bldg_full_bath_count,
                    bldg_bath_count,
                    bldg_bath_fixture_count,
                    bldg_story_count,
                    bldg_garage_spaces,
                    bldg_fireplace_count,
                    bldg_features_json,
                    bldg_pool_code,
                    bldg_pool,
                    bldg_roof_cover_code,
                    bldg_roof_cover,

                    ids_apn,
                    legal_description,
                    legal_subdivision_name,
                    lot_size_acres,

                    open_lien_total_count,
                    open_lien_total_balance,
                    open_lien_first_loan_recording_date,
                    open_lien_last_loan_recording_date,
                    open_lien_all_loan_types_json,

                    owner_full_name,
                    owner_occupied,
                    owner_status_type_code,
                    owner_status_type,
                    owner_ownership_rights_code,
                    owner_ownership_rights,
                    owner_mail_housenumber,
                    owner_mail_street,
                    owner_mail_city,
                    owner_mail_county,
                    owner_mail_state,
                    owner_mail_zip,
                    owner_mail_zip_plus4,
                    owner_mail_dpv_match_code,
                    owner_names_json,

                    pop_avg_assessed_value,
                    pop_avg_purchase_price,
                    pop_mortgages_total_balance,
                    pop_mortgages_count,
                    pop_mortgages_avg_balance,
                    pop_total_purchase_price,

                    intel_sale_propensity,
                    intel_sale_propensity_status,
                    intel_sale_propensity_category,

                    ql_absentee_owner,
                    ql_absentee_owner_in_state,
                    ql_absentee_owner_out_of_state,
                    ql_active_listing,
                    ql_active_auction,
                    ql_cash_buyer,
                    ql_corporate_owned,
                    ql_expired_listing,
                    ql_free_and_clear,
                    ql_high_equity,
                    ql_inherited,
                    ql_listed_below_market_price,
                    ql_low_equity,
                    ql_mailing_address_vacant,
                    ql_on_market,
                    ql_out_of_state_owner,
                    ql_owner_occupied,
                    ql_pending_listing,
                    ql_preforeclosure,
                    ql_recently_sold,
                    ql_same_property_and_mailing_address,
                    ql_tax_default,
                    ql_tired_landlord,
                    ql_unknown_equity,
                    ql_vacant,
                    ql_has_hoa,
                    ql_has_hoa_fees,
                    ql_canceled_listing,
                    ql_notice_of_sale,
                    ql_notice_of_default,
                    ql_notice_of_lis_pendens,

                    sale_last_transfer_doc_number,
                    sale_last_transfer_doc_type,
                    sale_last_transfer_recording_date,
                    sale_last_transfer_sale_date,
                    sale_prior_transfer_doc_number,
                    sale_prior_transfer_doc_type,
                    sale_prior_transfer_price_code_desc,
                    sale_prior_transfer_price_code,

                    tax_amount,
                    tax_year,
                    tax_delinquent_year,
                    tax_rate_code_area,

                    val_estimated_value,
                    val_price_range_min,
                    val_price_range_max,
                    val_confidence_score,
                    val_as_of_date,
                    val_equity_current_estimated_balance,
                    val_ltv,
                    val_equity_percent,

                    meta_property_date_modified,
                    meta_api_version,
                    meta_request_id,

                    deed_history_json,
                    mortgage_history_json,
                    involuntary_lien_json,
                    open_lien_mortgages_json,
                    raw_json,
                    created_at,
                    updated_at
                )
                VALUES (:case_id, :batch_property_id,
                        :address_validity, :address_house_number, :address_street,
                        :address_city, :address_county, :address_state,
                        :address_zip, :address_zip_plus4, :address_latitude,
                        :address_longitude, :address_county_fips, :address_hash,
                        :demo_age, :demo_household_size, :demo_income, :demo_net_worth,
                        :demo_discretionary_income, :demo_homeowner_renter_code,
                        :demo_homeowner_renter, :demo_gender_code, :demo_gender,
                        :demo_child_count, :demo_has_children,
                        :demo_marital_status_code, :demo_marital_status,
                        :demo_single_parent, :demo_religious,
                        :demo_religious_affil_code, :demo_religious_affil,
                        :demo_education_code, :demo_education,
                        :demo_occupation, :demo_occupation_code,
                        :fc_status_code, :fc_status, :fc_recording_date,
                        :fc_filing_date, :fc_case_number, :fc_auction_date,
                        :fc_auction_time, :fc_auction_location, :fc_auction_city,
                        :fc_auction_min_bid, :fc_document_number,
                        :fc_book_number, :fc_page_number,
                        :fc_document_type_code, :fc_document_type,

                        :assessed_improvement_value, :assessed_land_value,
                        :assessed_total_value, :assessed_year,
                        :market_improvement_value, :market_land_value,
                        :market_total_value, :market_value_year,

                        :bldg_total_area_sqft, :bldg_living_area_sqft,
                        :bldg_year_built, :bldg_effective_year_built,
                        :bldg_count, :bldg_room_count, :bldg_unit_count,
                        :bldg_res_unit_count, :bldg_calc_bath_count,
                        :bldg_full_bath_count, :bldg_bath_count,
                        :bldg_bath_fixture_count, :bldg_story_count,
                        :bldg_garage_spaces, :bldg_fireplace_count,
                        :bldg_features_json, :bldg_pool_code, :bldg_pool,
                        :bldg_roof_cover_code, :bldg_roof_cover,

                        :ids_apn, :legal_description, :legal_subdivision_name,
                        :lot_size_acres,

                        :open_lien_total_count, :open_lien_total_balance,
                        :open_lien_first_loan_recording_date,
                        :open_lien_last_loan_recording_date,
                        :open_lien_all_loan_types_json,

                        :owner_full_name, :owner_occupied,
                        :owner_status_type_code, :owner_status_type,
                        :owner_ownership_rights_code, :owner_ownership_rights,
                        :owner_mail_housenumber, :owner_mail_street,
                        :owner_mail_city, :owner_mail_county, :owner_mail_state,
                        :owner_mail_zip, :owner_mail_zip_plus4,
                        :owner_mail_dpv_match_code, :owner_names_json,

                        :pop_avg_assessed_value, :pop_avg_purchase_price,
                        :pop_mortgages_total_balance, :pop_mortgages_count,
                        :pop_mortgages_avg_balance, :pop_total_purchase_price,

                        :intel_sale_propensity, :intel_sale_propensity_status,
                        :intel_sale_propensity_category,

                        :ql_absentee_owner, :ql_absentee_owner_in_state,
                        :ql_absentee_owner_out_of_state, :ql_active_listing,
                        :ql_active_auction, :ql_cash_buyer,
                        :ql_corporate_owned, :ql_expired_listing,
                        :ql_free_and_clear, :ql_high_equity, :ql_inherited,
                        :ql_listed_below_market_price, :ql_low_equity,
                        :ql_mailing_address_vacant, :ql_on_market,
                        :ql_out_of_state_owner, :ql_owner_occupied,
                        :ql_pending_listing, :ql_preforeclosure,
                        :ql_recently_sold, :ql_same_property_and_mailing_address,
                        :ql_tax_default, :ql_tired_landlord,
                        :ql_unknown_equity, :ql_vacant, :ql_has_hoa,
                        :ql_has_hoa_fees, :ql_canceled_listing,
                        :ql_notice_of_sale, :ql_notice_of_default,
                        :ql_notice_of_lis_pendens,

                        :sale_last_transfer_doc_number,
                        :sale_last_transfer_doc_type,
                        :sale_last_transfer_recording_date,
                        :sale_last_transfer_sale_date,
                        :sale_prior_transfer_doc_number,
                        :sale_prior_transfer_doc_type,
                        :sale_prior_transfer_price_code_desc,
                        :sale_prior_transfer_price_code,

                        :tax_amount, :tax_year, :tax_delinquent_year,
                        :tax_rate_code_area,

                        :val_estimated_value, :val_price_range_min,
                        :val_price_range_max, :val_confidence_score,
                        :val_as_of_date, :val_equity_current_estimated_balance,
                        :val_ltv, :val_equity_percent,

                        :meta_property_date_modified,
                        :meta_api_version,
                        :meta_request_id,

                        :deed_history_json, :mortgage_history_json,
                        :involuntary_lien_json, :open_lien_mortgages_json,
                        :raw_json, :created_at, :updated_at
                )
                ON CONFLICT(case_id) DO UPDATE SET
                    batch_property_id          = excluded.batch_property_id,
                    address_validity           = excluded.address_validity,
                    address_house_number       = excluded.address_house_number,
                    address_street             = excluded.address_street,
                    address_city               = excluded.address_city,
                    address_county             = excluded.address_county,
                    address_state              = excluded.address_state,
                    address_zip                = excluded.address_zip,
                    address_zip_plus4          = excluded.address_zip_plus4,
                    address_latitude           = excluded.address_latitude,
                    address_longitude          = excluded.address_longitude,
                    address_county_fips        = excluded.address_county_fips,
                    address_hash               = excluded.address_hash,
                    demo_age                   = excluded.demo_age,
                    demo_household_size        = excluded.demo_household_size,
                    demo_income                = excluded.demo_income,
                    demo_net_worth             = excluded.demo_net_worth,
                    demo_discretionary_income  = excluded.demo_discretionary_income,
                    demo_homeowner_renter_code = excluded.demo_homeowner_renter_code,
                    demo_homeowner_renter      = excluded.demo_homeowner_renter,
                    demo_gender_code           = excluded.demo_gender_code,
                    demo_gender                = excluded.demo_gender,
                    demo_child_count           = excluded.demo_child_count,
                    demo_has_children          = excluded.demo_has_children,
                    demo_marital_status_code   = excluded.demo_marital_status_code,
                    demo_marital_status        = excluded.demo_marital_status,
                    demo_single_parent         = excluded.demo_single_parent,
                    demo_religious             = excluded.demo_religious,
                    demo_religious_affil_code  = excluded.demo_religious_affil_code,
                    demo_religious_affil       = excluded.demo_religious_affil,
                    demo_education_code        = excluded.demo_education_code,
                    demo_education             = excluded.demo_education,
                    demo_occupation            = excluded.demo_occupation,
                    demo_occupation_code       = excluded.demo_occupation_code,
                    fc_status_code             = excluded.fc_status_code,
                    fc_status                  = excluded.fc_status,
                    fc_recording_date          = excluded.fc_recording_date,
                    fc_filing_date             = excluded.fc_filing_date,
                    fc_case_number             = excluded.fc_case_number,
                    fc_auction_date            = excluded.fc_auction_date,
                    fc_auction_time            = excluded.fc_auction_time,
                    fc_auction_location        = excluded.fc_auction_location,
                    fc_auction_city            = excluded.fc_auction_city,
                    fc_auction_min_bid         = excluded.fc_auction_min_bid,
                    fc_document_number         = excluded.fc_document_number,
                    fc_book_number             = excluded.fc_book_number,
                    fc_page_number             = excluded.fc_page_number,
                    fc_document_type_code      = excluded.fc_document_type_code,
                    fc_document_type           = excluded.fc_document_type,

                    assessed_improvement_value = excluded.assessed_improvement_value,
                    assessed_land_value        = excluded.assessed_land_value,
                    assessed_total_value       = excluded.assessed_total_value,
                    assessed_year              = excluded.assessed_year,
                    market_improvement_value   = excluded.market_improvement_value,
                    market_land_value          = excluded.market_land_value,
                    market_total_value         = excluded.market_total_value,
                    market_value_year          = excluded.market_value_year,

                    bldg_total_area_sqft       = excluded.bldg_total_area_sqft,
                    bldg_living_area_sqft      = excluded.bldg_living_area_sqft,
                    bldg_year_built            = excluded.bldg_year_built,
                    bldg_effective_year_built  = excluded.bldg_effective_year_built,
                    bldg_count                 = excluded.bldg_count,
                    bldg_room_count            = excluded.bldg_room_count,
                    bldg_unit_count            = excluded.bldg_unit_count,
                    bldg_res_unit_count        = excluded.bldg_res_unit_count,
                    bldg_calc_bath_count       = excluded.bldg_calc_bath_count,
                    bldg_full_bath_count       = excluded.bldg_full_bath_count,
                    bldg_bath_count            = excluded.bldg_bath_count,
                    bldg_bath_fixture_count    = excluded.bldg_bath_fixture_count,
                    bldg_story_count           = excluded.bldg_story_count,
                    bldg_garage_spaces         = excluded.bldg_garage_spaces,
                    bldg_fireplace_count       = excluded.bldg_fireplace_count,
                    bldg_features_json         = excluded.bldg_features_json,
                    bldg_pool_code             = excluded.bldg_pool_code,
                    bldg_pool                  = excluded.bldg_pool,
                    bldg_roof_cover_code       = excluded.bldg_roof_cover_code,
                    bldg_roof_cover            = excluded.bldg_roof_cover,

                    ids_apn                    = excluded.ids_apn,
                    legal_description          = excluded.legal_description,
                    legal_subdivision_name     = excluded.legal_subdivision_name,
                    lot_size_acres             = excluded.lot_size_acres,

                    open_lien_total_count      = excluded.open_lien_total_count,
                    open_lien_total_balance    = excluded.open_lien_total_balance,
                    open_lien_first_loan_recording_date =
                        excluded.open_lien_first_loan_recording_date,
                    open_lien_last_loan_recording_date =
                        excluded.open_lien_last_loan_recording_date,
                    open_lien_all_loan_types_json     =
                        excluded.open_lien_all_loan_types_json,

                    owner_full_name                 = excluded.owner_full_name,
                    owner_occupied                  = excluded.owner_occupied,
                    owner_status_type_code          = excluded.owner_status_type_code,
                    owner_status_type               = excluded.owner_status_type,
                    owner_ownership_rights_code     = excluded.owner_ownership_rights_code,
                    owner_ownership_rights          = excluded.owner_ownership_rights,
                    owner_mail_housenumber          = excluded.owner_mail_housenumber,
                    owner_mail_street               = excluded.owner_mail_street,
                    owner_mail_city                 = excluded.owner_mail_city,
                    owner_mail_county               = excluded.owner_mail_county,
                    owner_mail_state                = excluded.owner_mail_state,
                    owner_mail_zip                  = excluded.owner_mail_zip,
                    owner_mail_zip_plus4            = excluded.owner_mail_zip_plus4,
                    owner_mail_dpv_match_code       = excluded.owner_mail_dpv_match_code,
                    owner_names_json                = excluded.owner_names_json,

                    pop_avg_assessed_value          = excluded.pop_avg_assessed_value,
                    pop_avg_purchase_price          = excluded.pop_avg_purchase_price,
                    pop_mortgages_total_balance     = excluded.pop_mortgages_total_balance,
                    pop_mortgages_count             = excluded.pop_mortgages_count,
                    pop_mortgages_avg_balance       = excluded.pop_mortgages_avg_balance,
                    pop_total_purchase_price        = excluded.pop_total_purchase_price,

                    intel_sale_propensity           = excluded.intel_sale_propensity,
                    intel_sale_propensity_status    = excluded.intel_sale_propensity_status,
                    intel_sale_propensity_category  = excluded.intel_sale_propensity_category,

                    ql_absentee_owner                      = excluded.ql_absentee_owner,
                    ql_absentee_owner_in_state             = excluded.ql_absentee_owner_in_state,
                    ql_absentee_owner_out_of_state         = excluded.ql_absentee_owner_out_of_state,
                    ql_active_listing                      = excluded.ql_active_listing,
                    ql_active_auction                      = excluded.ql_active_auction,
                    ql_cash_buyer                          = excluded.ql_cash_buyer,
                    ql_corporate_owned                     = excluded.ql_corporate_owned,
                    ql_expired_listing                     = excluded.ql_expired_listing,
                    ql_free_and_clear                      = excluded.ql_free_and_clear,
                    ql_high_equity                         = excluded.ql_high_equity,
                    ql_inherited                           = excluded.ql_inherited,
                    ql_listed_below_market_price           = excluded.ql_listed_below_market_price,
                    ql_low_equity                          = excluded.ql_low_equity,
                    ql_mailing_address_vacant              = excluded.ql_mailing_address_vacant,
                    ql_on_market                           = excluded.ql_on_market,
                    ql_out_of_state_owner                  = excluded.ql_out_of_state_owner,
                    ql_owner_occupied                      = excluded.ql_owner_occupied,
                    ql_pending_listing                     = excluded.ql_pending_listing,
                    ql_preforeclosure                      = excluded.ql_preforeclosure,
                    ql_recently_sold                       = excluded.ql_recently_sold,
                    ql_same_property_and_mailing_address   = excluded.ql_same_property_and_mailing_address,
                    ql_tax_default                         = excluded.ql_tax_default,
                    ql_tired_landlord                      = excluded.ql_tired_landlord,
                    ql_unknown_equity                      = excluded.ql_unknown_equity,
                    ql_vacant                              = excluded.ql_vacant,
                    ql_has_hoa                             = excluded.ql_has_hoa,
                    ql_has_hoa_fees                        = excluded.ql_has_hoa_fees,
                    ql_canceled_listing                    = excluded.ql_canceled_listing,
                    ql_notice_of_sale                      = excluded.ql_notice_of_sale,
                    ql_notice_of_default                   = excluded.ql_notice_of_default,
                    ql_notice_of_lis_pendens               = excluded.ql_notice_of_lis_pendens,

                    sale_last_transfer_doc_number          = excluded.sale_last_transfer_doc_number,
                    sale_last_transfer_doc_type            = excluded.sale_last_transfer_doc_type,
                    sale_last_transfer_recording_date      = excluded.sale_last_transfer_recording_date,
                    sale_last_transfer_sale_date           = excluded.sale_last_transfer_sale_date,
                    sale_prior_transfer_doc_number         = excluded.sale_prior_transfer_doc_number,
                    sale_prior_transfer_doc_type           = excluded.sale_prior_transfer_doc_type,
                    sale_prior_transfer_price_code_desc    = excluded.sale_prior_transfer_price_code_desc,
                    sale_prior_transfer_price_code         = excluded.sale_prior_transfer_price_code,

                    tax_amount                             = excluded.tax_amount,
                    tax_year                               = excluded.tax_year,
                    tax_delinquent_year                    = excluded.tax_delinquent_year,
                    tax_rate_code_area                     = excluded.tax_rate_code_area,

                    val_estimated_value                    = excluded.val_estimated_value,
                    val_price_range_min                    = excluded.val_price_range_min,
                    val_price_range_max                    = excluded.val_price_range_max,
                    val_confidence_score                   = excluded.val_confidence_score,
                    val_as_of_date                         = excluded.val_as_of_date,
                    val_equity_current_estimated_balance   = excluded.val_equity_current_estimated_balance,
                    val_ltv                                = excluded.val_ltv,
                    val_equity_percent                     = excluded.val_equity_percent,

                    meta_property_date_modified            = excluded.meta_property_date_modified,
                    meta_api_version                       = excluded.meta_api_version,
                    meta_request_id                        = excluded.meta_request_id,

                    deed_history_json          = excluded.deed_history_json,
                    mortgage_history_json      = excluded.mortgage_history_json,
                    involuntary_lien_json      = excluded.involuntary_lien_json,
                    open_lien_mortgages_json   = excluded.open_lien_mortgages_json,
                    raw_json                   = excluded.raw_json,
                    updated_at                 = excluded.updated_at
                """,
                vals,
            )

            # -------- Detail tables: wipe + repopulate --------

            # Deed history
            conn.exec_driver_sql(
                "DELETE FROM case_property_deed_history WHERE case_id = ?",
                (case_id,),
            )
            for i, d in enumerate(deed_history):
                if not isinstance(d, dict):
                    continue
                buyers = _json.dumps(d.get("buyers") or [])
                sellers = _json.dumps(d.get("sellers") or [])
                mail = d.get("mailingAddress") or {}
                conn.exec_driver_sql(
                    """
                    INSERT INTO case_property_deed_history (
                        case_id, seq, buyers_json, sellers_json,
                        recording_date, sale_date, document_number,
                        document_type_code, document_type, sale_price,
                        inter_family, mailing_street, mailing_city,
                        mailing_state, mailing_zip, mailing_hash
                    )
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """,
                    (
                        case_id,
                        i,
                        buyers,
                        sellers,
                        d.get("recordingDate"),
                        d.get("saleDate"),
                        d.get("documentNumber"),
                        d.get("documentTypeCode"),
                        d.get("documentType"),
                        d.get("salePrice"),
                        b2i(d.get("interFamily")),
                        (mail or {}).get("street"),
                        (mail or {}).get("city"),
                        (mail or {}).get("state"),
                        (mail or {}).get("zip"),
                        (mail or {}).get("hash"),
                    ),
                )

            # Mortgage history (historic)
            conn.exec_driver_sql(
                "DELETE FROM case_property_mortgage_history WHERE case_id = ?",
                (case_id,),
            )
            for i, m in enumerate(mort_hist):
                if not isinstance(m, dict):
                    continue
                borrowers = _json.dumps(m.get("borrowers") or [])
                conn.exec_driver_sql(
                    """
                    INSERT INTO case_property_mortgage_history (
                        case_id, seq, borrowers_json,
                        sale_date, recording_date, due_date,
                        lender_name, loan_type_code, loan_type,
                        loan_amount, loan_term_months, interest_rate
                    )
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """,
                    (
                        case_id,
                        i,
                        borrowers,
                        m.get("saleDate"),
                        m.get("recordingDate"),
                        m.get("dueDate"),
                        m.get("lenderName"),
                        m.get("loanTypeCode"),
                        m.get("loanType"),
                        m.get("loanAmount"),
                        m.get("loanTermMonths"),
                        m.get("interestRate"),
                    ),
                )

            # Involuntary liens
            conn.exec_driver_sql(
                "DELETE FROM case_property_involuntary_lien WHERE case_id = ?",
                (case_id,),
            )
            for i, l in enumerate(invol_liens):
                if not isinstance(l, dict):
                    continue
                conn.exec_driver_sql(
                    """
                    INSERT INTO case_property_involuntary_lien (
                        case_id, seq,
                        attorney_company_name,
                        book_number, document_number,
                        document_type, document_type_code,
                        filing_date, lien_type, lien_type_code,
                        page_number, recording_date
                    )
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """,
                    (
                        case_id,
                        i,
                        l.get("attorneyCompanyName"),
                        l.get("bookNumber"),
                        l.get("documentNumber"),
                        l.get("documentType"),
                        l.get("documentTypeCode"),
                        l.get("filingDate"),
                        l.get("lienType"),
                        l.get("lienTypeCode"),
                        l.get("pageNumber"),
                        l.get("recordingDate"),
                    ),
                )

            # Open lien mortgages (current)
            conn.exec_driver_sql(
                "DELETE FROM case_property_open_lien_mortgage WHERE case_id = ?",
                (case_id,),
            )
            for i, m in enumerate(open_mortgages):
                if not isinstance(m, dict):
                    continue
                conn.exec_driver_sql(
                    """
                    INSERT INTO case_property_open_lien_mortgage (
                        case_id, seq,
                        recording_date, loan_type_code, loan_type,
                        due_date, loan_amount, lender_name,
                        loan_term_months, current_estimated_interest_rate,
                        assigned_lender_name, ltv, estimated_payment_amount,
                        adjustable_rate_index, transaction_type,
                        transaction_type_code, first_change_date_year_conversion_rider
                    )
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """,
                    (
                        case_id,
                        i,
                        m.get("recordingDate"),
                        m.get("loanTypeCode"),
                        m.get("loanType"),
                        m.get("dueDate"),
                        m.get("loanAmount"),
                        m.get("lenderName"),
                        m.get("loanTermMonths"),
                        m.get("currentEstimatedInterestRate"),
                        m.get("assignedLenderName"),
                        m.get("ltv"),
                        m.get("estimatedPaymentAmount"),
                        m.get("adjustableRateIndex"),
                        m.get("transactionType"),
                        m.get("transactionTypeCode"),
                        m.get("firstChangeDateYearConversionRider"),
                    ),
                )

    except Exception as exc:
        logger.warning("Failed to save property lookup for case %s: %s", case_id, exc)


def save_skiptrace_row(case_id: int, skip_trace: dict) -> None:
    """
    Take our normalized skip_trace dict (from batchdata_skip_trace) and
    persist ALL phones/emails into case_skiptrace_phone / case_skiptrace_email,
    plus a summary row in case_skiptrace.
    """
    try:
        results = (skip_trace or {}).get("results") or []
        if not results:
            return

        res = results[0]
        persons = res.get("persons") or []
        if not persons:
            return

        p = persons[0]

        owner_name = p.get("full_name") or ""

        # Property address from the normalized result
        prop_addr = res.get("propertyAddress") or {}
        prop_street = prop_addr.get("street")
        prop_city = prop_addr.get("city")
        prop_state = prop_addr.get("state")
        prop_zip = prop_addr.get("zip") or prop_addr.get("postalCode")

        phones = p.get("phones") or []
        emails = p.get("emails") or []

        with engine.begin() as conn:
            # Upsert base summary row
            conn.exec_driver_sql(
                """
                INSERT INTO case_skiptrace (
                    case_id,
                    owner_name,
                    prop_street, prop_city, prop_state, prop_zip
                )
                VALUES (?, ?, ?, ?, ?, ?)
                ON CONFLICT(case_id) DO UPDATE SET
                    owner_name = excluded.owner_name,
                    prop_street = excluded.prop_street,
                    prop_city = excluded.prop_city,
                    prop_state = excluded.prop_state,
                    prop_zip = excluded.prop_zip
                """,
                (case_id, owner_name, prop_street, prop_city, prop_state, prop_zip),
            )

            # Clear old phones/emails for this case
            conn.exec_driver_sql(
                "DELETE FROM case_skiptrace_phone WHERE case_id = ?",
                (case_id,),
            )
            conn.exec_driver_sql(
                "DELETE FROM case_skiptrace_email WHERE case_id = ?",
                (case_id,),
            )

            # Insert ALL phones
            for ph in phones:
                if not isinstance(ph, dict):
                    continue
                number = ph.get("number")
                if not number:
                    continue
                phone_type = ph.get("type")
                carrier = ph.get("carrier")
                last_reported = ph.get("last_reported") or ph.get("lastReportedDate")
                score = ph.get("score")

                def as_int_bool(val):
                    if isinstance(val, bool):
                        return int(val)
                    return None

                tested = as_int_bool(ph.get("tested"))
                reachable = as_int_bool(ph.get("reachable"))
                dnc = as_int_bool(ph.get("dnc"))

                conn.exec_driver_sql(
                    """
                    INSERT INTO case_skiptrace_phone (
                        case_id, number, type, carrier,
                        last_reported, score, tested, reachable, dnc
                    )
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """,
                    (
                        case_id,
                        number,
                        phone_type,
                        carrier,
                        last_reported,
                        score,
                        tested,
                        reachable,
                        dnc,
                    ),
                )

            # Insert ALL emails
            for em in emails:
                if isinstance(em, dict):
                    email_addr = em.get("email")
                    tested_val = em.get("tested")
                    tested_int = int(tested_val) if isinstance(tested_val, bool) else None
                else:
                    email_addr = str(em)
                    tested_int = None

                if not email_addr:
                    continue

                conn.exec_driver_sql(
                    """
                    INSERT INTO case_skiptrace_email (
                        case_id, email, tested
                    )
                    VALUES (?, ?, ?)
                    """,
                    (case_id, email_addr, tested_int),
                )

    except Exception as exc:
        logger.warning("Failed to save skip trace rows for case %s: %s", case_id, exc)

def load_property_for_case(case_id: int) -> Optional[dict]:
    """
    Load raw property lookup JSON for a case, if it exists.
    """
    try:
        with engine.connect() as conn:
            row = conn.exec_driver_sql(
                "SELECT raw_json FROM case_property WHERE case_id = ?",
                (case_id,),
            ).fetchone()
        if row and row[0]:
            try:
                return json.loads(row[0])
            except Exception:
                return None
    except Exception as exc:
        logger.warning("Failed to load property lookup for case %s: %s", case_id, exc)
    return None


def load_skiptrace_for_case(case_id: int) -> Optional[dict]:
    """
    Load normalized skip-trace data from case_skiptrace + phone/email tables
    and convert it back into the 'skip_trace' dict structure the template expects.
    """
    try:
        with engine.connect() as conn:
            base = conn.exec_driver_sql(
                """
                SELECT
                    owner_name,
                    prop_street, prop_city, prop_state, prop_zip
                FROM case_skiptrace
                WHERE case_id = ?
                """,
                (case_id,),
            ).fetchone()

            phones_rows = conn.exec_driver_sql(
                """
                SELECT
                    number, type, carrier, last_reported,
                    score, tested, reachable, dnc
                FROM case_skiptrace_phone
                WHERE case_id = ?
                ORDER BY
                    -- highest score first, then non-null last_reported
                    CASE WHEN score IS NULL THEN 1 ELSE 0 END,
                    score DESC
                """,
                (case_id,),
            ).fetchall()

            emails_rows = conn.exec_driver_sql(
                """
                SELECT
                    email, tested
                FROM case_skiptrace_email
                WHERE case_id = ?
                """,
                (case_id,),
            ).fetchall()
    except Exception as exc:
        logger.warning("Failed to load skip trace for case %s: %s", case_id, exc)
        return None

    if not base:
        return None

    (
        owner_name,
        prop_street, prop_city, prop_state, prop_zip,
    ) = base

    def as_bool(val):
        if val is None:
            return None
        return bool(val)

    phones = []
    for row in phones_rows:
        (
            number, ptype, carrier, last_reported,
            score, tested, reachable, dnc,
        ) = row
        phones.append(
            {
                "number": number,
                "type": ptype,
                "carrier": carrier,
                "last_reported": last_reported,
                "score": score,
                "tested": as_bool(tested),
                "reachable": as_bool(reachable),
                "dnc": as_bool(dnc),
            }
        )

    emails = []
    for row in emails_rows:
        email_addr, tested = row
        emails.append(
            {
                "email": email_addr,
                "tested": as_bool(tested),
            }
        )

    property_address = {
        "street": prop_street,
        "city": prop_city,
        "state": prop_state,
        "postalCode": prop_zip,
    }

    person = {
        "full_name": owner_name,
        "phones": phones,
        "emails": emails,
    }

    return {
        "results": [
            {
                "propertyAddress": property_address,
                "persons": [person],
            }
        ]
    }



templates.env.filters["currency"] = _currency
templates.env.globals["streetview_url"] = streetview_url
templates.env.globals["pasco_appraiser_url"] = pasco_appraiser_url

# ======================================================================
# DB session
# ======================================================================
def get_db():
    """
    Standard DB session dependency.
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


# ======================================================================
# Skip Trace JSON Cache Helpers (legacy, still safe to keep)
# ======================================================================
def get_cached_skip_trace(case_id: int) -> Optional[dict]:
    """
    Read cached skip-trace JSON from the cases table, if any.
    """
    try:
        with engine.connect() as conn:
            row = conn.execute(
                text("SELECT skip_trace_json FROM cases WHERE id = :id"),
                {"id": case_id},
            ).mappings().first()
        if row and row.get("skip_trace_json"):
            try:
                return json.loads(row["skip_trace_json"])
            except Exception as exc:
                logger.warning(
                    "Failed to parse skip_trace_json for case %s: %s", case_id, exc
                )
                return None
    except Exception as exc:
        logger.warning(
            "Failed to read skip_trace_json for case %s: %s", case_id, exc
        )
    return None


def set_cached_skip_trace(case_id: int, payload: dict) -> None:
    """
    Persist skip-trace JSON into the cases.skip_trace_json column.
    """
    try:
        with engine.begin() as conn:
            conn.exec_driver_sql(
                "UPDATE cases SET skip_trace_json = :payload WHERE id = :id",
                {"payload": json.dumps(payload), "id": case_id},
            )
    except Exception as exc:
        logger.warning(
            "Failed to write skip_trace_json for case %s: %s", case_id, exc
        )


Base.metadata.create_all(bind=engine)

# ======================================================================
# Startup: ensure late-added columns exist (sqlite ALTERs)
# ======================================================================
@app.on_event("startup")
def ensure_sqlite_columns():
    Base.metadata.create_all(bind=engine)
    try:
        inspector = inspect(engine)
        cols = {c["name"] for c in inspector.get_columns("cases")}
        with engine.begin() as conn:
            if "current_deed_path" not in cols:
                conn.exec_driver_sql(
                    "ALTER TABLE cases ADD COLUMN current_deed_path TEXT DEFAULT ''"
                )
            if "previous_deed_path" not in cols:
                conn.exec_driver_sql(
                    "ALTER TABLE cases ADD COLUMN previous_deed_path TEXT DEFAULT ''"
                )
            # Outstanding liens column (JSON stored as TEXT)
            if "outstanding_liens" not in cols:
                conn.exec_driver_sql(
                    "ALTER TABLE cases ADD COLUMN outstanding_liens TEXT DEFAULT '[]'"
                )
            # Skip trace JSON cache
            if "skip_trace_json" not in cols:
                conn.exec_driver_sql(
                    "ALTER TABLE cases ADD COLUMN skip_trace_json TEXT DEFAULT NULL"
                )
    except OperationalError:
        # first run or non-sqlite; ignore
        pass


# --------------------------------------------------------
#  SKIP TRACE NORMALIZED TABLE (CREATE ON STARTUP)
# --------------------------------------------------------
@app.on_event("startup")
# --------------------------------------------------------
#  SKIP TRACE NORMALIZED TABLES (CREATE ON STARTUP)
# --------------------------------------------------------
@app.on_event("startup")
def ensure_skiptrace_tables():
    """
    Ensure the skip-trace tables exist:

      - case_skiptrace         (1 row per case: owner + property address)
      - case_skiptrace_phone   (N rows per case: all phones)
      - case_skiptrace_email   (N rows per case: all emails)
    """
    try:
        with engine.begin() as conn:
            # Base summary table (leave existing extra columns alone if already created)
            conn.exec_driver_sql(
                """
                CREATE TABLE IF NOT EXISTS case_skiptrace (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    case_id INTEGER NOT NULL UNIQUE,
                    owner_name TEXT,
                    prop_street TEXT,
                    prop_city TEXT,
                    prop_state TEXT,
                    prop_zip TEXT,
                    FOREIGN KEY(case_id) REFERENCES cases(id)
                )
                """
            )

            # Phones: one row per phone record
            conn.exec_driver_sql(
                """
                CREATE TABLE IF NOT EXISTS case_skiptrace_phone (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    case_id INTEGER NOT NULL,
                    number TEXT,
                    type TEXT,
                    carrier TEXT,
                    last_reported TEXT,
                    score INTEGER,
                    tested INTEGER,
                    reachable INTEGER,
                    dnc INTEGER,
                    FOREIGN KEY(case_id) REFERENCES cases(id)
                )
                """
            )

            # Emails: one row per email record
            conn.exec_driver_sql(
                """
                CREATE TABLE IF NOT EXISTS case_skiptrace_email (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    case_id INTEGER NOT NULL,
                    email TEXT,
                    tested INTEGER,
                    FOREIGN KEY(case_id) REFERENCES cases(id)
                )
                """
            )
    except OperationalError:
        # sqlite / first run quirks; ignore
        pass
    except Exception as exc:
        logger.warning("Failed to ensure skip-trace tables: %s", exc)
# --------------------------------------------------------
#  PROPERTY LOOKUP TABLE (CREATE ON STARTUP)
# --------------------------------------------------------
# --------------------------------------------------------
#  PROPERTY DETAIL TABLE (CREATE/MIGRATE ON STARTUP)
# --------------------------------------------------------
@app.on_event("startup")
def ensure_property_table():
    """
    Ensure case_property exists with all expected columns.
    If the table already exists (older schema), add any missing columns.
    """
    try:
        inspector = inspect(engine)
        tables = inspector.get_table_names()

        desired_ddl = """
            CREATE TABLE IF NOT EXISTS case_property (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                case_id INTEGER NOT NULL UNIQUE,

                -- BatchData property id
                batch_property_id TEXT,

                -- Address block
                address_validity        TEXT,
                address_house_number    TEXT,
                address_street          TEXT,
                address_city            TEXT,
                address_county          TEXT,
                address_state           TEXT,
                address_zip             TEXT,
                address_zip_plus4       TEXT,
                address_latitude        REAL,
                address_longitude       REAL,
                address_county_fips     TEXT,
                address_hash            TEXT,

                -- Demographics block
                demo_age                     INTEGER,
                demo_household_size          INTEGER,
                demo_income                  INTEGER,
                demo_net_worth               INTEGER,
                demo_discretionary_income    INTEGER,
                demo_homeowner_renter_code   TEXT,
                demo_homeowner_renter        TEXT,
                demo_gender_code             TEXT,
                demo_gender                  TEXT,
                demo_child_count             INTEGER,
                demo_has_children            INTEGER,
                demo_marital_status_code     TEXT,
                demo_marital_status          TEXT,
                demo_single_parent           INTEGER,
                demo_religious               INTEGER,
                demo_religious_affil_code    TEXT,
                demo_religious_affil         TEXT,
                demo_education_code          TEXT,
                demo_education               TEXT,
                demo_occupation              TEXT,
                demo_occupation_code         TEXT,

                -- Foreclosure block
                fc_status_code          TEXT,
                fc_status               TEXT,
                fc_recording_date       TEXT,
                fc_filing_date          TEXT,
                fc_case_number          TEXT,
                fc_auction_date         TEXT,
                fc_auction_time         TEXT,
                fc_auction_location     TEXT,
                fc_auction_city         TEXT,
                fc_auction_min_bid      REAL,
                fc_document_number      TEXT,
                fc_book_number          TEXT,
                fc_page_number          TEXT,
                fc_document_type_code   TEXT,
                fc_document_type        TEXT,

                -- Full deed history + full payload backup
                deed_history_json   TEXT,
                raw_json            TEXT,

                created_at          TEXT,
                updated_at          TEXT,

                FOREIGN KEY(case_id) REFERENCES cases(id)
            )
        """

        with engine.begin() as conn:
            # 1) Create table if it doesn't exist at all
            if "case_property" not in tables:
                conn.exec_driver_sql(desired_ddl)
                return

            # 2) If it DOES exist (older version), add missing columns
            existing_cols = {c["name"] for c in inspector.get_columns("case_property")}

            columns_to_add = [
                ("batch_property_id", "TEXT"),
                ("address_validity", "TEXT"),
                ("address_house_number", "TEXT"),
                ("address_street", "TEXT"),
                ("address_city", "TEXT"),
                ("address_county", "TEXT"),
                ("address_state", "TEXT"),
                ("address_zip", "TEXT"),
                ("address_zip_plus4", "TEXT"),
                ("address_latitude", "REAL"),
                ("address_longitude", "REAL"),
                ("address_county_fips", "TEXT"),
                ("address_hash", "TEXT"),
                ("demo_age", "INTEGER"),
                ("demo_household_size", "INTEGER"),
                ("demo_income", "INTEGER"),
                ("demo_net_worth", "INTEGER"),
                ("demo_discretionary_income", "INTEGER"),
                ("demo_homeowner_renter_code", "TEXT"),
                ("demo_homeowner_renter", "TEXT"),
                ("demo_gender_code", "TEXT"),
                ("demo_gender", "TEXT"),
                ("demo_child_count", "INTEGER"),
                ("demo_has_children", "INTEGER"),
                ("demo_marital_status_code", "TEXT"),
                ("demo_marital_status", "TEXT"),
                ("demo_single_parent", "INTEGER"),
                ("demo_religious", "INTEGER"),
                ("demo_religious_affil_code", "TEXT"),
                ("demo_religious_affil", "TEXT"),
                ("demo_education_code", "TEXT"),
                ("demo_education", "TEXT"),
                ("demo_occupation", "TEXT"),
                ("demo_occupation_code", "TEXT"),
                ("fc_status_code", "TEXT"),
                ("fc_status", "TEXT"),
                ("fc_recording_date", "TEXT"),
                ("fc_filing_date", "TEXT"),
                ("fc_case_number", "TEXT"),
                ("fc_auction_date", "TEXT"),
                ("fc_auction_time", "TEXT"),
                ("fc_auction_location", "TEXT"),
                ("fc_auction_city", "TEXT"),
                ("fc_auction_min_bid", "REAL"),
                ("fc_document_number", "TEXT"),
                ("fc_book_number", "TEXT"),
                ("fc_page_number", "TEXT"),
                ("fc_document_type_code", "TEXT"),
                ("fc_document_type", "TEXT"),
                ("deed_history_json", "TEXT"),
                ("raw_json", "TEXT"),
                ("created_at", "TEXT"),
                ("updated_at", "TEXT"),
            ]

            for col_name, col_type in columns_to_add:
                if col_name not in existing_cols:
                    conn.exec_driver_sql(
                        f"ALTER TABLE case_property ADD COLUMN {col_name} {col_type}"
                    )
    except Exception as exc:
        logger.warning("Failed to ensure/migrate case_property table: %s", exc)



# ======================================================================
# Helpers: shell runner + scraper glue
# ======================================================================
async def run_command_with_logs(cmd: list[str], job_id: str) -> int:
    """
    Async process runner that streams stdout->progress_bus line by line.
    """
    proc = await asyncio.create_subprocess_exec(
        *cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.STDOUT,
    )
    assert proc.stdout is not None
    async for raw in proc.stdout:
        await progress_bus.publish(job_id, raw.decode(errors="ignore").rstrip("\n"))
    rc = await proc.wait()
    await progress_bus.publish(job_id, f"[done] exit_code={rc}")
    return rc


def _find_scraper_script() -> Path:
    """
    Locate `pasco_foreclosure_scraper.py` in either:
    - <root>/Pasco Foreclosure Scrape
    - <root>/app/scrapers
    """
    candidates = [
        BASE_DIR / "Pasco Foreclosure Scrape" / "pasco_foreclosure_scraper.py",
        BASE_DIR / "app" / "scrapers" / "pasco_foreclosure_scraper.py",
    ]
    for p in candidates:
        if p.exists():
            return p
    raise HTTPException(
        status_code=500,
        detail=(
            "Scraper script not found. Place 'pasco_foreclosure_scraper.py' in "
            "'Pasco Foreclosure Scrape/' or 'app/scrapers/'."
        ),
    )


def _import_csv_into_db(db: Session, csv_path: str) -> tuple[int, int, int]:
    """
    Lightweight importer (upsert by case_number, ignore duplicates).
    Returns (added, updated, skipped).
    """
    import re
    logger = logging.getLogger(__name__)

    def norm_case(s):
        s = str(s or "").strip().replace("\\", "-").replace("/", "-")
        s = re.sub(r"\s+", "", s)
        return s

    def pick_col(headers, candidates):
        """
        Given a list of headers and candidate names, return the first
        header that matches (case-insensitive, trimmed).
        """
        norm_headers = [h.strip().lower() for h in headers]
        for cand in candidates:
            cand_norm = cand.strip().lower()
            if cand_norm in norm_headers:
                # return the original header name exactly as in the CSV
                return headers[norm_headers.index(cand_norm)]
        return None

    added, updated, skipped = 0, 0, 0

    with open(csv_path, newline="", encoding="utf-8-sig") as f:
        reader = _csv.DictReader(f)
        headers = reader.fieldnames or []
        logger.info("UpdateCases: CSV headers = %s", headers)

        # Try multiple possible names for important columns
        case_col   = pick_col(headers, ["Case #", "Case Number", "Case", "Case No.", "Case No"])
        filing_col = pick_col(headers, ["Filing Date", "Filing", "Filed"])
        style_col  = pick_col(headers, ["Case Name", "Style", "Case Style"])

        if not case_col:
            msg = f"Could not find case number column in CSV headers: {headers}"
            logger.error("UpdateCases: %s", msg)
            # fail cleanly so you see the error on the progress page
            raise HTTPException(status_code=400, detail=msg)

        for row in reader:
            cn_raw = row.get(case_col, "")
            cn = norm_case(cn_raw)
            if not cn:
                skipped += 1
                continue

            case = db.query(Case).filter(Case.case_number == cn).one_or_none()
            if not case:
                case = Case(case_number=cn)
                if filing_col:
                    case.filing_datetime = row.get(filing_col, "") or None
                if style_col:
                    case.style = row.get(style_col, "") or None
                db.add(case)
                db.flush()
                added += 1
            else:
                # only fill blanks to avoid overwriting your manual edits
                if not case.filing_datetime and filing_col:
                    case.filing_datetime = row.get(filing_col, "") or None
                if not case.style and style_col:
                    case.style = row.get(style_col, "") or None
                updated += 1

            # defendants: add only new names
            dnames = [
                row.get(k, "")
                for k in row.keys()
                if k and k.strip().lower().startswith("defendant")
            ]
            dnames = [d.strip() for d in dnames if d and d.strip()]

            existing = {d.name for d in (case.defendants or [])}
            for name in dnames:
                if name not in existing:
                    db.add(Defendant(case_id=case.id, name=name))

        db.commit()

    logger.info(
        "UpdateCases: Import complete. Added=%s Updated=%s Skipped=%s",
        added, updated, skipped,
    )
    return added, updated, skipped


# ======================================================================
# Routes: home, list, detail
# ======================================================================
@app.get("/", response_class=HTMLResponse)
def home():
    return RedirectResponse(url="/cases", status_code=303)


@app.get("/cases/new", response_class=HTMLResponse)
def new_case_form(request: Request):
    return templates.TemplateResponse("cases_new.html", {"request": request, "error": None})


@app.post("/cases/create")
def create_case(
    request: Request,
    case_number: str = Form(...),
    filing_date: Optional[str] = Form(None),   # "YYYY-MM-DD" or blank
    style: Optional[str] = Form(None),
    parcel_id: Optional[str] = Form(None),
    address_override: Optional[str] = Form(None),
    arv: Optional[str] = Form(None),
    rehab: Optional[str] = Form(None),
    closing_costs: Optional[str] = Form(None),
    defendants_csv: Optional[str] = Form(None),
    db: Session = Depends(get_db),
):
    # helpers
    def _num(x: Optional[str]) -> Optional[float]:
        if x is None:
            return None
        s = x.strip()
        if not s:
            return None
        try:
            return float(s.replace(",", ""))
        except ValueError:
            return None

    cn = (case_number or "").strip()
    if not cn:
        return templates.TemplateResponse("cases_new.html", {"request": request, "error": "Case # is required."})

    # Duplicate check
    exists = db.query(Case).filter(Case.case_number == cn).one_or_none()
    if exists:
        return templates.TemplateResponse("cases_new.html", {"request": request, "error": f"Case {cn} already exists (ID {exists.id})."})

    # Create case
    case = Case(case_number=cn)
    if filing_date:
        case.filing_datetime = filing_date.strip()
    if style:
        case.style = style.strip()
    if parcel_id:
        case.parcel_id = parcel_id.strip()
    if address_override:
        case.address_override = address_override.strip()

    # only set if provided
    v_arv = _num(arv)
    v_rehab = _num(rehab)
    v_cc = _num(closing_costs)
    if v_arv is not None:
        case.arv = v_arv
    if v_rehab is not None:
        case.rehab = v_rehab
    if v_cc is not None:
        case.closing_costs = v_cc

    db.add(case)
    db.flush()

    if defendants_csv:
        raw = defendants_csv.replace("\r", "\n")
        parts = [p.strip() for chunk in raw.split("\n") for p in chunk.split(",")]
        seen = set()
        for name in parts:
            if name and name not in seen:
                seen.add(name)
                db.add(Defendant(case_id=case.id, name=name))

    db.commit()
    return RedirectResponse(url=f"/cases/{case.id}", status_code=303)


@app.get("/cases/{case_id}", response_class=HTMLResponse)
def case_detail(request: Request, case_id: int, db: Session = Depends(get_db)):
    getter = getattr(db, "get", None)
    if callable(getter):
        case = db.get(Case, case_id)
    else:
        case = db.query(Case).get(case_id)  # type: ignore[call-arg]

    if not case:
        raise HTTPException(status_code=404, detail="Case not found")

    notes = (
        db.query(Note)
        .filter(Note.case_id == case_id)
        .order_by(Note.id.desc())
        .all()
    )
    try:
        setattr(case, "notes", notes)
    except Exception:
        pass

    # Load skip trace from normalized table (if present)
    skip_trace = load_skiptrace_for_case(case_id)
    skip_trace_error = None

    # Property snapshot from case_property (if available)
    property_snapshot = None
    try:
        row = db.execute(
            text("SELECT * FROM case_property WHERE case_id = :cid"),
            {"cid": case_id},
        ).mappings().first()
        if row:
            property_snapshot = dict(row)
    except Exception as exc:
        logging.exception("Failed to load property snapshot for case %s: %s", case_id, exc)
        property_snapshot = None

    offer = compute_offer_70(case.arv or 0, case.rehab or 0, case.closing_costs or 0)

    return templates.TemplateResponse(
        "case_detail.html",
        {
            "request": request,
            "case": case,
            "offer_70": offer,
            "active_parcel_id": case.parcel_id,
            "notes": notes,
            "skip_trace": skip_trace,
            "skip_trace_error": skip_trace_error,
            "property_snapshot": property_snapshot,
        },
    )




# NEW: Skip trace endpoint using BatchData
@app.post("/cases/{case_id}/skip-trace", response_class=HTMLResponse)
def skip_trace_case(request: Request, case_id: int, db: Session = Depends(get_db)):
    # Load case
    getter = getattr(db, "get", None)
    if callable(getter):
        case = db.get(Case, case_id)
    else:
        case = db.query(Case).get(case_id)  # type: ignore[call-arg]

    if not case:
        raise HTTPException(status_code=404, detail="Case not found")

    # Notes
    notes = (
        db.query(Note)
        .filter(Note.case_id == case_id)
        .order_by(Note.id.desc())
        .all()
    )

    skip_trace: Optional[dict] = None
    skip_trace_error: Optional[str] = None

    # 1) Try table-based cache first
    skip_trace = load_skiptrace_for_case(case_id)

    # 2) If no stored data, call BatchData and persist normalized row
    if skip_trace is None:
        street, city, state, postal_code = get_case_address_components(case)

        try:
            skip_trace = batchdata_skip_trace(street, city, state, postal_code)
            # Save normalized into case_skiptrace
            save_skiptrace_row(case.id, skip_trace)
            # (optional) also keep JSON cache if you still want it:
            # set_cached_skip_trace(case_id, skip_trace)
        except HTTPException as exc:
            detail = exc.detail
            skip_trace_error = detail if isinstance(detail, str) else str(detail)
        except Exception as exc:
            skip_trace_error = f"Unexpected error during skip trace: {exc}"

    offer = compute_offer_70(case.arv or 0, case.rehab or 0, case.closing_costs or 0)

    return templates.TemplateResponse(
        "case_detail.html",
        {
            "request": request,
            "case": case,
            "offer_70": offer,
            "active_parcel_id": case.parcel_id,
            "notes": notes,
            "skip_trace": skip_trace,
            "skip_trace_error": skip_trace_error,
            "property_data": load_property_for_case(case_id),
            "property_error": None,
        },
    )

@app.post("/cases/{case_id}/property-lookup", response_class=HTMLResponse)
def property_lookup_case(request: Request, case_id: int, db: Session = Depends(get_db)):
    # Load case
    getter = getattr(db, "get", None)
    if callable(getter):
        case = db.get(Case, case_id)
    else:
        case = db.query(Case).get(case_id)  # type: ignore[call-arg]

    if not case:
        raise HTTPException(status_code=404, detail="Case not found")

    # Notes
    notes = (
        db.query(Note)
        .filter(Note.case_id == case_id)
        .order_by(Note.id.desc())
        .all()
    )
    try:
        setattr(case, "notes", notes)
    except Exception:
        pass

    # Existing skip trace (unchanged)
    skip_trace = load_skiptrace_for_case(case_id)
    skip_trace_error: Optional[str] = None

    # Property lookup
    property_data: Optional[dict] = None
    property_error: Optional[str] = None

    try:
        street, city, state, postal_code = get_case_address_components(case)
        property_data = batchdata_property_lookup_all_attributes(
            street, city, state, postal_code
        )
        save_property_for_case(case.id, property_data)
    except HTTPException as exc:
        detail = exc.detail
        property_error = detail if isinstance(detail, str) else str(detail)
        # fall back to any previously saved data
        property_data = load_property_for_case(case_id)
    except Exception as exc:
        property_error = f"Unexpected error during property lookup: {exc}"
        property_data = load_property_for_case(case_id)

    offer = compute_offer_70(case.arv or 0, case.rehab or 0, case.closing_costs or 0)

    return templates.TemplateResponse(
        "case_detail.html",
        {
            "request": request,
            "case": case,
            "offer_70": offer,
            "active_parcel_id": case.parcel_id,
            "notes": notes,
            "skip_trace": skip_trace,
            "skip_trace_error": skip_trace_error,
            "property_data": property_data,
            "property_error": property_error,
        },
    )


# ======================================================================
# SSE progress endpoints + update job orchestration
# ======================================================================
@app.get("/update_progress/{job_id}", response_class=HTMLResponse)
async def update_progress_page(request: Request, job_id: str):
    html = f"""
<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Updating cases</title>
  <style>
    body {{ font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; margin: 0; }}
    .wrap {{ max-width: 900px; margin: 24px auto; padding: 0 16px; }}
    .spinner {{
      position: fixed; inset: 0; display: flex; align-items: center; justify-content: center;
      background: rgba(0,0,0,0.5); color: #fff; z-index: 9999; font-size: 18px;
    }}
    .log {{
      background: #0b0b0b; color: #c9f4ff; padding: 16px; border-radius: 12px;
      font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace;
      white-space: pre-wrap; line-height: 1.35; max-height: 60vh; overflow: auto;
      box-shadow: 0 10px 30px rgba(0,0,0,0.2);
    }}
    .muted {{ color: #9aa7b1; font-size: 12px; margin-top: 8px; }}
    .hide {{ display:none; }}
    .pill {{ display:inline-block; padding:4px 10px; border-radius: 999px; background:#eef2ff; color:#3730a3; font-size:12px; }}
  </style>
</head>
<body>
  <div id="spinner" class="spinner">Updating cases Please dont navigate away.</div>
  <div class="wrap">
    <h1>Update in progress <span class="pill">live log</span></h1>
    <div id="log" class="log"></div>
    <div id="hint" class="muted">This log will auto-scroll. Youll be redirected when finished.</div>
  </div>

<script>
  const logEl = document.getElementById('log');
  const spinner = document.getElementById('spinner');
  const es = new EventSource('/events/{job_id}');
  function appendLine(s) {{
    logEl.textContent += s + '\\n';
    logEl.scrollTop = logEl.scrollHeight;
  }}
  es.onmessage = (e) => {{
    const t = e.data || '';
    if (t.startsWith('[done]')) {{
      spinner.classList.add('hide');
      es.close();
      setTimeout(() => window.location.href = '/cases', 10000);
    }} else {{
      if (t.trim().length) {{
        appendLine(t);
        spinner.classList.add('hide');
      }}
    }}
  }};
  es.onerror = () => {{
    appendLine('[connection error] retrying');
  }};
</script>
</body>
</html>
"""
    return HTMLResponse(content=html)


@app.get("/events/{job_id}")
async def events(job_id: str):
    async def event_generator():
        # initial hello to open the stream promptly
        yield ": connected\n\n"
        while True:
            try:
                async for line in progress_bus.stream(job_id):
                    yield f"data: {line}\n\n"
            except Exception:
                # brief heartbeat to keep connection alive
                yield ": heartbeat\n\n"
                await asyncio.sleep(5)
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"},
    )


@app.get("/import", response_class=HTMLResponse)
def update_case_list_page(request: Request):
    # Renders the form with the "Days to scrape" selector that posts to /update_cases
    return templates.TemplateResponse("import.html", {"request": request})


@app.post("/update_cases")
async def update_cases(
    request: Request,
    since_days: int = Form(7),
):
    """
    Starts an async job that:
      1) Runs the foreclosure scraper with --since-days
      2) Imports the resulting CSV with upsert-by-case_number (no dupes)
    Immediately redirects to a live log page.
    """
    job_id = uuid.uuid4().hex
    # prime the log so the progress page shows something immediately
    await progress_bus.publish(job_id, f"Queued job {job_id}")
    asyncio.create_task(_update_cases_job(job_id, since_days))
    return RedirectResponse(url=f"/update_progress/{job_id}", status_code=303)


async def _update_cases_job(job_id: str, since_days: int):
    try:
        await progress_bus.publish(job_id, f"Starting update job {job_id} (since_days={since_days})")

        # 1) Run the scraper to produce CSV
        scraper_script = _find_scraper_script()
        tmpdir = tempfile.mkdtemp(prefix="pasco_update_")
        csv_out = os.path.join(tmpdir, "pasco_foreclosures.csv")

        cmd = [
            sys.executable,
            str(scraper_script),
            "--since-days", str(max(0, int(since_days))),
            "--out", csv_out,  # your integrated scraper should accept --out
        ]
        await progress_bus.publish(job_id, "Launching scraper: " + " ".join(cmd))
        rc = await run_command_with_logs(cmd, job_id)
        if rc != 0 or not os.path.exists(csv_out):
            await progress_bus.publish(job_id, "[error] Scraper failed or CSV not found.]")
            await progress_bus.publish(job_id, "[done] exit_code=1")
            return

        await progress_bus.publish(job_id, "Scraper finished. Importing CSV via tools/import_pasco_csv.py")

        # 2) Import CSV using the same logic as the CLI tool
        def _run_import():
            import_pasco_csv_main(csv_out)

        loop = asyncio.get_running_loop()
        await loop.run_in_executor(None, _run_import)

        await progress_bus.publish(job_id, "Import complete via tools/import_pasco_csv.py")
        await progress_bus.publish(job_id, "[done] exit_code=0")

    except Exception as e:
        # Surface the exception in the log and signal completion
        await progress_bus.publish(job_id, f"[exception] {e}")
        await progress_bus.publish(job_id, "[done] exit_code=1")


# ======================================================================
# PDF Report for a Case (summary + attached documents)
# ======================================================================
@app.get("/cases/{case_id}/report")
def case_report(case_id: int, db: Session = Depends(get_db)):
    # Fetch case
    getter = getattr(db, "get", None)
    if callable(getter):
        case = db.get(Case, case_id)
    else:
        case = db.query(Case).get(case_id)  # type: ignore[call-arg]

    if not case:
        raise HTTPException(status_code=404, detail="Case not found")

    # -----------------------------
    # 1) Build summary/cover page
    # -----------------------------
    summary_buf = io.BytesIO()
    c = canvas.Canvas(summary_buf, pagesize=letter)
    width, height = letter

    y = height - 50

    def line(text: str, dy: int = 16, bold: bool = False):
        nonlocal y
        if bold:
            c.setFont("Helvetica-Bold", 12)
        else:
            c.setFont("Helvetica", 11)
        c.drawString(50, y, text)
        y -= dy

    # Header
    c.setFont("Helvetica-Bold", 18)
    c.drawString(50, y, "JSN Holdings - Case Report")
    y -= 30

    c.setFont("Helvetica-Bold", 12)
    c.drawString(50, y, f"Case ID: {case.id}")
    y -= 18
    c.drawString(50, y, f"Case Number: {case.case_number or ''}")
    y -= 18

    # Basic info
    line(f"Filing Date: {case.filing_datetime or ''}")
    line(f"Style / Case Name: {case.style or ''}")
    line(f"Parcel ID: {case.parcel_id or ''}")
    addr = (getattr(case, 'address_override', None) or getattr(case, 'address', '') or '').strip()
    line(f"Address: {addr}")
    # Financials
    y -= 10
    line("Financials:", bold=True)
    arv_val = getattr(case, "arv", "") or ""
    rehab_val = getattr(case, "rehab", "") or ""
    closing_val = getattr(case, "closing_costs", "") or ""

    def _fmt_money(raw) -> str:
        # Accept str, int, float, or None and return a currency-formatted string when possible
        if raw is None:
            return ""
        if isinstance(raw, (int, float)):
            try:
                return f"${float(raw):,.2f}"
            except Exception:
                return str(raw)
        raw_str = str(raw).strip()
        if not raw_str:
            return ""
        cleaned = raw_str.replace("$", "").replace(",", "")
        try:
            val = float(cleaned)
            return f"${val:,.2f}"
        except Exception:
            return raw_str

    line(f"ARV: {_fmt_money(arv_val)}")
    line(f"Rehab: {_fmt_money(rehab_val)}")
    line(f"Closing Costs: {_fmt_money(closing_val)}")

    # JSN deal calculator
    try:
        if isinstance(arv_val, (int, float)):
            arv_num = float(arv_val)
        else:
            arv_num = float((str(arv_val) or "").replace("$", "").replace(",", "") or 0)
    except Exception:
        arv_num = 0.0
    try:
        if isinstance(rehab_val, (int, float)):
            rehab_num = float(rehab_val)
        else:
            rehab_num = float((str(rehab_val) or "").replace("$", "").replace(",", "") or 0)
    except Exception:
        rehab_num = 0.0
    try:
        if isinstance(closing_val, (int, float)):
            closing_num = float(closing_val)
        else:
            closing_num = float((str(closing_val) or "").replace("$", "").replace(",", "") or 0)
    except Exception:
        closing_num = 0.0

    try:
        from app.utils import compute_offer_70 as _compute_offer_70
    except Exception:
        def _compute_offer_70(arv, rehab, closing):
            return max(0.0, 0.7 * (arv or 0.0) - (rehab or 0.0) - (closing or 0.0))

    offer_70 = _compute_offer_70(arv_num, rehab_num, closing_num)
    try:
        offer_display = f"{offer_70:,.2f}"
    except Exception:
        offer_display = str(offer_70)
    line(f"JSN Max Offer: ${offer_display}")

    # Max Seller in Hand Cash (JSN Max Offer - sum of all liens)
    total_liens_for_calc = 0.0
    liens_raw_for_calc = getattr(case, "outstanding_liens", "[]") or "[]"
    try:
        liens_for_calc = json.loads(liens_raw_for_calc)
    except Exception:
        liens_for_calc = []
    if isinstance(liens_for_calc, list):
        for l in liens_for_calc:
            if isinstance(l, dict):
                amt_raw2 = (l.get("amount") or "").strip()
            else:
                amt_raw2 = ""
            if not amt_raw2:
                continue
            cleaned2 = amt_raw2.replace("$", "").replace(",", "")
            try:
                total_liens_for_calc += float(cleaned2)
            except Exception:
                continue
    try:
        seller_cash = max(0.0, float(offer_70) - float(total_liens_for_calc))
    except Exception:
        seller_cash = 0.0
    try:
        seller_display = f"{seller_cash:,.2f}"
    except Exception:
        seller_display = str(seller_cash)
    line(f"Max Seller in Hand Cash: ${seller_display}")

    # Defendants
    y -= 10
    line("Defendants:", bold=True)
    defendants = getattr(case, "defendants", []) or []
    clean_defendants = []
    for d in defendants:
        name = (getattr(d, "name", "") or "").strip()
        if not name:
            continue
        lower = name.lower()
        if lower in {"nan", "none", "nil"}:
            continue
        clean_defendants.append(name)
    if clean_defendants:
        for name in clean_defendants:
            line(f" - {name}")
    else:
        line(" - None recorded")

    # Outstanding Liens
    y -= 10
    line("Outstanding Liens:", bold=True)
    liens_raw = getattr(case, "outstanding_liens", "[]") or "[]"
    try:
        liens = json.loads(liens_raw)
    except Exception:
        liens = []
    total_liens = 0.0
    if isinstance(liens, list) and liens:
        for idx, l in enumerate(liens):
            if isinstance(l, dict):
                desc = (l.get("description") or "").strip()
                amt_raw = (l.get("amount") or "").strip()
            else:
                desc = str(l).strip()
                amt_raw = ""

            if not desc:
                if idx == 0:
                    desc = "Foreclosing Mortgage"
                else:
                    desc = "Lien"

            amt_str = ""
            if amt_raw:
                cleaned = amt_raw.replace("$", "").replace(",", "")
                try:
                    total_liens += float(cleaned)
                except Exception:
                    pass
                try:
                    amt_val = float(cleaned)
                    amt_str = f"${amt_val:,.2f}"
                except Exception:
                    amt_str = f"${cleaned}"

            if amt_str:
                line(f" - {desc} - {amt_str}")
            else:
                line(f" - {desc}")
    else:
        line(" - None recorded")

    # Mortgage info
    mortgage_info = "Not uploaded"
    mort_rel = getattr(case, "mortgage_path", None)
    if mort_rel:
        try:
            mort_path = UPLOAD_ROOT / mort_rel
            if mort_path.exists():
                try:
                    r = PdfReader(str(mort_path))
                except Exception:
                    r = None
                if r is not None:
                    text_chunks = []
                    for page in r.pages[:2]:
                        try:
                            t = page.extract_text() or ""
                        except Exception:
                            t = ""
                        if t:
                            text_chunks.append(t)
                    full_text = " ".join(text_chunks)
                    full_text_norm = " ".join(full_text.split())
                    if full_text_norm:
                        snippet = full_text_norm[:200]
                        if len(full_text_norm) > 200:
                            snippet += "..."
                        mortgage_info = snippet
                    else:
                        mortgage_info = "Uploaded (no extractable text found)"
            else:
                mortgage_info = "Uploaded (file not found on disk)"
        except Exception:
            mortgage_info = "Uploaded (error reading file)"

    line(f"Mortgage Info: {mortgage_info}")

    # Notes summary
    notes = getattr(case, "notes", None)
    if notes is None:
        notes = db.query(Note).filter(Note.case_id == case_id).order_by(Note.id.desc()).all()
    y -= 10
    line("Notes:", bold=True)
    if notes:
        for n in notes:
            content = (getattr(n, "content", "") or "").strip()
            if not content:
                continue
            if len(content) > 160:
                content = content[:157] + "..."
            line(f" - {content}")
    else:
        line(" - None recorded")

    # Attached documents list
    y -= 10
    line("Attached Documents:", bold=True)
    attachments = []

    def add_doc(label: str, attr: str):
        rel = getattr(case, attr, None)
        if rel:
            attachments.append((label, rel))

    add_doc("Verified Complaint", "verified_complaint_path")
    add_doc("Value Calculation", "value_calc_path")
    add_doc("Mortgage", "mortgage_path")
    add_doc("Current Deed", "current_deed_path")
    add_doc("Previous Deed", "previous_deed_path")

    if attachments:
        for label, rel in attachments:
            line(f" - {label}: {rel}")
    else:
        line(" - No documents uploaded")

    c.showPage()
    c.save()
    summary_buf.seek(0)

    # -----------------------------
    # 2) Merge summary + attachments
    # -----------------------------
    writer = PdfWriter()

    summary_reader = PdfReader(summary_buf)
    for page in summary_reader.pages:
        writer.add_page(page)

    from pathlib import Path as _Path

    for label, rel in attachments:
        abs_path = _Path(UPLOAD_ROOT) / rel
        if abs_path.exists():
            try:
                reader = PdfReader(str(abs_path))
                for page in reader.pages:
                    writer.add_page(page)
            except Exception:
                continue

    out_buf = io.BytesIO()
    writer.write(out_buf)
    out_buf.seek(0)

    filename = f"case_{case.id}_report.pdf"
    return StreamingResponse(
        out_buf,
        media_type="application/pdf",
        headers={"Content-Disposition": f'attachment; filename=\"{filename}\"'},
    )


# ======================================================================
# Case editing / uploads / notes
# ======================================================================
@app.post("/cases/{case_id}/update")
def case_update(
    case_id: int,
    parcel_id: Optional[str] = Form(None),
    address_override: Optional[str] = Form(None),
    arv: Optional[str] = Form(None),
    rehab: Optional[str] = Form(None),
    closing_costs: Optional[str] = Form(None),
    db: Session = Depends(get_db),
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)

    if parcel_id is not None:
        case.parcel_id = (parcel_id or "").strip()
    if address_override is not None:
        case.address_override = (address_override or "").strip()

    def _num(x: Optional[str]) -> Optional[float]:
        if x is None:
            return None
        s = x.strip()
        if not s:
            return None
        try:
            return float(s.replace(",", ""))
        except ValueError:
            return None

    v_arv = _num(arv)
    v_rehab = _num(rehab)
    v_cc = _num(closing_costs)

    if v_arv is not None:
        case.arv = v_arv
    if v_rehab is not None:
        case.rehab = v_rehab
    if v_cc is not None:
        case.closing_costs = v_cc

    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)



@app.post("/cases/{case_id}/upload/verified")
async def upload_verified(
    case_id: int, verified_complaint: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Verified_Complaint.pdf"
    with open(dest, "wb") as f:
        f.write(await verified_complaint.read())
    case.verified_complaint_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/upload/value_calc")
async def upload_value_calc(
    case_id: int, value_calc: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Value_Calculation.pdf"
    with open(dest, "wb") as f:
        f.write(await value_calc.read())
    case.value_calc_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/upload/mortgage")
async def upload_mortgage(
    case_id: int, mortgage: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Mortgage.pdf"
    with open(dest, "wb") as f:
        f.write(await mortgage.read())
    case.mortgage_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/upload/current-deed")
async def upload_current_deed(
    case_id: int, current_deed: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Current_Deed.pdf"
    with open(dest, "wb") as f:
        f.write(await current_deed.read())
    case.current_deed_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/upload/previous-deed")
async def upload_previous_deed(
    case_id: int, previous_deed: UploadFile = File(...), db: Session = Depends(get_db)
):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        return RedirectResponse("/cases", status_code=303)
    folder = ensure_case_folder(str(UPLOAD_ROOT), case.case_number)
    dest = Path(folder) / "Previous_Deed.pdf"
    with open(dest, "wb") as f:
        f.write(await previous_deed.read())
    case.previous_deed_path = dest.relative_to(UPLOAD_ROOT).as_posix()
    db.commit()
    return RedirectResponse(f"/cases/{case_id}", status_code=303)


@app.post("/cases/{case_id}/notes/add")
def add_note(case_id: int, content: str = Form(...), db: Session = Depends(get_db)):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        raise HTTPException(status_code=404, detail="Case not found")
    content = (content or "").strip()
    if not content:
        return RedirectResponse(url=f"/cases/{case_id}", status_code=303)
    ts = _dt.datetime.now().strftime("%Y-%m-%d %H:%M")
    note = Note(case_id=case_id, content=content, created_at=ts)
    db.add(note)
    db.commit()
    return RedirectResponse(url=f"/cases/{case_id}", status_code=303)


# ======================================================================
# NEW: Outstanding Liens API
# ======================================================================
@app.get("/cases/{case_id}/liens", response_model=list[OutstandingLien])
def get_outstanding_liens(case_id: int, db: Session = Depends(get_db)):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        raise HTTPException(status_code=404, detail="Case not found")
    return case.get_outstanding_liens()


@app.post("/cases/{case_id}/liens", response_model=list[OutstandingLien])
def save_outstanding_liens(case_id: int, payload: OutstandingLiensUpdate, db: Session = Depends(get_db)):
    case = db.query(Case).get(case_id)  # type: ignore[call-arg]
    if not case:
        raise HTTPException(status_code=404, detail="Case not found")
    case.set_outstanding_liens([l.dict() for l in payload.outstanding_liens])
    db.add(case)
    db.commit()
    db.refresh(case)
    return case.get_outstanding_liens()


# ======================================================================
# Simple health check
# ======================================================================
@app.get("/healthz")
def healthz():
    return {"status": "ok"}


# =====================
# START: Added in v1.05+ for Archive + Export + Search
# =====================
@app.on_event("startup")
def _ensure_archived_column():
    try:
        inspector = inspect(engine)
        cols = {c["name"] for c in inspector.get_columns("cases")}
        if "archived" not in cols:
            with engine.begin() as conn:
                conn.exec_driver_sql("ALTER TABLE cases ADD COLUMN archived INTEGER DEFAULT 0")
    except Exception as e:
        logger.warning("Could not ensure 'archived' column: %s", e)


@app.get("/cases", response_class=HTMLResponse)
def cases_list(
    request: Request,
    page: int = Query(1),
    show_archived: int = Query(0),
    case: str = Query("", alias="case"),
    db: Session = Depends(get_db),
):
    qry = db.query(Case)

    if not show_archived:
        qry = qry.filter(text("(archived IS NULL OR archived = 0)"))

    if case:
        qry = qry.filter(Case.case_number.contains(case))

    page_size = 10
    total = qry.count()
    pages = (total + page_size - 1) // page_size
    offset = (page - 1) * page_size
    cases = (
        qry.order_by(Case.filing_datetime.desc())
           .offset(offset)
           .limit(page_size)
           .all()
    )
    pagination = {"page": page, "pages": pages, "total": total}
    return templates.TemplateResponse(
        "cases_list.html",
        {
            "request": request,
            "cases": cases,
            "pagination": pagination,
            "show_archived": bool(show_archived),
            "search_query": case,
        },
    )


@app.post("/cases/archive")
def archive_cases(
    request: Request,
    ids: List[int] = Form(default=[]),
    show_archived: int = Form(0),
    db: Session = Depends(get_db),
):
    if ids:
        db.execute(
            text("UPDATE cases SET archived = 1 WHERE id IN :ids")
            .bindparams(bindparam("ids", expanding=True)),
            {"ids": ids},
        )
        db.commit()
    return RedirectResponse(url="/cases?show_archived=0&page=1", status_code=303)


@app.post("/cases/export")
def export_cases(
    request: Request,
    ids: List[int] = Form(default=[]),
    show_archived: int = Form(0),
    case: str = Form("", alias="case"),
    db: Session = Depends(get_db),
):
    qry = db.query(Case)

    if not show_archived:
        qry = qry.filter(text("(archived IS NULL OR archived = 0)"))

    if case:
        qry = qry.filter(Case.case_number.contains(case))
    if ids:
        qry = qry.filter(Case.id.in_(ids))

    header = [
        "id",
        "case_number",
        "filing_datetime",
        "style",
        "address",
        "arv",
        "closing_costs",
        "current_deed_path",
        "defendants",
        "mortgage_path",
        "notes_count",
        "outstanding_liens",
        "parcel_id",
        "previous_deed_path",
        "rehab",
        "value_calc_path",
        "verified_complaint_path",
    ]

    buf = io.StringIO()
    writer = _csv.writer(buf, lineterminator="\n")
    writer.writerow(header)

    rows = qry.order_by(Case.filing_datetime.desc()).all()
    for c in rows:
        try:
            defendants = [d.name for d in c.defendants] if getattr(c, "defendants", None) else []
        except Exception:
            defendants = []
        try:
            notes_count = len(c.notes) if getattr(c, "notes", None) else 0
        except Exception:
            notes_count = 0

        address = (getattr(c, "address_override", None) or getattr(c, "address", "") or "").strip()
        outstanding = getattr(c, "outstanding_liens", None) or "[]"

        writer.writerow([
            c.id,
            c.case_number or "",
            c.filing_datetime or "",
            c.style or "",
            address,
            getattr(c, "arv", "") or "",
            getattr(c, "closing_costs", "") or "",
            getattr(c, "current_deed_path", "") or "",
            json.dumps(defendants),
            getattr(c, "mortgage_path", "") or "",
            notes_count,
            outstanding,
            c.parcel_id or "",
            getattr(c, "previous_deed_path", "") or "",
            getattr(c, "rehab", "") or "",
            getattr(c, "value_calc_path", "") or "",
            getattr(c, "verified_complaint_path", "") or "",
        ])

    buf.seek(0)
    filename = f"cases_export_{_dt.datetime.now().strftime('%Y-%m-%d')}.csv"
    return StreamingResponse(
        iter([buf.getvalue()]),
        media_type="text/csv",
        headers={"Content-Disposition": f'attachment; filename=\"{filename}\"'},
    )


# =====================
# v1.07 Additions  Unarchive + AJAX endpoints
# =====================
@app.on_event("startup")
def _ensure_archived_column_v107():
    try:
        inspector = inspect(engine)
        cols = {c["name"] for c in inspector.get_columns("cases")}
        if "archived" not in cols:
            with engine.begin() as conn:
                conn.exec_driver_sql("ALTER TABLE cases ADD COLUMN archived INTEGER DEFAULT 0")
    except Exception as e:
        logger.warning("Could not ensure 'archived' column: %s", e)


@app.post("/cases/unarchive")
def unarchive_cases(
    request: Request,
    ids: List[int] = Form(default=[]),
    show_archived: int = Form(0),
    db: Session = Depends(get_db),
):
    if ids:
        db.execute(
            text("UPDATE cases SET archived = 0 WHERE id IN :ids")
            .bindparams(bindparam("ids", expanding=True)),
            {"ids": ids},
        )
        db.commit()
    return RedirectResponse(url=f"/cases?show_archived={show_archived}&page=1", status_code=303)


@app.post("/cases/archive_async")
def archive_cases_async(
    ids: List[int] = Form(default=[]),
    db: Session = Depends(get_db),
):
    if not ids:
        return {"ok": True, "updated": 0}
    db.execute(
        text("UPDATE cases SET archived = 1 WHERE id IN :ids")
        .bindparams(bindparam("ids", expanding=True)),
        {"ids": ids},
    )
    db.commit()
    return {"ok": True, "updated": len(ids)}


@app.post("/cases/unarchive_async")
def unarchive_cases_async(
    ids: List[int] = Form(default=[]),
    db: Session = Depends(get_db),
):
    if not ids:
        return {"ok": True, "updated": 0}
    db.execute(
        text("UPDATE cases SET archived = 0 WHERE id IN :ids")
        .bindparams(bindparam("ids", expanding=True)),
        {"ids": ids},
    )
    db.commit()
    return {"ok": True, "updated": len(ids)}


# =====================
# Manual Add Case (v1.08)
# =====================
# (placeholder for future additions)
